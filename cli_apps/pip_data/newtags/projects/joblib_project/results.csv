content
"(['Joblib: running Python functions as pipeline jobs', 'joblib.dump', 'joblib.load'], ['Joblib is a set of tools to provide ', '. In particular:', 'transparent disk-caching of functions and lazy re-evaluation\n(memoize pattern)', 'easy simple parallel computing', 'Joblib is optimized to be ', ' and ', ' on large\ndata in particular and has specific optimizations for ', ' arrays. It is\n', '.', 'The vision is to provide tools to easily achieve better performance and\nreproducibility when working with long running jobs.', ': code is often rerun again and\nagain, for instance when prototyping computational-heavy jobs (as in\nscientific development), but hand-crafted solutions to alleviate this\nissue are error-prone and often lead to unreproducible results.', ': efficiently persisting\narbitrary objects containing large data is hard. Using\njoblib’s caching mechanism avoids hand-written persistence and\nimplicitly links the file on disk to the execution context of\nthe original Python object. As a result, joblib’s persistence is\ngood for resuming an application status or computational job, eg\nafter a crash.', 'Joblib addresses these problems while ', ' (no framework, no new paradigms).', ' a memoize or\nmake-like functionality for Python functions that works well for\narbitrary Python objects, including very large numpy arrays. Separate\npersistence and flow-execution logic from domain logic or algorithmic\ncode by writing the operations as a set of steps with well-defined\ninputs and  outputs: Python functions. Joblib can save their\ncomputation to disk and rerun it only if necessary:', ' to make it easy to write readable\nparallel code and debug it quickly:', ': a replacement for pickle to work\nefficiently on Python objects containing large data (\n', ' & ', ' ).', '([location,\xa0backend,\xa0mmap_mode,\xa0...])', ""A context object for caching a function's return value each time it is called with the same input arguments."", '([n_jobs,\xa0backend,\xa0verbose,\xa0...])', 'Helper class for readable parallel mapping.', '(value,\xa0filename[,\xa0compress,\xa0protocol,\xa0...])', 'Persist an arbitrary Python object into one file.', '(filename[,\xa0mmap_mode])', 'Reconstruct a Python object from a file persisted with joblib.dump.', '(obj[,\xa0hash_name,\xa0coerce_mmap])', 'Quick calculation of a hash to identify uniquely Python objects containing numpy arrays.', '(compressor_name,\xa0compressor)', 'Register a new compressor.', '\n  ', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n'])"
content
"(['Joblib: running Python functions as pipeline jobs', 'joblib.dump', 'joblib.load'], ['Joblib is a set of tools to provide ', '. In particular:', 'transparent disk-caching of functions and lazy re-evaluation\n(memoize pattern)', 'easy simple parallel computing', 'Joblib is optimized to be ', ' and ', ' on large\ndata in particular and has specific optimizations for ', ' arrays. It is\n', '.', 'The vision is to provide tools to easily achieve better performance and\nreproducibility when working with long running jobs.', ': code is often rerun again and\nagain, for instance when prototyping computational-heavy jobs (as in\nscientific development), but hand-crafted solutions to alleviate this\nissue are error-prone and often lead to unreproducible results.', ': efficiently persisting\narbitrary objects containing large data is hard. Using\njoblib’s caching mechanism avoids hand-written persistence and\nimplicitly links the file on disk to the execution context of\nthe original Python object. As a result, joblib’s persistence is\ngood for resuming an application status or computational job, eg\nafter a crash.', 'Joblib addresses these problems while ', ' (no framework, no new paradigms).', ' a memoize or\nmake-like functionality for Python functions that works well for\narbitrary Python objects, including very large numpy arrays. Separate\npersistence and flow-execution logic from domain logic or algorithmic\ncode by writing the operations as a set of steps with well-defined\ninputs and  outputs: Python functions. Joblib can save their\ncomputation to disk and rerun it only if necessary:', ' to make it easy to write readable\nparallel code and debug it quickly:', ': a replacement for pickle to work\nefficiently on Python objects containing large data (\n', ' & ', ' ).', '([location,\xa0backend,\xa0mmap_mode,\xa0...])', ""A context object for caching a function's return value each time it is called with the same input arguments."", '([n_jobs,\xa0backend,\xa0verbose,\xa0...])', 'Helper class for readable parallel mapping.', '(value,\xa0filename[,\xa0compress,\xa0protocol,\xa0...])', 'Persist an arbitrary Python object into one file.', '(filename[,\xa0mmap_mode])', 'Reconstruct a Python object from a file persisted with joblib.dump.', '(obj[,\xa0hash_name,\xa0coerce_mmap])', 'Quick calculation of a hash to identify uniquely Python objects containing numpy arrays.', '(compressor_name,\xa0compressor)', 'Register a new compressor.', '\n  ', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n', '\n'])"
