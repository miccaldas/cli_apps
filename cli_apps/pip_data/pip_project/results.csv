name,content
PasteDeploy,"protocol,one,specification,entry points,Contents,Documents:,Paste Deployment is a system for finding and configuring WSGI
applications and servers.  For WSGI application consumers it provides
a single, simple function (,) for loading a WSGI application
from a configuration file or a Python Egg.  For WSGI application
providers it only asks for a single, simple entry point to your
application, so that application users don't need to be exposed to the
implementation details of your application.,The result is something a system administrator can install and manage
without knowing any Python, or the details of the WSGI application or
its container.,Paste Deployment currently does not require other parts of ,, and is distributed as a separate package.,To see updates that have been made to Paste Deploy see the ,.,Paste Deploy is released under the ,.,Paste Deploy has passed version 1.0.  Paste Deploy is an actively
maintained project.  As of 1.0, we'll make a strong effort to maintain
backward compatibility (this actually started happening long before
1.0, but now it is explicit).  This will include deprecation warnings
when necessary.  Major changes will take place under new functions or
with new entry points.,Note that the most key aspect of Paste Deploy is the entry points it
defines (such as ,).  Paste Deploy is not the only
consumer of these entry points, and many extensions can best take
place by utilizing the entry points instead of using Paste Deploy
directly.  The entry points will not change; if changes are necessary,
new entry points will be defined.,First make sure you have either
, or its
modern replacement
, installed.
For Python 3.x you need distribute as setuptools does not work on it.,Then you can install Paste Deployment using , by running:,If you want to track development, do:,This will install the package locally, and will load the files in the
checkout.  You can also simply install ,.,For downloads and other information see the ,.,A complementary package is ,.
To install that, use , (or ,).,In the following sections, the Python API for using Paste Deploy is
given.  This isn't what users will be using (but it is useful for
Python developers and useful for setting up tests fixtures).,The primary interaction with Paste Deploy is through its configuration
files.  The primary thing you want to do with a configuration file is
serve it.  To learn about serving configuration files, see , command
<,>`_.,A config file has different sections.  The only sections Paste Deploy
cares about have prefixes, like , or , --
the part after the , is the ""name"" of the section, and the part
before gives the ""type"".  Other sections are ignored.,The format is a simple ,: ,.  You can
extend the value by indenting subsequent lines.  , is a comment.,Typically you have one or two sections, named ""main"": an application
section (,) and a server section (,).
, signifies something that dispatches to multiple
applications (example below).,Here's a typical configuration file that also shows off mounting multiple applications:,I'll explain each section in detail now:,That this is a , section means it dispatches the request
to other applications.  , means to use the
composite application named , from the , package.
, is a particularly common composite application -- it uses a
path prefix to map your request to another application.  These are
the applications like ""home"", ""blog"", ""wiki"" and ""config:cms.ini"".  The last
one just refers to another file , in the same directory.,Next up:, is another simple application, in this case it
just serves up non-dynamic files.  It takes one bit of configuration:
,.  You can use variable substitution, which will pull
variables from the section , (case sensitive!) with
markers like ,.  The special variable , is
the directory containing the configuration file; you should use that
in lieu of relative filenames (which depend on the current directory,
which can change depending how the server is run).,Then:,The , section means that you want an application
with a filter applied.  The application being filtered is indicated
with , (which refers to the next section).  The
, filter doesn't actually exist, but one
could imagine it logs people in and checks permissions.,That last section is just a reference to an application that you
probably installed with ,, and one bit of
configuration you passed to it (,).,Lastly:,This section is similar to the previous one, with one important difference.
Instead of an entry point in an egg, it refers directly to the ,
variable in the , module. The reference consist of two parts,
separated by a colon. The left part is the full name of the module and the
right part is the path to the variable, as a Python expression relative to the
containing module.,So, that's most of the features you'll use.,The basic way you'll use Paste Deployment is to load , applications.  Many
Python frameworks now support WSGI, so applications written for these
frameworks should be usable.,The primary function is ,.  This loads an
application given a URI.  You can use it like:,There's two URI formats currently supported: , and ,.,URIs that being with , refer to configuration files.  These
filenames can be relative if you pass the , keyword
argument to ,.,Note,Filenames are never considered relative to the current working
directory, as that is an unpredictable location.  Generally when
a URI has a context it will be seen as relative to that context;
for example, if you have a , URI inside another
configuration file, the path is considered relative to the
directory that contains that configuration file.,Configuration files are in the INI format.  This is a simple format
that looks like:,All values are strings (no quoting is necessary).  The keys and
section names are case-sensitive, and may contain punctuation and
spaces (though both keys and values are stripped of leading and
trailing whitespace).  Lines can be continued with leading whitespace.,Lines beginning with , (preferred) or , are considered
comments.,You can define multiple applications in a single file; each
application goes in its own section.  Even if you have just one
application, you must put it in a section.,Each section name defining an application should be prefixed with
,.  The ""main"" section (when just defining one application)
would go in , or just ,.,There's two ways to indicate the Python code for the application.  The
first is to refer to another URI or name:,It would seem at first that this was pointless; just a way to point to
another location.  However, in addition to loading the application
from that location, you can also add or change the configuration.,The other way to define an application is to point exactly to some
Python code:,You must give an explicit , (in this case
,), and the value is something to import.  In
this case the module , is loaded, and the
, object retrieved from it.,See , for more about the protocols.,Configuration is done through keys besides , (or the protocol
names).  Any other keys found in the section will be passed as keyword
arguments to the factory.  This might look like:,You can override these in other sections, like:,This way some settings could be defined in a generic configuration
file (if you have ,) or you can
publish multiple (more specialized) applications just by adding a
section.,Often many applications share the same configuration.  While you can
do that a bit by using other config sections and overriding values,
often you want that done for a bunch of disparate configuration
values.  And typically applications can't take ""extra"" configuration
parameters; with global configuration you do something equivalent to
""if this application wants to know the admin email, this is it"".,Applications are passed the global configuration separately, so they
must specifically pull values out of it; typically the global
configuration serves as the basis for defaults when no local
configuration is passed in.,Global configuration to apply to every application defined in a file
should go in a special section named ,.  You can override
global configuration locally like:,That is, by using , in front of the key.,""Composite"" applications are things that act like applications, but
are made up of other applications.  One example would be a URL mapper,
where you mount applications at different URL paths.  This might look
like:,The composite application ""main"" is just like any other application
from the outside (you load it with , for instance), but it
has access to other applications defined in the configuration file.,In addition to sections with ,, you can define filters and
servers in a configuration file, with , and ,
prefixes.  You load these with , and ,.  The
configuration works just the same; you just get back different kinds
of objects.,There are several ways to apply filters to applications.  It mostly
depends on how many filters, and in what order you want to apply them.,The first way is to use the , setting, like:,Also, two special section types exist to apply filters to your
applications: , and ,.  Both of
these sections define applications, and so can be used wherever an
application is needed., defines a filter (just like you would in a
, section), and then a special key , which
points to the application to apply the filter to., is used when you need apply a number of filters.  It
takes , configuration key , (plus any global
configuration overrides you want).  , is a list of filters
ended by an application, like:,If you want to get the configuration without creating the application,
you can use the , function, which is just like the
, function except it returns the configuration that would
be used, as a dictionary.  Both global and local configuration is
combined into a single dictionary, but you can look at just one or the
other with the attributes , and ,.,
are a distribution and installation format produced by , and
, that adds metadata to a
normal Python package (among other things).,You don't need to understand a whole lot about Eggs to use them.  If
you have a , , script, just change:,to:,Now when you install the package it will be installed as an egg.,The first important part about an Egg is that it has a
,.  This is formed from the name of your distribution
(the , keyword argument to ,), and you can specify a
specific version.  So you can have an egg named ,, or
, to specify a specific version.,The second is ,.  These are references to Python objects
in your packages that are named and have a specific protocol.
""Protocol"" here is just a way of saying that we will call them with
certain arguments, and expect a specific return value.  We'll talk
more about the protocols ,.,The important part here is how we define entry points.  You'll add an
argument to , like:,This defines two applications named , and ,.  You can
then refer to these by , (or just ,,
since , is the default) and ,.,The values are instructions for importing the objects.  , is
located in the , module, in an object named
,.,There's no way to add configuration to objects imported as Eggs.,This lets you point to factories (that obey the specific protocols we
mentioned).  But that's not much use unless you can create factories
for your applications.,There's a few protocols: ,,
,, ,, and lastly
,.  Each of these expects a callable (like a
function, method, or class).,The application is the most common.  You define one like:,The , is a dictionary, and local configuration is
passed as keyword arguments.  The function returns a WSGI application.,Composites are just slightly more complex:,The , argument is an object that has a couple interesting
methods.  , return a WSGI
application with the given name.  , and ,
work the same way.,A more interesting example might be a composite factory that does
something.  For instance, consider a ""pipeline"" application:,Then we use it like:,Filter factories are just like app factories (same signature), except
they return filters.  Filters are callables that take a WSGI
application as the only argument, and return a ""filtered"" version of
that application.,Here's an example of a filter that checks that the , CGI
variable is set, creating a really simple authentication filter:,This is very similar to ,, except that it also
takes a , argument, and returns a WSGI application.  So if
you changed the above example to:,Then , would serve as a filter_app_factory
(, is a required local configuration key in this
case).,This takes the same signature as applications and filters, but returns
a server.,A server is a callable that takes a single argument, a WSGI
application.  It then serves the application.,An example might look like:,The implementation of , is left to the user.,Like ,, except , is passed as the
first argument, and the server should run immediately."
name,content
Babel,"Babel,Babel is an integrated collection of utilities that assist in
internationalizing and localizing Python applications, with an emphasis on
web-based applications.,The user documentation explains some core concept of the library and gives
some information about how it can be used.,The API reference lists the full public API that Babel provides.,
  Babel is a collection of tools for internationalizing Python applications.
,
  You can download the documentation in other formats as well:
"
name,content
imagesize,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,shibukawa/imagesize_py,Name already in use,imagesize,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This module analyzes JPEG/JPEG 2000/PNG/GIF/TIFF/SVG/Netpbm/WebP image headers and returns image size or DIP.,This module is a pure Python module. You can use file like object like file or something like ,.,Returns image size (width, height).,Returns image DPI (width, height).,It only parses headers, and ignores pixel data. So it is much faster than Pillow.,I tested on MacBookPro (2014/Core i7) with 125kB PNG files.,Run test with the following command:,MIT License,I referred to the following code:,I use sample image from here:,Thank you for feedback:"
name,content
mypy-extensions,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python/mypy_extensions,Name already in use,Mypy Extensions,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Extensions for mypy
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,The , module defines extensions to the Python standard
library , module that are supported by the mypy type checker and
the mypyc compiler.,
      Extensions for mypy
    "
name,content
distro,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-distro/distro,Name already in use,Distro - an OS platform information API,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A much more elaborate replacement for removed Python's `platform.linux_distribution()` method
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,
, provides information about the
OS distribution it runs on, such as a reliable machine-readable ID, or
version information.,It is the recommended replacement for Python's original
,
function (removed in Python 3.8). It also provides much more functionality
which isn't necessarily Python bound, like a command-line interface.,Distro currently supports Linux and BSD based systems but , is also planned.,For Python 2.6 support, see ,Installation of the latest released version from PyPI:,Installation of the latest development version:,To use as a standalone script, download , directly:, is safe to vendor within projects that do not wish to add
dependencies.,On top of the aforementioned API, several more functions are available. For a complete description of the
API, see the ,.,An alternative implementation became necessary because Python 3.5 deprecated
this function, and Python 3.8 removed it altogether. Its predecessor function
,
was already deprecated since Python 2.6 and removed in Python 3.8. Still, there
are many cases in which access to that information is needed. See , for more information.,The , package implements a robust and inclusive way of retrieving the
information about a distribution based on new standards and old methods,
namely from these data sources (from high to low precedence):, is supported and tested on Python 3.6+ and PyPy and on any
distribution that provides one or more of the data sources covered.,This package is tested with test data that mimics the exact behavior of the data sources of ,.,Pull requests are always welcome to deal with specific distributions or just
for general merriment.,See , for contribution info.,Reference implementations for supporting additional distributions and file
formats can be found here:,
      A much more elaborate replacement for removed Python's `platform.linux_distribution()` method
    "
name,content
cheap-repr,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,alexmojaki/cheap_repr,Name already in use,cheap_repr,suppressed,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Better version of repr/reprlib for short, cheap string representations in Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , ,This library provides short, fast, configurable string representations, and an easy API for registering your own. It's an improvement of the standard library module , (, in Python 2).,Just use the , function instead of ,:, knows how to handle many different types out of the box. You can register a function for any type, and pull requests to make these part of the library are welcome. If it doesn't know how to handle a particular type, the default , is used, possibly truncated:, is meant to prevent slow, expensive computations of string representations. So if it finds that a particular class can potentially produce very long representations, the class will be ,, meaning that in future the  , won't be calculated at all:, refers to the attribute on the function itself, not the module. By default it's 300, meaning that a , longer than 300 characters will trigger the suppression.,For example:,In general, write a function that takes two arguments , and decorate it with ,. Then , where , will dispatch to that function, unless there is also a registered function for a subclass which , is also an instance of. More precisely, the function corresponding to the first class in the MRO will be used. This is in contrast to the standard library module ,, which cannot handle subclasses that aren't explicitly 'registered', or classes with the same name.,The , argument is an object with a couple of useful attributes and methods:, produces a comma-separated representation of ,, automatically handling nesting and iterables that are too long, surrounded by , and ,. The number of items is limited to , (see the configuration section below).,Set , to include items from both the beginning and end, possibly leaving out items
in the middle. Only do this if , supports efficient slicing at the end, e.g. ,.,Provide the , parameter if , doesn't work. Usually this is not needed., returns a version of , at most , characters long, with the middle replaced by , if necessary., indicates how much nesting is still allowed in the result. If it's 0, return something minimal such as , to indicate that the original object is too deep to show all its contents. Otherwise, if you use , on several items inside ,, pass , as the second argument, e.g. ,.,If an exception occurs in ,, whether from a registered repr function or the usual ,, the exception will be caught and the cheap repr of the class will be suppressed:,If you would prefer exceptions to bubble up normally, you can:,To configure a specific function, you set attributes on that function. To find the function corresponding to a class, use ,:,For most functions, there are two attributes available to configure, but contributors and library writers are encouraged to add arbitrary attributes for their own functions. The first attribute is ,, described in the previous section.,The other configurable attribute is ,. All registered repr functions have this attribute. It determines the maximum number of 'parts' (e.g. list elements or string characters, the meaning depends on the function) from the input that the output can display without truncation. The default value is 6. The decorator , conveniently sets the attribute to make writing your own registered functions nicer. For example:,The functions for ,s and , from the , library don't use ,.
For the , function there's , and ,. For the , function there's just ,., takes an optional argument , which controls the display of nested objects. Typically this decreases through recursive calls, and when it's 0, the contents of the object aren't shown. See 'Registering your own repr function' for more details. This means you can change the amount of nested data in the output of , by changing the , argument. The default value is ,, which is initially 3. This means that changing , will effectively change the , argument whenever it isn't explicitly specified.,These things that can be configured globally:, returns a string that looks like the default ,. This is handy if you don't want to write your own repr function to register. Simply register this function instead, e.g., returns , - register it with a class to indicate that its own , method is already fine. This prevents it from being supressed when its output is a bit long., is handy when you want to register a repr function for a class that may not exist, e.g. if the class is in a third party package that may not be installed. See the docstring for more details.,
      Better version of repr/reprlib for short, cheap string representations in Python
    "
name,content
nvidia-cuda-runtime-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
cycler,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,matplotlib/cycler,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        cycler: composable cycles
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , ,Docs: ,
      cycler: composable cycles
    "
name,content
keystoneauth1,"Common Authentication Library for OpenStack Clients,Common Authentication Library for OpenStack Clients,Keystoneauth provides a standard way to do authentication and service requests
within the OpenStack ecosystem. It is designed for use in conjunction with the
existing OpenStack clients and for simplifying the process of writing new
clients.,Code is hosted ,. Submit bugs to the Keystone project on
,. Submit code to the , project
using ,.,Run tests with ,.,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Docs.openstack.org is powered by
          ,.
        "
name,content
progress,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,verigak/progress,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Easy to use progress bars for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,There are 7 progress bars to choose from:,To use them, just call , to advance and , to finish:,or use any bar of this class as a context manager:,The result will be a bar like the following:,To simplify the common case where the work is done in an iterator, you can
use the , method:,Progress bars are very customizable, you can change their width, their fill
character, their suffix and more:,This will produce a bar like the following:,You can use a number of template arguments in , and ,:,Instead of passing all configuration options on instatiation, you can create
your custom subclass:,You can also override any of the arguments or create your own:,For actions with an unknown number of steps you can use a spinner:,There are 5 predefined spinners:,Download from PyPi,There are a number of other classes available too, please check the source or
subclass one of them to create your own.,progress is licensed under ISC,
      Easy to use progress bars for Python
    "
name,content
alive-progress,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,rsalmei/alive-progress,Name already in use,alive-progress,pause some processing,seamlessly resume,Exponential Smoothing Algorithm,alive,Dual Line,Dual Line,Disabled,counter,definite,unknown,manual,definite,unknown,manual,different,alternating,alive,Cell Architecture,ready to play,Cell Architecture,Closures,Generators,Generator Expressions,Closures,Function Decorator,also maintaining color codes,Cell Architecture,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A new kind of Progress Bar, with real-time throughput, ETA, and very cool animations!
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,
,Have you ever wondered where your lengthy processing was at, and when would it finish? Do you usually hit , several times to make sure it didn't crash, or the SSH connection didn't freeze? Have you ever thought it'd be awesome to be able to , without hassle, return to the Python prompt to manually fix some items, then , it? I did...,I've started this new progress bar thinking about all that, behold the ,! ,Introducing the newest concept in progress bars for Python! , is in a class of its own, with an array of cool features that set it apart. Here are a few highlights:,This README is always evolving, so do take a more comprehensive look from time to time... You might find great new details in other sections! ,A very cool update here! In addition to polishing things up and improving terminal support, now , supports resuming computations!,When processing huge datasets or things that take a long time, you might either use batches or cache partial results. Then, in case it stops and is restarted, you end up skipping all those already done items very quickly, which makes the , think you're processing thousands of items per second, which in turn completely ruins the ETA... But not anymore! Just tell , that you've skipped items... 👏,You can use it in two ways:, If you do know where you've stopped:,Yep, just call , once, with the number of items., If you do not know or the items are scattered:,Yep, it's as simple as that! Just call , when an item is already done, or , as usual otherwise. You could also share a single , call at the end, with a bool saying whether you did skip that item or not. Cool, huh?,Also in this version:,Yep, I could finally get this version out! These are the new goodies:,Highly anticipated fixes:,And last but not least, a more polished layout for you to enjoy your progress!
,Now, , supports , text mode!,If you ever wanted to include longer situational messages within the bar, you probably felt squeezed into one line. You had to shrink the beautifully animated bar or, even worse, remove widgets (!) to be able to see what you needed...
,Not anymore!! You can now make the bar ,, and put text below it!,Yes, there's a message below the whole bar, and any other print/logging messages scroll above it!,There's also a new , function parameter in , which enables you to set the title and/or text of the final receipt, and improved logging support which detects customized loggers.,This is all about customization; the core widgets can now be changed:,It's incredible that these strings support all Python format features, so you can e.g., , 😉.,They can be further customized when on the ,!,If you've hidden some widgets before, just so they wouldn't appear on the receipt, now you can see them in all their running glory, and hide just the receipt ones! Or the other way around ,Another addition, now , beautifully renders its cool final receipt whenever it is stopped, even if you CTRL+C it prematurely! I don't know why I haven't thought about that before...,And finally, you can choose to disable CTRL+C at all! The default is the safer ,, which does make CTRL-C work as usual.
,Disable it ,, to make your interactive , much smoother to use (there are no stack traces if you stop it), and/or if it is at the top-level of your program!,Beware: If it is e.g. inside a for-loop, it will just continue to the next iteration, which may or may not be what you want...,Some major new features, often requested, have finally landed!,YES! Now , has support for Jupyter Notebooks and also includes a , state! Both were highly sought after, and have finally landed!
,And better, I've implemented an auto-detection mechanism for jupyter notebooks, so it just works, out of the box, without any changes in your code!!,See for yourself:,It seems to work very well, but at this moment, it should be considered ,.
,There were instances in which some visual glitches have appeared, like two , refreshes being concatenated together instead of over one another... And it's something I think I can't possibly work around: it seems Jupyter sometimes refresh the canvas at odd times, which makes it lose some data. Please let me know on the issues if something funnier arises.,This is a major breakthrough in ,!
,I took 1 year developing it, and I'm very proud of what I've accomplished \o/,Since this is a major version change, direct backward compatibility is not guaranteed. If something does not work at first, just check the new imports and functions' signatures, and you should be good to go. All previous features should still work here! ,Just install with pip:,If you're wondering what styles are builtin, it's ,! ;),Note: Please disregard the path in the animated gif below, the correct one is above. These long gifs are very time-consuming to generate, so I can't make another on every single change. Thanks for your understanding.,I've made these styles just to try all the animation factories I've created, but I think some of them ended up very, very cool! Use them at will, and mix them to your heart's content!,Do you want to see actual , bars gloriously running in your system before trying them yourself?,Cool, huh?? Now enter an , REPL and try this:,You'll see something like this, with cool animations throughout the process 😜:,Nice, huh? Loved it? I knew you would, thank you 😊.,To actually use it, just wrap your normal loop in an , context manager like this:,And it's alive! ,So, in short: retrieve the items as always, enter the , context manager with the number of items, and then iterate/process those items, calling , at the end! It's that simple! :),You can get creative! Since the bar only goes forward when you call ,, it is ,! So you can use it to monitor anything you want, like pending transactions, broken items, etc., or even call it more than once in the same iteration! So, in the end, you'll get to know how many of those ""special"" events there were, including their percentage relative to the total!,While inside an , context, you can effortlessly display messages tightly integrated with the current progress bar being displayed! It won't break in any way and will even enrich your message!,Awesome right? And all of these work just the same in a terminal or in a Jupyter notebook!,You now have a quicker way to monitor anything! Here, the items are automatically tracked for you!
,Behold the , => the , iterator adapter!,Simply wrap your items with it, and loop over them as usual!
,The bar will just work; it's that simple!,HOW COOL IS THAT?! 😜,All , parameters apply but ,, which is smarter (if not supplied, it will be auto-inferred from your data using , or ,), and , that does not make sense here.,Note there isn't any , handle at all in there. But what if you do want it, e.g. to set text messages or retrieve the current progress?
,You can interact with the internal , by just assigning , to a variable like this:,Note that this is a slightly special ,, which does not support ,, since the iterator adapter tracks items automatically for you. Also, it supports ,, which enables you to set the title and/or text of the final receipt:,In a nutshell:,Actually, the , argument is optional. If you do provide it, the bar enters in ,, the one used for well-bounded tasks. This mode has all the widgets , has to offer: progress, count, throughput, and ETA.,If you don't, the bar enters in ,, the one used for unbounded tasks. In this mode, the whole progress bar is animated, as it's not possible to determine the progress, and therefore the ETA. But you still get the count and throughput widgets as usual.
,The cool spinner is still present here alongside the progress bar, both running their animations concurrently and independently of each other, rendering a unique show in your terminal! ,Both definite and unknown modes use internally a , to maintain progress. This is the source value which all widgets are derived from.,On the other hand, the , uses internally a , to maintain progress. This enables you to get complete control of the bar position! It's usually used to monitor processes that only feed you the percentage of completion, or to generate some kind of special effects.,To use it, just include a , argument into , (or ,), and you get to send any percentage to the , handler! For example, to set it to 15%, just call , — which is 15 / 100.,You can also use , here! If you do provide it, , will infer an internal , by itself, and thus will be able to offer you the same count, throughput, and ETA widgets!
,If you don't, you'll at least get rough versions of the throughput and ETA widgets. The throughput will use ""%/s"" (percent per second), and the ETA will be till 1.0 (100%). Both are very inaccurate but better than nothing.,You can call , in manual mode as frequently as you want! The refresh rate will still be asynchronously computed as usual, according to the current progress and the elapsed time, so you won't ever spam the terminal with more updates than it can handle.,When , is provided all is cool:,When it isn't, some compromises have to be made:,But actually it's quite simple, you do not need to think about which mode you should use:
,Just always send the , if you have it, and use , if you need it!
,It will just work the best it can! , \o/,The , handlers support either relative or absolute semantics, depending on the mode:,The manual modes enable you to get super creative! Since you can set the bar instantly to whatever position you want, you could:,In any case, to retrieve the current count/percentage, just call: ,:,Last but not least, the , handler of the , mode has a unique ability: skipping items for an accurate ETA! Just call , or , to use it. When skipped is True, that item(s) are ignored when computing the rate, and thus not ruining the ETA.,Maintaining an open source project is hard and time-consuming, and I've put much , and effort into this.,If you've appreciated my work, you can back me up with a donation! Thank you ,
,The , exhibit has an optional argument to choose which show to present, , (default), , or ,, do take a look at them! ;),Note: Please disregard the path in the animated gif below, the correct one is above. These long gifs are very time-consuming to generate, so I can't make another on every single change. Thanks for your understanding.,And the themes one (, new in 2.0):,The , exhibit also accepts some customization options:,For example to get a marine show, you can ,:,You can also access these shows with the shorthands ,, ,, and ,!,There's also a small utility called ,, to help find that cool character to put in your customized spinners and bars, or to determine if your terminal does support Unicode characters.,There are several options to customize both appearance and behavior!
,All of them can be set both directly in the , or globally in the ,!,These are the options - default values in brackets:,And there's also one that can only be set locally in an , context:,To set them locally, just send them as keyword arguments to ,:,To use them globally, send them to ,, and any , created after that will include those options! And you can mix and match them, local options always have precedence over global ones:,Yes, you can assemble your own spinners! And it's easy!
,I've created a plethora of special effects, so you can just mix and match them any way you want! There are frames, scrolling, bouncing, sequential, alongside, and delayed spinners! Get creative! ,The spinners' animations are engineered by very advanced generator expressions, deep within several layers of meta factories, factories and generators 🤯!,These generators are capable of multiple different animation cycles according to the spinner behavior, e.g. a bouncing spinner can run one cycle to smoothly bring a subject into the scene, then repeatedly reposition it until the other side, then make it smoothly disappear off the scene => and this is all only one cycle! Then it can be followed by another cycle to make it all again but backwards!
And bouncing spinners also accept , and , patterns in both the right and left directions, which makes them generate the cartesian product of all the combinations, possibly producing dozens of different cycles until they start repeating them!! ,And there's more, I think one of the most impressive achievements I got in this animation system (besides the spinner compiler itself)... They only yield more animation frames until the current cycle is not exhausted, then ,! Yep, the next cycle does not start just yet! This behavior creates natural breaks in exactly the correct spots, where the animations are not disrupted, so I can smoothly link with whatever other animation I want!!
,This has all kinds of cool implications: the cycles can have different frame counts, different screen lengths, they do not need to be synchronized, they can create long different sequences by themselves, they can cooperate to play cycles in sequence or alongside, and I can amaze you displaying several totally distinct animations at the same time without any interferences whatsoever!,It's almost like they were... ,!! ,
,==> Yes, that's where this project's name came from! ,Now, these generators of cycles and frames are fully consumed ahead of time by the ,! This is a very cool new processor that I made inside the , effort, to make all these animations work even in the presence of wide chars or complex grapheme clusters! It was very hard to make these clusters  gradually enter and exit frames, smoothly, while keeping them from breaking the Unicode encoding and especially maintain their original lengths in all frames! Yes, several chars in sequence can represent another completely different symbol, so they cannot ever be split! They have to enter and exit the frame always together, all at once, or the grapheme won't show up at all (an Emoji for instance)!! Enter the ,......,This has made possible some incredible things!! Since this Compiler generates the whole spinner frame data beforehand:,Also, with the complete frame data compiled and persisted, I could create several commands to , that data, like changing shapes, replacing chars, adding visual pauses (frame repetitions), generating bouncing effects on-demand over any content, and even transposing cycles with frames!!,But how can you see these effects? Does the effect you created look good? Or is it not working as you thought? YES, now you can see all generated cycles and frames analytically, in a very beautiful rendition!!
,I love what I've achieved here ,, it's probably THE most beautiful tool I've ever created... Behold the , tool!!,It's awesome if I say so myself, isn't it? And a very complex piece of software I'm proud of, , if you'd like.,And the , tool is much more powerful! For instance, you can see the codepoints of the frames!!! And maybe have a glimpse of why this version was so, so very hard and complex to make...,In red, you see the grapheme clusters, that occupy one or two ""logical positions"", regardless of their actual sizes... These are the ""Cells"" of the new ,...
,Look how awesome an Emoji Flag is represented:,The flag seems to move so smoothly because it uses ""half-characters""! Since it is a wide char, , knows it will be rendered with ""two visible chars"", and the animations consider this, but compose with spaces, which occupy only one. When one uses mixed backgrounds, the situation is much more complex...,The types of factories I've created are:,For more details please look at their docstrings, which are very complete.,Customizing bars is nowhere near that involved. Let's say they are ""immediate"", passive objects. They do not support animations, i.e. they will always generate the same rendition given the same parameters. Remember spinners are infinite generators, capable of generating long and complex sequences.,Well, bars also have a meta factory, use closures to store the styling parameters, and receive additional operating parameters, but then the actual factory can't generate any content by itself. It still needs an extra parameter, a floating-point number between 0 and 1, which is the percentage to render itself., calculates this percentage automatically based on the counter and total, but you can send it yourself when in the , mode!,Bars also do not have a Bar Compiler, but they ,!! ,You can even mix and match wide chars and normal chars just like in spinners! (and everything keeps perfectly aligned ,),Use the check tools to your heart's content!! They have even more goodies awaiting you, even real-time animations!,Create the wildest and coolest animations you can and send them to me!
,I'm thinking about creating some kind of , package, with user-contributed spinners and bars!,Wow, if you've read everything till here, you should now have a sound knowledge about using ,! ,
,But brace yourself because there is even more, exciting stuff lies ahead!,Maintaining an open source project is hard and time-consuming, and I've put much , and effort into this.,If you've appreciated my work, you can back me up with a donation! Thank you ,
,Oh, you want to pause it altogether, I hear? This is an amazing novel concept, not found anywhere AFAIK.
,With this you get to act on some items ,, at will, right in the middle of an ongoing processing!!
,YES, you can return to the prompt and fix, change, submit things, and the bar will just ""remember"" where it was...,Suppose you need to reconcile payment transactions (been there, done that). You need to iterate over thousands of them, detect somehow the faulty ones, and fix them. This fix is not simple nor deterministic, you need to study each one to understand what to do. They could be missing a recipient, or have the wrong amount, or not be synced with the server, etc., it's hard to even imagine all possibilities.,Typically, you would have to let the detection process run until completion, appending to a list each inconsistency it finds and waiting, potentially a long time, until you can finally start fixing them... You could of course mitigate that by processing in chunks, or printing them and acting via another shell, etc., but those have their own shortcomings... ,
,Now, there's a better way! Simply pause the actual detection process for a while! Then you just have to wait till the next fault is found, and act in near real-time!,To use the pause mechanism you just have to write a function, so the code can , the items you want to interact with. You most probably already use one in your code, but in the , shell or another REPL you probably don't. So just wrap your debug code in a function, then enter within a , context!!,That's it! It's that simple! \o/
,Now run , to instantiate the generator, and whenever you want the next faulty transaction, just call ,! I love it...
,The , bar will start and run as usual, but as soon as any inconsistency is found, the bar will pause itself, turning off the refresh thread and remembering its exact state, and yield the transaction to you directly on the prompt! It's almost magic! ,You can then inspect the transaction with the usual , shortcut of , (or just directly assign it with ,), and you're all set to fix it!
,When you're done, just reactivate the bar with the same , call as before!! The bar reappears, turns everything back on, and continues ,!! Ok, it is magic ,Rinse and repeat till the final receipt appears, and there'll be no faulty transactions anymore. ,So, you need to monitor a fixed operation, without any loops, right?
,It'll work for sure! Here is a naive example (we'll do better in a moment):,It's naive because it assumes all steps take the same amount of time, but actually, each one may take a very different time to complete. Think , and , may be extremely fast, which makes the percentage skyrocket to 50%, then stopping for a long time in the , step... You get the point, it can ruin the user experience and create a very misleading ETA.,To improve upon that you need to distribute the steps' percentages accordingly! Since you told , there were four steps, when the first one was completed it understood 1/4 or 25% of the whole processing was complete... Thus, you need to measure how long your steps actually take and use the , to increase the bar percentage by the right amount at each step!,You can use my other open source project , to easily measure these durations! Just try to simulate with some representative inputs, to get better results. Something like:,There you go! Now you know the relative timings of all the steps, and can use them to improve your original code! Just get the cumulative timings and put them within a manual mode ,!,For example, if the timings you found were 10%, 30%, 20%, and 40%, you'd use 0.1, 0.4, 0.6, and 1.0 (the last one should always be 1.0):,That's it! The user experience and ETA should be greatly improved now.,So, you want to calibrate the engine?,The , bars have cool visual feedback of the current throughput, so you can actually , how fast your processing is, as the spinner runs faster or slower with it.
,For this to happen, I've put together and implemented a few fps curves to empirically find which one gave the best feel of speed:,(interactive version [here](,)),The graph shows the logarithmic (red), parabolic (blue) and linear (green) curves, these are the ones I started with. It was not an easy task, I've made dozens of tests, and never found one that really inspired that feel of speed I was looking for. The best one seemed to be the logarithmic one, but it reacted poorly with small numbers.
I know I could make it work with a few twists for those small numbers, so I experimented a lot and adjusted the logarithmic curve (dotted orange) until I finally found the behavior I expected! It is the one that seemed to provide the best all-around perceived speed changes throughout the whole spectrum from a few to billions...
That is the curve I've settled with, and it's the one used in all modes and conditions. In the future and if someone would find it useful, that curve could be configurable.,Well, the default , calibration is , in bounded modes, i.e., it takes 1 million iterations per second for the bar to refresh itself at 60 frames per second. In the manual unbounded mode, it is , (100%). Both enable a vast operating range and generally work quite well.,For example, take a look at the effect these very different calibrations have, running the very same code at the very same speed! Notice the feel the spinner passes to the user, is this processing going slow or going fast? And remember that isn't only the spinner refreshing but the whole line, complete with the bar rendition and all widgets, so everything gets smoother or sluggish:,So, if your processing hardly gets to 20 items per second, and you think , is rendering sluggish, you could increase that sense of speed by calibrating it to let's say ,, and it will be running waaaay faster... It is better to always leave some headroom and calibrate it to something between 50% and 100% more, and then tweak it from there to find the one you like the most! :),Do these astonishing , animations refuse to display?,PyCharm is awesome, I love it! But I'll never understand why they've disabled emulating a terminal by default... If you do use PyCharm's output console, please enable this on all your Run Configurations:,I even recommend you go into , > , > ,, select ,, and also enable it there, so any new ones you create will already have this set.,In addition to that, some terminals report themselves as ""non-interactive"", like when running out of a real terminal (PyCharm and Jupyter for example), in shell pipelines (,), or in background processes (not connected to a tty).,When , finds itself in a non-interactive terminal, it automatically disables all kinds of animations, printing only the final receipt. This is made in order to avoid both messing up the pipeline output and spamming your log file with thousands of , refreshes.,So, when you know it's safe, you can force them to see , in all its glory! Here is the , argument:,The values accepted are:,You can also set it system-wide using ,, so you don't need to pass it manually anymore.,Do note that PyCharm's console and Jupyter notebooks are heavily instrumented and thus have much more overhead, so the outcome may not be as fluid as you would expect. On top of that, Jupyter notebooks do not support ANSI Escape Codes, so I had to develop some workarounds to emulate functions like ""clear the line"" and ""clear from cursor""... To see the fluid and smooth , animations as I intended, always prefer a full-fledged terminal.,Complete ,., will always try to keep up with Python, so starting from version 2.0, I'll drop support for all Python versions which enter EoL. See their schedule ,.,But don't worry if you can't migrate just yet: , versions are perennial, so just keep using the one that works for you and you're good.
,I just strongly recommend setting older , packages in a requirements.txt file with the following formats. These will always fetch the latest build releases previous to a given version, so, if I ever release bug fixes, you'll get them too.,This software is licensed under the MIT License. See the LICENSE file in the top distribution directory for the full license text.,Maintaining an open source project is hard and time-consuming, and I've put much , and effort into this.,If you've appreciated my work, you can back me up with a donation! Thank you ,
,
      A new kind of Progress Bar, with real-time throughput, ETA, and very cool animations!
    "
name,content
lit,"The LLVM Project is a collection of modular and reusable compiler and
   toolchain technologies.  Despite its name, LLVM has little to do with
   traditional virtual machines.  The name
   ""LLVM"" itself is not an acronym; it is the full name of the project.,LLVM began as a , at
   the ,, with
   the goal of providing a modern, SSA-based compilation strategy capable
   of supporting both static and dynamic compilation of arbitrary
   programming languages.  Since then, LLVM has
   grown to be an umbrella project consisting of a number of
   subprojects, many of which are being used in production by a wide variety of
   , projects
   as well as being widely used in ,.  Code
   in the LLVM project is licensed under the
   ,
   ,The primary sub-projects of LLVM are:,The , libraries provide a modern source- and
    target-independent ,, along with
    , for many
    popular CPUs (as well as some less common ones!) These libraries are built
    around a , code representation
    known as the LLVM intermediate representation (""LLVM IR"").  The LLVM Core
    libraries are ,, and it is particularly
    easy to invent your own language (or port an existing compiler) to use
    ,., is an ""LLVM native""
    C/C++/Objective-C compiler, which aims to deliver amazingly fast compiles,
    extremely useful , and to provide a platform for building great
    source level tools.
    The , and
    , are
    tools that automatically find bugs in your code, and are great examples of the
    sort of tools that can be built using the Clang frontend as a library to
    parse C/C++ code.,The , project builds on
    libraries provided by LLVM and Clang to provide a great native debugger.
    It uses the Clang ASTs and expression parser, LLVM JIT, LLVM disassembler,
    etc so that it provides an experience that ""just works"".  It is also
    blazing fast and much more memory efficient than GDB at loading symbols.
    ,The , and
    , projects provide
    a standard conformant and high-performance implementation of the C++
    Standard Library, including full support for C++11 and C++14.,The , project
    provides highly tuned implementations of the low-level code generator
    support routines like "","" and other calls generated when
    a target doesn't have a short sequence of native instructions to implement
    a core IR operation. It also provides implementations of run-time libraries
    for dynamic testing tools such as
    ,,
    ,,
    ,,
    and
    ,.
    ,The , subproject is a novel
    approach to building reusable and extensible compiler infrastructure. MLIR
    aims to address software fragmentation, improve compilation for heterogeneous
    hardware, significantly reduce the cost of building domain specific compilers,
    and aid in connecting existing compilers together.
    ,The , subproject
    provides an , runtime for use with the
    OpenMP implementation in Clang.,The , project implements
    a suite of cache-locality optimizations as well as auto-parallelism and
    vectorization using a polyhedral model.,The , project aims to
    implement the OpenCL standard library.,The , project implements a
    ""symbolic virtual machine"" which uses a theorem prover to try to evaluate
    all dynamic paths through a program in an effort to find bugs and to prove
    properties of functions.  A major feature of klee is that it can produce a
    testcase in the event that it detects a bug.,The , project is a new
    linker. That is a drop-in replacement for system linkers
    and runs much faster.,The ,
    project is a post-link optimizer. It achieves the improvements by optimizing
    application's code layout based on execution profile gathered by sampling
    profiler.,In addition to official subprojects of LLVM, there are a broad variety of
other projects that ,.  Through these external projects you can use
LLVM to compile Ruby, Python, Haskell, Rust, D, PHP, Pure, Lua, Julia, and a number of
other languages. A major strength of LLVM is its versatility, flexibility, and
reusability, which is why it is being used for such a wide variety of different
tasks: everything from doing light-weight JIT compiles of embedded languages
like Lua to compiling Fortran code for massive super computers.,As much as everything else, LLVM has a broad and friendly community of people
who are interested in building great low-level tools.  If you are interested in
,, a
good first place is to skim the , and join ,.  For information on how to send in a patch, get commit access, and
copyright and license topics, please see ,.
,: LLVM 16.0.6 is now ,!  LLVM is publicly available under an open source ,.  Also, you might want to
  check out , in Git that will appear in the next LLVM release.  If
  you want them early, , through
  anonymous Git.,
, - LLVM Dev Mtg,
,LLVM has been awarded the ,!
     This award is given by ACM to , software system worldwide
   every year.
   ,
     LLVM is ,!
     Click on any of the individual recipients' names on that page for
     the detailed citation describing the award.
  ,Upcoming:,Proceedings from past meetings:"
name,content
invoke,"Welcome to Invoke!, , , , ,Invoke is a Python (2.7 and 3.4+) library for managing shell-oriented
subprocesses and organizing executable Python code into CLI-invokable tasks. It
draws inspiration from various sources (,/,, Fabric 1.x, etc) to
arrive at a powerful & clean feature set.,To find out what’s new in this version of Invoke, please see ,.,The project maintainer keeps a , on his website.,This website covers project information for Invoke such as the changelog,
contribution guidelines, development roadmap, news/blog, and so forth.
Detailed usage and API documentation can be found at our code documentation
site, ,.,Please see below for a high level intro, or the navigation on the left for the
rest of the site content.,Like Ruby’s Rake tool and Invoke’s own predecessor Fabric 1.x, it provides a
clean, high level API for running shell commands and defining/organizing
task functions from a , file:,From GNU Make, it inherits an emphasis on minimal boilerplate for common
patterns and the ability to run multiple tasks in a single invocation:,Where Fabric 1.x considered the command-line approach the default mode of
use, Invoke (and tools built on it) are equally at home embedded in your own
Python code or a REPL:,Following the lead of most Unix CLI applications, it offers a traditional
flag-based style of command-line parsing, deriving flag names and value types
from task signatures (optionally, of course!):,Like many of its predecessors, it offers advanced features as well –
namespacing, task aliasing, before/after hooks, parallel execution and more.,Pythonic task execution,
,
,
Professionally-supported Invoke is available with the
,.
"
name,content
nvidia-cudnn-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
decorator,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,micheles/decorator,Name already in use,Decorators for Humans,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        decorator
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,The goal of the decorator module is to make it easy to define
signature-preserving function decorators and decorator factories.
It also includes an implementation of multiple dispatch and other niceties
(please check the docs). It is released under a two-clauses
BSD license, i.e. basically you can do whatever you want with it but I am not
responsible.,If you are lazy, just perform,which will install just the module on your system.,If you prefer to install the full distribution from source, including
the documentation, clone the , or download the ,, unpack it and run,in the main directory, possibly as superuser.,If you have the source code installation you can run the tests with,or (if you have setuptools installed),Notice that you may run into trouble if in your system there
is an older version of the decorator module; in such a case remove the
old version. It is safe even to copy the module decorator.py over
an existing one, since we kept backward-compatibility for a long time.,The project is hosted on GitHub. You can look at the source here:,The documentation has been moved to ,From there you can get a PDF version by simply using the print
functionality of your browser.,Here is the documentation for previous versions of the module:,
,
,
,
,Here is an example of how to define a family of decorators tracing slow
operations:,Enjoy!,
      decorator
    "
name,content
Flask,"Flask,Flask is a lightweight , web application framework. It is designed
to make getting started quick and easy, with the ability to scale up to
complex applications. It began as a simple wrapper around ,
and , and has become one of the most popular Python web
application frameworks.,Flask offers suggestions, but doesn't enforce any dependencies or
project layout. It is up to the developer to choose the tools and
libraries they want to use. There are many extensions provided by the
community that make adding new functionality easy.,
          ,
        
        , ,
        , ,
        , ,
      "
name,content
Flask-Migrate,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,miguelgrinberg/Flask-Migrate,Name already in use,Flask-Migrate,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        SQLAlchemy database migrations for Flask applications using Alembic
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Flask-Migrate is an extension that handles SQLAlchemy database migrations for Flask applications using Alembic. The database operations are provided as command-line arguments under the , command.,Install Flask-Migrate with ,:,This is an example application that handles database migrations through Flask-Migrate:,With the above application you can create the database or enable migrations if the database already exists with the following command:,Note that the , environment variable must be set according to the Flask documentation for this command to work. This will add a , folder to your application. The contents of this folder need to be added to version control along with your other source files.,You can then generate an initial migration:,The migration script needs to be reviewed and edited, as Alembic currently does not detect every change you make to your models. In particular, Alembic is currently unable to detect indexes. Once finalized, the migration script also needs to be added to version control.,Then you can apply the migration to the database:,Then each time the database models change repeat the , and , commands.,To sync the database in another system just refresh the , folder from source control and run the , command.,To see all the commands that are available run this command:,
      SQLAlchemy database migrations for Flask applications using Alembic
    "
name,content
jaraco.classes,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jaraco/jaraco.classes,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,."
name,content
lockfile,"Platform-,independent file locking module for Python,
              ,
            ,
              ,
                is the current focus of development.
              
            ,
          
           
             pylockfile
             does not have any download files registered with Launchpad.
           
        "
name,content
hupper,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Pylons/hupper,Name already in use,hupper,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        in-process file monitor / reloader for reloading your code automatically during development
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is an integrated process monitor that will track changes to
any imported Python files in , as well as custom paths. When
files are changed the process is restarted.,Hupper can load any Python code similar to , by using the
, program.,Start by defining an entry point for your process. This must be an importable
path in string format. For example, ,., is inspired by initial work done by Carl J Meyer and David Glick
during a Pycon sprint and is built to be a more robust and generic version of
Ian Bicking's excellent PasteScript , and Pyramid's
,.,
      in-process file monitor / reloader for reloading your code automatically during development
    "
name,content
isort,"Home,
,
,
,
,
,
,
,
,
, - ,isort your imports, so you don't have to.,isort is a Python utility / library to sort imports alphabetically, and
automatically separated into sections and by type. It provides a command line
utility, Python library and , to
quickly sort all your imports. It requires Python 3.7+ to run but
supports formatting Python 2 code too.,Before isort:,After isort:,Installing isort is as simple as:,Install isort with requirements.txt support:,Install isort with Pipfile support:,Install isort with both formats support:,:,To run on specific files:,To apply recursively:,If ,
is enabled, , is equivalent to:,To view proposed changes without applying them:,Finally, to atomically run isort against a project, only applying
changes if they don't introduce syntax errors:,(Note: this is disabled by default, as it prevents isort from
running against code written using a different version of Python.),:,or:,Several plugins have been written that enable to use isort from within a
variety of text-editors. You can find a full list of them ,.
Additionally, I will enthusiastically accept pull requests that include
plugins for other text editors and add documentation for them as I am
notified.,You will notice above the \""multi_line_output\"" setting. This setting
defines how from imports wrap when they extend past the line_length
limit and has ,.,To change the how constant indents appear - simply change the
indent property with the following accepted formats:,For example:,is equivalent to 4.,For the import styles that use parentheses, you can control whether or
not to include a trailing comma after the last import with the
, option (defaults to ,).,As of isort 3.1.0 support for balanced multi-line imports has been
added. With this enabled isort will dynamically change the import length
to the one that produces the most balanced grid, while staying below the
maximum import length defined.,Example:,Will be produced instead of:,To enable this set , to , in your config or pass
the , option into the command line utility.,isort provides configuration options to change almost every aspect of how
imports are organized, ordered, or grouped together in sections., for an overview of all these options.,To make isort ignore a single import simply add a comment at the end of
the import line containing the text ,:,or:,To make isort skip an entire file simply add , to the
module's doc string:,isort can be ran or configured to add / remove imports automatically.,isort can also be used to verify that code is correctly formatted
by running it with ,. Any files that contain incorrectly sorted
and/or formatted imports will be outputted to ,.,One great place this can be used is with a pre-commit git hook, such as
this one by \@acdha:,This can help to ensure a certain level of code quality throughout a
project.,isort provides a hook function that can be integrated into your Git
pre-commit script to check Python code before committing.,Upon installation, isort enables a , command that checks
Python files declared by your project.,Place this badge at the top of your repository to let others know your project uses isort.,For README.md:,Or README.rst:,To report a security vulnerability, please use the ,. Tidelift will coordinate the
fix and disclosure.,isort simply stands for import sort. It was originally called
""sortImports"" however I got tired of typing the extra characters and
came to the realization camelCase is not pythonic.,I wrote isort because in an organization I used to work in the manager
came in one day and decided all code must have alphabetically sorted
imports. The code base was huge - and he meant for us to do it by hand.
However, being a programmer - I\'m too lazy to spend 8 hours mindlessly
performing a function, but not too lazy to spend 16 hours automating it.
I was given permission to open source sortImports and here we are :),Professional support for isort is available as part of the ,.
Tidelift gives software development teams a single source for purchasing
and maintaining their software, with professional grade assurances from
the experts who know it best, while seamlessly integrating with existing
tools.,Thanks and I hope you find isort useful!,~Timothy Crosley"
name,content
chardet,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,chardet/chardet,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python character encoding detector
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Note,Our ISO-8859-2 and windows-1250 (Hungarian) probers have been temporarily
disabled until we can retrain the models.,Requires Python 3.7+.,Install from ,:,For users, docs are now available at ,.,chardet comes with a command-line script which reports on the encodings of one
or more files:,This is a continuation of Mark Pilgrim's excellent original chardet port from C, and ,'s
, Python 3-compatible fork.,
      Python character encoding detector
    "
name,content
click,"Click,Click is a Python package for creating beautiful command line interfaces
in a composable way with as little code as necessary. It's the ""Command
Line Interface Creation Kit"". It's highly configurable but comes with
sensible defaults out of the box.,It aims to make the process of writing command line tools quick and fun
while also preventing any frustration caused by the inability to
implement an intended CLI API.,Click in three points:,
          ,
        
        , ,
        , ,
        , ,
      "
name,content
djoser,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,sunscrapers/djoser,Name already in use,djoser,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        REST implementation of Django authentication system.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,REST implementation of , authentication
system. , library provides a set of ,
views to handle basic actions such as registration, login, logout, password
reset and account activation. It works with
,.,Instead of reusing Django code (e.g. ,), we reimplemented
few things to fit better into ,
architecture.,Developed by , with passion & patience.,To be able to run , you have to meet the following requirements:,Simply install using ,:,And continue with the steps described at
,
guide.,Documentation is available to study at
,
and in , directory.,To start developing on ,, clone the repository:,We use , as dependency management and packaging tool.,This will create a virtualenv with all development dependencies.,To run the test just type:,We also prepared a convenient , to automate commands above:,To activate the virtual environment run,New versions of , can use , to build the package and install its dependencies.,You can also play with test project by running following commands:,Before sending patches please make sure you have , activated in your local git repository:,This will ensure that your code is cleaned before you commit it.,List of projects related to Django, REST and authentication:,Please, keep in mind that while using custom authentication and TokenCreateSerializer
validation, there is a path that , from authenticate()
and try to find User using parameters. Probably, that will be changed in the future.,
      REST implementation of Django authentication system.
    "
name,content
os-service-types,"Welcome to os-service-types’s documentation!,Welcome to os-service-types’s documentation!,Indices and tables,Contents:,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Openstack.org is powered by
          ,.
        "
name,content
aiosignal,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,aio-libs/aiosignal,Name already in use,aiosignal,frozen,gitter chat,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        aiosignal: a list of registered asynchronous callbacks
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A project to manage callbacks in asyncio projects., is a list of registered asynchronous callbacks.,The signal's life-cycle has two stages: after creation its content
could be filled by using standard list operations: ,
etc.,After you call , the signal is ,: adding, removing
and dropping callbacks is forbidden.,The only available operation is calling the previously registered
callbacks by using ,.,For concrete usage examples see the Signals
<,>
section of the `Web Server Advanced
<,> chapter of the ,.,The library requires Python 3.8 or newer., , is offered under the Apache 2 license.,The project is hosted on ,Please file an issue in the , if you have found a bug
or have some suggestions to improve the library.,
      aiosignal: a list of registered asynchronous callbacks
    "
name,content
aiopg,"Welcome to AIOPG,asyncio,like,optional,autocommit mode,sqlalchemy,aio-libs, is a library for accessing a , database
from the , (PEP-3156/tulip) framework. It wraps
asynchronous features of the Psycopg database driver.,Current version is 1.4.0.,Warning,Removing await the before , function,Only supports ,Only support syntax ,Implements , , , interface for
,.  It includes ,,
, and , objects.,Implements , support for charming ,
functional sql layer.,The library uses , connections in , mode
internally.,Literally it is an (almost) transparent wrapper for psycopg2-binary
connection and cursor, but with only exception.,You should use , instead of just call , for
every method.,Properties are unchanged, so , is correct as well as
,.,See example:,For documentation about connection and cursor methods/properties
please go to psycopg docs: ,Note,psycopg2-binary creates new connections with ,
option in asynchronous mode. Autocommitting cannot be disabled.,See , about transaction usage
in ,., provides core support for , connections.,We have found it to be very annoying to write raw SQL queries manually,
so we introduce support for , query builders:,We believe constructions like , and
, to be very handy and
convenient.,Note, requires , library.,You can use global environment or you use like to use virtual environments
(,, , or ,) you
probably have to install , development package,Also you probably want to use ,., module is , and requires
,. You can install , by running,The project is hosted on ,Please feel free to file an issue on , if you have found a bug
or have some suggestion for library improvement.,The library uses , for
Continious Integration., google group: ,Feel free to post your questions and ideas here.,Python 3.6+,psycopg2-binary,aiopg.sa requires ,.,The , package is written by Andrew Svetlov.  It’s BSD
licensed and freely available.,Feel free to improve this package and send a pull request to ,.,Contents:,
  ,
,aiopg - Postgres integration with asyncio,
,
"
name,content
MechanicalSoup,"Welcome to MechanicalSoup’s documentation!,Indices and tables,A Python library for automating interaction with websites. MechanicalSoup automatically stores and sends cookies, follows redirects, and can follow links and submit forms. It doesn’t do Javascript.,MechanicalSoup was created by ,, who was a fond user of the
, library.
Unfortunately, Mechanize is , and its development
stalled for several years. MechanicalSoup provides a similar API, built on Python
giants , (for
http sessions) and , (for document
navigation). Since 2017 it is a project actively maintained by a small
team including , and ,.,Contents:,
        © Copyright 2014-2023
      
        ,
      

    "
name,content
nvidia-cusparse-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
click-plugins,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,click-contrib/click-plugins,Name already in use,click-plugins,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Register CLI commands via setuptools entry-points.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,An extension module for , to register
external CLI commands via setuptools entry-points.,Lets say you develop a commandline interface and someone requests a new feature
that is absolutely related to your project but would have negative consequences
like additional dependencies, major refactoring, or maybe its just too domain
specific to be supported directly.  Rather than developing a separate standalone
utility you could offer up a ,
that allows others to use your commandline utility as a home for their related
sub-commands.  You get to choose where these sub-commands or sub-groups CAN be
registered but the plugin developer gets to choose they ARE registered.  You
could have all plugins register alongside the core commands, in a special
sub-group, across multiple sub-groups, or some combination.,For a more detailed example see the , section.,The only requirement is decorating , with ,
which handles attaching external commands and groups.  In this case the core CLI developer
registers CLI plugins from ,.,Plugin developers need to register their sub-commands or sub-groups to an
entry-point in their , that is loaded by the core package.,Any sub-command or sub-group that cannot be loaded is caught and converted to
a , rather than just crashing the entire
CLI.  The short-help is converted to a warning message like:,and if the sub-command or group is executed the entire traceback is printed.,Opening a CLI to plugins encourages other developers to independently extend
functionality independently but there is no guarantee these new features will
be ""on brand"".  Plugin developers are almost certainly already using features
in the core package the CLI belongs to so defining commonly used arguments and
options in one place lets plugin developers reuse these flags to produce a more
cohesive CLI.  If the CLI is simple maybe just define them at the top of
, or for more complex packages something like
,.  These common options need to be easy to find
and be well documented so that plugin developers know what variable to give to
their sub-command's function and what object they can expect to receive.  Don't
forget to document non-obvious callbacks.,Keep in mind that plugin developers also have access to the parent group's
,, which is very useful for passing things like verbosity levels or
config values around to sub-commands.,Here's some code that sub-commands could re-use:,Plugin developers can access this with:,With ,:,From source:,See ,See ,See ,
      Register CLI commands via setuptools entry-points.
    "
name,content
csvkit,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,wireservice/csvkit,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A suite of utilities for converting to and working with CSV, the king of tabular file formats.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,csvkit is a suite of command-line tools for converting to and working with CSV, the king of tabular file formats.,It is inspired by pdftk, GDAL and the original csvcut tool by Joe Germuska and Aaron Bycoffe.,Important links:,
      A suite of utilities for converting to and working with CSV, the king of tabular file formats.
    "
name,content
jeepney,"
jeepney
,

,Pure Python DBus interface"
name,content
coverage,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,nedbat/coveragepy,Name already in use,Coverage.py,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        The code coverage tool for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Code coverage testing for Python.,Coverage.py measures code coverage, typically during test execution. It uses
the code analysis tools and tracing hooks provided in the Python standard
library to determine which lines are executable, and which have been executed.,Coverage.py runs on these versions of Python:,Documentation is on ,.  Code repository and issue tracker are on
,.,
improved data combining;
, setting;
,;
type annotations.,
dropped support for Python 2.7, 3.5, and 3.6;
write data on SIGTERM;
added support for 3.10 match/case statements.,Looking to run , on your test suite? See the ,
of the docs.,The complete history of changes is on the ,.,Everyone participating in the coverage.py project is expected to treat other
people with respect and to follow the guidelines articulated in the ,.,Found a bug? Want to help improve the code or documentation? See the
, of the docs.,To report a security vulnerability, please use the ,.  Tidelift will coordinate the fix and disclosure.,Licensed under the ,.  For details, see ,.,
      The code coverage tool for Python
    "
name,content
litecli,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,dbcli/litecli,Name already in use,litecli,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        CLI for SQLite Databases with auto-completion and syntax highlighting
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A command-line client for SQLite databases that has auto-completion and syntax highlighting.,
,If you already know how to install python packages, then you can install it via pip:,You might need sudo on linux.,The package is also available on Arch Linux through AUR in two versions: , is based the latest release (git tag) and , is based on the master branch of the git repo. You can install them manually or with an AUR helper such as ,:,or,For MacOS users, you can also use Homebrew to install it:,A config file is automatically created at , at first launch. For Windows machines a config file is created at , at first launch. See the file itself for a description of all available options.,Visit: ,
      CLI for SQLite Databases with auto-completion and syntax highlighting
    "
name,content
MarkupSafe,"MarkupSafe,MarkupSafe implements a text object that escapes characters so it is safe to use in HTML and XML. Characters that have special meanings are replaced so that they display as the actual characters. This mitigates injection attacks, meaning untrusted user input can safely be displayed on a page. Escaping is implemented in C so it is as efficient as possible.,
          ,
        
        , ,
        , ,
        , ,
      "
name,content
asgiref,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,django/asgiref,Name already in use,asgiref,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        ASGI specification and utilities
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,ASGI is a standard for Python asynchronous web apps and servers to communicate
with each other, and positioned as an asynchronous successor to WSGI. You can
read more at ,This package includes ASGI base libraries, such as:,These allow you to wrap or decorate async or sync functions to call them from
the other style (so you can call async functions from a synchronous thread,
or vice-versa).,In particular:,The idea is to make it easier to call synchronous APIs from async code and
asynchronous APIs from synchronous code so it's easier to transition code from
one style to the other. In the case of Channels, we wrap the (synchronous)
Django view system with SyncToAsync to allow it to run inside the (asynchronous)
ASGI server.,Note that exactly what threads things run in is very specific, and aimed to
keep maximum compatibility with old synchronous code. See
""Synchronous code & Threads"" below for a full explanation. By default,
, will run all synchronous code in the program in the same
thread for safety reasons; you can disable this for more performance with
,, but make sure that your code does
not rely on anything bound to threads (like database connections) when you do.,This is a drop-in replacement for , that works with both
threads and asyncio Tasks. Even better, it will proxy values through from a
task-local context to a thread-local context when you use ,
to run things in a threadpool, and vice-versa for ,.,If you instead want true thread- and task-safety, you can set
, on the Local object to ensure this instead.,Includes a , class which provides all the hard work of
writing a stateless server (as in, does not handle direct incoming sockets
but instead consumes external streams or sockets to work out what is happening).,An example of such a server would be a chatbot server that connects out to
a central chat server and provides a ""connection scope"" per user chatting to
it. There's only one actual connection, but the server has to separate things
into several scopes for easier writing of the code.,You can see an example of this being used in ,.,Allows you to wrap a WSGI application so it appears as a valid ASGI application.,Simply wrap it around your WSGI application like so:,The WSGI application will be run in a synchronous threadpool, and the wrapped
ASGI application will be one that accepts , class messages.,Please note that not all extended features of WSGI may be supported (such as
file handles for incoming POST bodies)., requires Python 3.7 or higher.,Please refer to the
,.,To run tests, make sure you have installed the , extra with the package:,The documentation uses ,:,To build the docs, you can use the default tools:,...or you can use , to run a server and rebuild/reload
your documentation changes automatically:,To release, first add details to CHANGELOG.txt and update the version number in ,.,Then, build and push the packages:,The , module provides two wrappers that let you go between
asynchronous and synchronous code at will, while taking care of the rough edges
for you.,Unfortunately, the rough edges are numerous, and the code has to work especially
hard to keep things in the same thread as much as possible. Notably, the
restrictions we are working with are:,The first compromise you get to might be that , code should
just run in the same thread and not spawn in a sub-thread, fulfilling the first
restriction, but that immediately runs you into the second restriction.,The only real solution is to essentially have a variant of ThreadPoolExecutor
that executes any , code on the outermost synchronous
thread - either the main thread, or a single spawned subthread.,This means you now have two basic states:,Crucially, this means that in both cases there is a thread which is a shared
resource that all , code must run on, and there is a chance
that this thread is currently blocked on its own , call. Thus,
, needs to act as an executor for thread code while it's blocking.,The , class provides this functionality; rather than
simply waiting on a Future, you can call its , method and
it will run submitted code until that Future is done. This means that code
inside the call can then run code on your thread.,To report security issues, please contact ,. For GPG
signatures and more security process information, see
,.,To report bugs or request new features, please open a new GitHub issue.,This repository is part of the Channels project. For the shepherd and maintenance team, please see the
,.,
      ASGI specification and utilities
    "
name,content
isodate,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,gweis/isodate,Name already in use,ISO 8601 date/time parser,date,time,datetime,timedelta,date,datetime,time,date,datetime,timedelta,Duration,tzinfo,timedelta,Duration,timedelta,Duration,timedelta,xxx_isoformat,datetime.isoformat,hh:mm:ssZ,yyyy-mm-dd,yyyy-mm-ddThh:mm:ssZ,PnnYnnMnnDTnnHnnMnnS,hh:mm,strftime,datetime,Duration,python setup.py install,setuptools,distribute,easy_install,Duration,timedelta,setup.py,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        ISO 8601 date/time parser
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This module implements ISO 8601 date, time and duration parsing.
The implementation follows ISO8601:2004 standard, and implements only
date/time representations mentioned in the standard. If something is not
mentioned there, then it is treated as non existent, and not as an allowed
option.,For instance, ISO8601:2004 never mentions 2 digit years. So, it is not
intended by this module to support 2 digit years. (while it may still
be valid as ISO date, because it is not explicitly forbidden.)
Another example is, when no time zone information is given for a time,
then it should be interpreted as local time, and not UTC.,As this module maps ISO 8601 dates/times to standard Python data types, like
,, ,, , and ,, it is not possible to convert
all possible ISO 8601 dates/times. For instance, dates before 0001-01-01 are
not allowed by the Python , and , classes. Additionally
fractional seconds are limited to microseconds. That means if the parser finds
for instance nanoseconds it will round it to microseconds.,As ISO 8601 allows to define durations in years and months, and ,
does not handle years and months, this module provides a , class,
which can be used almost like a , object (with some limitations).
However, a , object can be converted into a , object.,There are also ISO formatting methods for all supported data types. Each
, method accepts a format parameter. The default format is
always the ISO 8601 expanded format. This is the same format used by
,:,This module can easily be installed with Python standard installation methods.,Either use , or in case you have , or
, available, you can also use ,.,The doc strings and unit tests should provide rather detailed information about
the methods and their limitations.,The source release provides a , script,
which can be used to run the unit tests included.,Source code is available at ,.,
      ISO 8601 date/time parser
    "
name,content
lexicon,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,bitprophet/lexicon,Name already in use,use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Powerful Python dict subclass(es) providing aliasing & attribute access
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , , ,Lexicon is a simple collection of Python , subclasses providing extra
power:,, a dictionary supporting both simple and complex key aliasing:,, supporting attribute read & write access, e.g. , exhibits , and ,.,, a subclass of both of the above which exhibits both sets of
behavior.,If you have a clone of the source repository, you can run the tests like so:,In all examples, , is the alias and , is the ""real"",
unaliased key.,: Alias , to , so
, behaves exactly like , for both reads and
writes.,: Alias , to
both , and ,. As you might expect, this only works
well for writes, as there is never any guarantee that all targets of the
alias will contain the same value.,: Removes the , alias; any subsequent
reads/writes to , will behave as normal for a regular ,., (aka ,): Returns True when given an alias,
so if , is an alias to some other key, dictionary membership tests
will behave as if , is set., (aka ,): This effectively becomes , -- to remove the alias itself, use ,.,: Deletes the real key/value pair (i.e. it calls
,) but doesn't touch any aliases pointing to ,.,Caveats:,Because of the single-key/multi-key duality, , is incapable of
honoring non-string-type keys when aliasing (it must test , to tell strings apart from non-string iterables).,Lexicon subclasses from , first, then ,, with the
end result that attribute access will honor aliases. E.g.:,
      Powerful Python dict subclass(es) providing aliasing & attribute access
    "
name,content
fqdn,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,ypcrts/fqdn,Name already in use,Python FQDN Fully-Qualified Domain Names,fascinating,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        RFC-compliant FQDN validation and manipulation for Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , ,
, , ,This package validates Fully Qualified Domain Names (FQDNs) conforming to the
Internet Engineering Task Force specification ,. The design intent is to
validate that a string would be traditionally acceptable as a public Internet
hostname to RFC-conforming software, which is a strict subset of the logic in
modern web browsers like Mozilla Firefox and Chromium that determines whether
make a DNS lookup ,. Configuration options can relax constraints
so that short hostnames without periods or others with underscores will
be valid. These relaxations are closer to how modern web browsers work , .,Equality checks are implemented case insensitive conforming to to the IETF
specification [#equality].,In the default configuration, this package adds only one additional constraint
to the IETF specification, requiring a minimum of two labels, separated by
periods. This extra restriction can be disabled. It is enabled by default to
prevent breaking backwards compatibility. Review the tests for examples of the
impact of this.,The IETF specification restricts domain names to alphanumeric ASCII characters
and hyphens as described below.,: Requirements for Internet
Hosts - Application and Support, October 1989,2.1  Host Names and Numbers,The syntax of a legal Internet host name was specified in RFC-952
[DNS:4].  One aspect of host name syntax is hereby changed: the
restriction on the first character is relaxed to allow either a
letter or a digit.  Host software MUST support this more liberal
syntax.,Host software MUST handle host names of up to 63 characters and
SHOULD handle host names of up to 255 characters.,Whenever a user inputs the identity of an Internet host, it SHOULD
be possible to enter either (1) a host domain name or (2) an IP
address in dotted-decimal (""#.#.#.#"") form.  The host SHOULD check
the string syntactically for a dotted-decimal number before
looking it up in the Domain Name System.,: DoD Internet host table
specification, October 1985,: Domain Name Concepts and
Facilities, November 1987,Section 3.5 specifies a ""preferred name syntax"", which is non-compulsory.,3.5. Preferred name syntax,The DNS specifications attempt to be as general as possible in the rules
for constructing domain names.  The idea is that the name of any
existing object can be expressed as a domain name with minimal changes.
However, when assigning a domain name for an object, the prudent user
will select a name which satisfies both the rules of the domain system
and any existing rules for the object, whether these rules are published
or implied by existing programs.,For example, when naming a mail domain, the user should satisfy both the
rules of this memo and those in RFC-822.  When creating a new host name,
the old rules for HOSTS.TXT should be followed.  This avoids problems
when old software is converted to use domain names.,: Domain Names
- Implementation and Specification, November 1987,: Clarification to the DNS
Specification, July 1997,: Application Techniques for
Checking and Transformation of Names, February 2004,
      RFC-compliant FQDN validation and manipulation for Python.
    "
name,content
nose,"nose,Note to Users,Installation and quick start,Python3,Documentation,On most UNIX-like systems, you’ll probably need to run these commands as root
or using sudo.,nose extends unittest to make testing easier.,Nose has been in maintenance mode for the past several years and will likely
cease without a new person/team to take over maintainership.  New projects
should consider using ,, ,, or just plain unittest/unittest2.,Install nose using setuptools/distribute:,Or pip:,Or, if you don’t have setuptools/distribute installed, use the download
link at right to download the source package, and install it in the
normal fashion: Ungzip and untar the source package, cd to the new
directory, and:,However, , that without setuptools/distribute installed,
you will not be able to use third-party nose plugins.,This will install the nose libraries, as well as the ,
script, which you can use to automatically discover and run tests.,Now you can run tests for your project:,You should see output something like this:,Indicating that nose found and ran your tests.,For help with nosetests’ many command-line options, try:,or visit the ,.,nose supports python3. Building from source on python3 requires
,. If you don’t
have distribute installed, , will install
it via distribute’s bootstrap script.,Additionally, if your project is using ,, ,
command will automatically convert your sources with 2to3 and then run the
tests with python 3.,Warning,nose itself supports python 3, but many 3rd-party plugins do not!,Find out how to write, find and run tests using nose.,
      ,Find out how to write your own plugins, and about nose
        internals., ,What's new in this release?,
        ,Plugin recipes and usage examples, trivia and other
        uncategorizable items.,
        "
name,content
nvidia-nccl-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
about-time,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,rsalmei/about-time,Name already in use,about-time,s,ms,µs,ns,k,M,G,T,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A cool helper for tracking time and throughput of code blocks, with beautiful human friendly renditions.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,
,Did you ever need to measure the duration of an operation? Yeah, this is easy.,But how to:,Yes, it can get tricky! More interesting details about , and ,.
,If you'd tried to do it without these magic, it would probably get messy and immensely pollute the code being instrumented.,I have the solution, behold!,This , function prints:,How cool is that? ,You can also get the duration in seconds if needed:,But , is way better, isn't it? The same with , and ,!,So, , measures code blocks, both time and throughput, and converts them to beautiful human friendly representations! ,Just install with pip:,There are three modes of operation: context manager, callable and throughput. Let's dive in.,This way you can nicely wrap any amount of code.,In this mode, there are the basic fields , and ,.,This way you have a nice one liner, and do not need to increase the indent of your code.,In this mode, there is an additional field ,, with the return of the callable.,If the callable have params, you can use a , or (, new) simply send them:,This way , also extracts the number of iterations, and with the measured duration it calculates the throughput of the whole loop! It's especially useful with generators, which do not have length.,In this mode, there are the additional fields ,, ,, , and ,.,Cool tricks under the hood:,According to the SI standard, there are 1000 bytes in a ,.
,There is another standard called IEC that has 1024 bytes in a ,, but this is only useful when measuring things that are naturally a power of two, e.g. a stick of RAM.,Be careful to not render IEC quantities with SI scaling, which would be incorrect. But I still support it, if you really want to ;),By default, this will use SI, , divisor, and , between values and scales/units. SI uses prefixes: ,, ,, ,, ,, ,, ,, ,, and ,.,These are the optional features:,To change them, just use the properties:,For example, to enable spaces between scales/units:,I've used just one key concept in designing the human duration features: cleanliness., is more meaningful than ,, and , is much nicer than ,.,So what I do is: round values to at most two decimal places (three significant digits), and find the best scale unit to represent them, minimizing resulting values smaller than ,. The search for the best unit considers even the rounding been applied!, does not end up as , (truncate) nor , (bad unit), but is auto-upgraded to the next unit ,!,The , units change seamlessly from nanoseconds to hours.,It feels much more humane, humm? ;),Some examples:,I've made the , with a similar logic. It is funny how much trickier ""throughput"" is to the human brain!,If something took , to handle ,, how fast did it go? It's not obvious...,It doesn't help even if we divide the duration by the number of items, ,, which still does not mean much. How fast was that? We can't say.
,How many items did we do per time unit?,Oh, we just need to invert it, so ,, there it is! 😂,To make some sense of it we need to multiply that by 3600 (seconds in an hour) to get ,, which is much better, and again by 24 (hours in a day) to finally get ,!! Now we know how fast that process was! \o/ As you see, it's not easy at all.,The , unit changes seamlessly from per-second, per-minute, per-hour, and per-day.
,It also automatically inserts SI-prefixes, like k, M, and G. , supports all versions of python, but in pythons >= , it performs even better, with much higher resolution and smaller propagation of errors, thanks to the new ,. In older versions, it uses , as usual.,This software is licensed under the MIT License. See the LICENSE file in the top distribution directory for the full license text.,Maintaining an open source project is hard and time-consuming, and I've put much , and effort into this.,If you've appreciated my work, you can back me up with a donation! Thank you ,
,
      A cool helper for tracking time and throughput of code blocks, with beautiful human friendly renditions.
    "
name,content
playsound,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,TaylorSMarks/playsound,Name already in use,playsound,Pure Python, cross platform, single function module with no dependencies for playing sounds.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Pure Python, cross platform, single function module with no dependencies for playing sounds.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Install via pip:,Done.,If you insist on the (slightly) harder way of installing, from source,
you know how to do it already and don't need my help.,The latest version of the source code can be found at:
,Once you've installed, you can really quickly verified that it works with just this:,The playsound module contains only one thing - the function (also named) playsound.,It requires one argument - the path to the file with the sound you'd like to play. This may be a local file, or a URL.,There's an optional second argument, block, which is set to True by default. Setting it to False makes the function run asynchronously.,On Windows, uses windll.winmm. WAVE and MP3 have been tested and are known to work. Other file formats may work as well.,On OS X, uses AppKit.NSSound. WAVE and MP3 have been tested and are known to work. In general, anything QuickTime can play, playsound should be able to play, for OS X.,On Linux, uses GStreamer. Known to work on Ubuntu 14.04 and ElementaryOS Loki. I expect any Linux distro with a standard gnome desktop experience should work.,If you'd like other Linux distros (or any other OS) to work, submit a PR adding in support for it, but please make sure it passes the tests (see below).,Playsound includes a small set of tests - if you're making a PR, please ensure that you have no regressions and all the tests pass on your local system.
Also make sure that Travis-CI, which runs these tests against Windows Server 2016, macOS 10.11 (El Capitan, 2015) and 11.3 (Big Sur, 2020), Ubuntu 14 (Trusty), and Ubuntu 18 (Bionic), for both Python 2.7 and 3.9, fully passes.
You can check the Travis-CI status for Playsound here: ,This software is Copyright (c) 2021 Taylor Marks <,>.,See the bundled LICENSE file for more information.,
      Pure Python, cross platform, single function module with no dependencies for playing sounds.
    "
name,content
goose3,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,goose3/goose3,Name already in use,Goose3 - Article Extractor,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A Python 3 compatible version of goose ,
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Goose was originally an article extractor written in Java that has most
recently (Aug2011) been converted to a ,.,This is a complete rewrite in Python. The aim of the software is to
take any news article or article-type web page and not only extract what
is the main body of the article but also all meta data and most probable
image candidate.,Goose will try to extract the following information:,The Python version was originally rewritten by:,If you find Goose useful or have issues please drop me a line. I'd love
to hear how you're using it or what features should be improved.,Goose is licensed by Gravity.com under the Apache 2.0 license; see the
LICENSE file for more details.,On-line documentation is available on
, which contains more in-depth
documentation.,To install using pip, with all supported languages, which will install additional dependencies:,To install the minimal version:,To install just the dependencies for a single language:,To install from source:,There are two ways to pass configuration to goose. The first one is to
pass goose a Configuration() object. The second one is to pass a
configuration dict.,For instance, if you want to change the userAgent used by Goose just
pass:,Switching parsers: Goose can now be used with lxml html parser or lxml
soup parser. By default the html parser is used. If you want to use the
soup parser pass it in the configuration dict :,One can also set Goose to be more lenient on network exceptions. To turn off
throwing all network exceptions, set the strict configuration setting to false:,To turn on image fetching, one can simply enable it using the enable_image_fetching
configuration property:,For example, scraping a Spanish content page with correct meta language
tags:,Some pages don't have correct meta language tags, you can force it using
configuration :,Passing {'use_meta_language': False, 'target_language':'es'} will
forcibly select Spanish.,Some users want to use Goose for Chinese content. Chinese word
segmentation is way more difficult to deal with than occidental
languages. Chinese needs a dedicated StopWord analyser that need to be
passed to the config object.,In order to use Goose in Arabic you have to use the StopWordsArabic
class.,In order to use Goose in Korean you have to use the StopWordsKorean
class.,
      A Python 3 compatible version of goose ,
    "
name,content
nvidia-cuda-nvrtc-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
autocommand,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Lucretiel/autocommand,Name already in use,autocommand,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Autocommand turns a python function into a CLI program
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,A library to automatically generate and run simple argparse parsers from function signatures.,Autocommand is installed via pip:,Autocommand turns a function into a command-line program. It converts the function's parameter signature into command-line arguments, and automatically runs the function if the module was called as ,. In effect, it lets your create a smart main function.,As you can see, autocommand converts the signature of the function into an argument spec. When you run the file as a program, autocommand collects the command-line arguments and turns them into function arguments. The function is executed with these arguments, and then the program exits with the return value of the function, via ,. Autocommand also automatically creates a usage message, which can be invoked with , or ,, and automatically prints an error message when provided with invalid arguments.,You can use a type annotation to give an argument a type. Any type (or in fact any callable) that returns an object when given a string argument can be used, though there are a few special cases that are described later.,Autocommand will catch , raised by the type during argument parsing, so you can supply a callable and do some basic argument validation as well.,You can add a , parameter to your function to give it trailing arguments. The command will collect 0 or more trailing arguments and supply them to , as a tuple. If a type annotation is supplied, the type is applied to each argument.,To create , switches, just assign a default. Autocommand will automatically create , and ,hort switches.,The option's type is automatically deduced from the default, unless one is explicitly given in an annotation:,If an option is given a default value of ,, it reads in a value as normal, but supplies , if the option isn't provided.,If an argument is given a default value of , or ,, or
given an explicit , type, it becomes an option switch.,Autocommand attempts to do the ""correct thing"" in these cases- if the default is ,, then supplying the switch makes the argument ,; if the type is , and the default is some other , value, then supplying the switch makes the argument ,, while not supplying the switch makes the argument the default value.,Autocommand also supports the creation of switch inverters. Pass , to , to enable this.,Using the , version of a switch will pass the opposite value in as a function argument. If multiple switches are present, the last one takes precedence.,If the default value is a file object, such as ,, then autocommand just looks for a string, for a file path. It doesn't do any special checking on the string, though (such as checking if the file exists); it's better to let the client decide how to handle errors in this case. Instead, it provides a special context manager called ,, which behaves exactly like , if a filename or other openable type is provided, but also lets you use already open files:,The , decorator accepts , and , kwargs, corresponding to the ,_ and ,_ of the ,. If no description is given, but the decorated function has a docstring, then it is taken as the , for the ,. You can also provide both the description and epilog in the docstring by splitting it into two sections with 4 or more - characters.,You can also attach description text to individual parameters in the annotation. To attach both a type and a description, supply them both in any order in a tuple,Autocommand automatically follows wrapper chains created by ,. This means that you can apply other wrapping decorators to your main function, and autocommand will still correctly detect the signature.,Even though autocommand is being applied to the , returned by ,, it still retreives the signature of the underlying , function to create the argument parsing.,While autocommand's automatic parser generator is a powerful convenience, it doesn't cover all of the different features that argparse provides. If you need these features, you can provide your own parser as a kwarg to ,:,Any parser should work fine, so long as each of the parser's arguments has a corresponding parameter in the decorated main function. The order of parameters doesn't matter, as long as they are all present. Note that when using a custom parser, autocommand doesn't modify the parser or the retrieved arguments. This means that no description/epilog will be added, and the function's type annotations and defaults (if present) will be ignored.,The decorated function is only called and exited from if the first argument to , is , or ,. If it is neither of these values, or no argument is given, then a new main function is created by the decorator. This function has the signature ,, and is intended to be called with arguments as if via ,. The function has the attributes , and ,, which are the generated , and the original main function that was decorated. This is to facilitate testing and library use of your main. Calling the function triggers a , with the supplied arguments, and returns the result of the main function. Note that, while it returns instead of calling ,, the , function will raise a , in the event of a parsing error or , argument.,If the function is called with no arguments, , is used. This is to allow the autocommand function to be used as a setuptools entry point.,There are a few possible exceptions that , can raise. All of them derive from ,.,There are a few argparse features that are not supported by autocommand.,Autocommand cannot be important from the project root; this is to enforce separation of concerns and prevent accidental importing of , or tests. To develop, install the project in editable mode:,This will create a link to the source files in the deployment directory, so that any source changes are reflected when it is imported.,
      Autocommand turns a python function into a CLI program
    "
name,content
newspaper3k,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,codelucas/newspaper,Name already in use,Newspaper3k: Article scraping & curation,seamlessly,entire,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        News, full-text, and article metadata extraction in Python 3. Advanced docs:
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Inspired by , for its simplicity and powered by , for its speed:,""Newspaper is an amazing python library for extracting & curating articles.""
-- , Kenneth Reitz, Author of ,""Newspaper delivers Instapaper style article extraction."" -- ,! Or, view our , ,Newspaper can extract and detect languages ,.
If no language is specified, Newspaper will attempt to auto detect a language.,If you are certain that an , news source is in one language, ,Check out , for full and detailed guides using newspaper.,Interested in adding a new language for us? Refer to: ,Run , , ,NOT , , ⛔,On python3 you must install ,, , ,. , is our python2 library.
Although installing newspaper is simple with ,, you will
run into fixable issues if you are trying to install on ubuntu.,, install using the following:,Install , command needed to install , package:,Python development version, needed for Python.h:,lxml requirements:,For PIL to recognize .jpg images:,NOTE: If you find problem installing ,, try installing ,.,Download NLP related corpora:,Install the distribution via pip:,, install using the following, you may use both homebrew or macports:,, install with the following:,NOTE: You will still most likely need to install the following libraries via your package manager,Your donations are greatly appreciated! They will free me up to work on this project more,
to take on things like: adding new features, bug-fix support, addressing concerns with the library.,If you'd like to contribute and hack on the newspaper project, feel free to clone
a development version of this repository locally:,Once you have a copy of the source, you can embed it in your Python package,
or install it into your site-packages easily:,Feel free to give our testing suite a shot, everything is mocked!:,Planning on tweaking our full-text algorithm? Add the , parameter:,View a working online demo here: ,This is another working online demo: ,Authored and maintained by ,., sponsored some work on newspaper, specifically focused on
automatic extraction.,Newspaper uses a lot of , parsing code. View their license ,.,Please feel free to , if you run into issues or just would like
to talk about the future of this library and news extraction in general!,
      News, full-text, and article metadata extraction in Python 3. Advanced docs:
    "
name,content
hyperframe,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-hyper/hyperframe,Name already in use,hyperframe: Pure-Python HTTP/2 framing,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Pure-Python HTTP/2 framing
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This library contains the HTTP/2 framing code used in the , project. It
provides a pure-Python codebase that is capable of decoding a binary stream
into HTTP/2 frames.,This library is used directly by , and a number of other projects to
provide HTTP/2 frame decoding logic.,hyperframe welcomes contributions from anyone! Unlike many other projects we
are happy to accept cosmetic contributions and small contributions, in addition
to large feature requests and changes.,Before you contribute (either by opening an issue or filing a pull request),
please ,.,hyperframe is made available under the MIT License. For more details, see the
, file in the repository.,hyperframe is maintained by Cory Benfield, with contributions from others. For
more details about the contributors, please see ,.,
      Pure-Python HTTP/2 framing
    "
name,content
CT3,"Cheetah3, the Python-Powered Template Engine,Cheetah3 is a free and , template engine and
code-generation tool written in ,. Cheetah can be
used unto itself, or incorporated with other technologies and stacks regardless
of whether they’re written in Python or not.,At its core, Cheetah is a domain-specific language for markup generation and
templating which allows for full integration with existing Python code but also
offers extensions to traditional Python syntax to allow for easier text-generation.,It’s a fork of the ,
CheetahTemplate library.,You can get involved and talk with Cheetah developers on the ,.,Below is a simple example of some Cheetah code, as you can see it’s practically
Python. You can import, inherit and define methods just like in a regular Python
module, since that’s what your Cheetah templates are compiled to :)"
name,content
fonttools,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,fonttools/fonttools,Name already in use,Extra:,Extra:,Extra:,Extra:,Extra:,Extra:,Extra:,Extra:,Extra:,Extra:,Extra:,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A library to manipulate font files from Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , , and
,
are available at ,.,FontTools requires , 3.8
or later. We try to follow the same schedule of minimum Python version support as
NumPy (see ,).,The package is listed in the Python Package Index (PyPI), so you can
install it with ,:,If you would like to contribute to its development, you can clone the
repository from GitHub, install the package in 'editable' mode and
modify the source code in place. We recommend creating a virtual
environment, using , or
Python 3 , module.,The , package currently has no (required) external dependencies
besides the modules included in the Python Standard Library.
However, a few extra dependencies are required by some of its modules, which
are needed to unlock optional features.
The , PyPI distribution also supports so-called ""extras"", i.e. a
set of keywords that describe a group of additional dependencies, which can be
used when installing via pip, or when specifying a requirement.
For example:,This command will install fonttools, as well as the optional dependencies that
are required to unlock the extra features named ""ufo"", etc.,The module exports a ElementTree-like API for reading/writing XML files, and
allows to use as the backend either the built-in , module or
,. The latter is preferred whenever present,
as it is generally faster and more secure., ,Package for reading and writing UFO source files; it requires:, ,Module to compress/decompress WOFF 2.0 web fonts; it requires:, ,To better compress WOFF 1.0 web fonts, the following module can be used
instead of the built-in , library:, ,To display the Unicode character names when dumping the , table
with , we use the , module in the Standard Library.
The version included in there varies between different Python versions.
To use the latest available data, you can install:, ,Module for finding wrong contour/component order between different masters.
It requires one of the following packages in order to solve the so-called
""minimum weight perfect matching problem in bipartite graphs"", or
the Assignment problem:, ,Module for visualizing DesignSpaceDocument and resulting VariationModel., ,Advanced module for symbolic font statistics analysis; it requires:, ,To get the file creator and type of Macintosh PostScript Type 1 fonts
on Python 3 you need to install the following module, as the old ,
module is no longer included in Mac Python:, ,Simplify TrueType glyphs by merging overlapping contours and components., , and ,Pens for drawing glyphs with Cocoa , or , require:,Pen for drawing glyphs with Qt's ,, requires:,Pen to drawing glyphs as PNG images, requires:,Pen to drawing glyphs with FreeType as raster images, requires:,Use the Harfbuzz library to serialize GPOS/GSUB using , method, requires:, ,In alphabetical order:,aschmitz, Olivier Berten, Samyak Bhuta, Erik van Blokland, Petr van Blokland,
Jelle Bosma, Sascha Brawer, Tom Byrer, Antonio Cavedoni, Frédéric
Coiffier, Vincent Connare, David Corbett, Simon Cozens, Dave Crossland,
Simon Daniels, Peter Dekkers, Behdad Esfahbod, Behnam Esfahbod, Hannes
Famira, Sam Fishman, Matt Fontaine, Takaaki Fuji, Yannis Haralambous, Greg
Hitchcock, Jeremie Hornus, Khaled Hosny, John Hudson, Denis Moyogo Jacquerye,
Jack Jansen, Tom Kacvinsky, Jens Kutilek, Antoine Leca, Werner Lemberg, Tal
Leming, Peter Lofting, Cosimo Lupo, Olli Meier, Masaya Nakamura, Dave Opstad,
Laurence Penney, Roozbeh Pournader, Garret Rieger, Read Roberts, Colin Rofls,
Guido van Rossum, Just van Rossum, Andreas Seidel, Georg Seifert, Chris
Simpkins, Miguel Sousa, Adam Twardoch, Adrien Tétar, Vitaly Volkov,
Paul Wise.,Copyright (c) 2000 BeOpen.com. All Rights Reserved.,Copyright (c) 1995-2001 Corporation for National Research Initiatives.
All Rights Reserved.,Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam. All
Rights Reserved.,Have fun!,
      A library to manipulate font files from Python.
    "
name,content
dbus-python,"best,This page lists implementations and language bindings for the D-Bus protocol, their status and, if appropriate, links to download them. ,GDBus is part of GNOME's GLib library, since version 2.26+. Language bindings are available via GObject-Introspection. It is an implementation of the D-Bus protocol (not a binding).,QtDBus is part of Qt, and is a higher-level binding for libdbus. Various language bindings for QtDBus are available.,Eldbus is part of Enlightenment's EFL. It is a binding for libdbus.,If you use this low-level API directly, you're signing up for some pain. —official API documentation,libdbus is part of dbus, and is the reference implementation of the D-Bus protocol. This does not make it the , implementation of D-Bus, and for most purposes it isn't the best available. Its maintainers recommend using GDBus, sd-bus or QtDBus instead.,sd-bus is part of libsystemd, and is an implementation of the D-Bus protocol (not a binding).,If you implement a new C++ library for D-Bus, please call it something more distinctive than /dbus-c(p|x|plus|+)\1/, otherwise everyone will mix it up with the existing libraries.,dbus-cxx is a sigc++ binding for libdbus.,dbus-cpp is a header-only C++11 binding for libdbus.,Also known as dbus-cplusplus, this is a C++ binding for libdbus. It appears to be inactive (latest release 2011) and is not recommended. Various forks exist; please list any actively-maintained forks here if you know of them.,A C++17 binding for systemd's sd-bus., is a modern, pythonic D-Bus library built on top of PyGI and GDBus., is a another modern python library for D-Bus.,GDBus, the D-Bus implementation in GLib, can be used from Python 2 or 3 via ,.,QtDBus, the D-Bus implementation in Qt, can be used from Python 2 or 3 via recent versions of ,., is a native Python implementation of the D-Bus protocol for the Twisted networking framework. , is a pure Python D-Bus module.
It consists of an IO-free core implementing the protocol, and integrations
for both blocking I/O and for different asynchronous frameworks., is the most popular Ruby D-Bus library. It is an implementation of the D-Bus protocol (not a binding).,Rust implementation, based on Serde.,libdbus-based binding.,dbus-sharp is an implementation of the D-Bus protocol (not a binding).,FreePascal has dbus package included.,Gambas has gb.dbus package included.,Since version 2.0 it has been a complete native implementation of the protocol and not a wrapper around the reference implementation. 1.x versions are feature-complete bindings around the reference implementation.,Java D-Bus is hosted in freedesktop.org's ,., ,The last release binding the reference implementation is ,. (2006-12-26),Documentation and API reference for the Java implementation of D-Bus is ,.,The Maintainer is Matthew Johnson < , > ,dbus-glib is an old GLib binding for libdbus. ,dbus-python is a binding for libdbus, the reference implementation of D-Bus. For compatibility reasons, its API involves a lot of type-guessing (despite ""explicit is better than implicit"" and ""resist the temptation to guess""). "
name,content
cssselect,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,scrapy/cssselect,Name already in use,cssselect: CSS Selectors for Python,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        CSS Selectors for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a BSD-licensed Python library to parse , and
translate them to , expressions., expressions can be used in , or another XPath engine to find
the matching elements in an XML or HTML document.,Find the cssselect online documentation at ,.,Quick facts:,
      CSS Selectors for Python
    "
name,content
loguru,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Delgan/loguru,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python logging made (stupidly) simple
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
    ,
,
    ,
    ,
    ,
    ,
    ,
    ,
    ,
,
    ,
, is a library which aims to bring enjoyable logging in Python.,Did you ever feel lazy about configuring a logger and used , instead?... I did, yet logging is fundamental to every application and eases the process of debugging. Using , you have no excuse not to use logging from the start, this is as simple as ,.,Also, this library is intended to make Python logging less painful by adding a bunch of useful functionalities that solve caveats of the standard loggers. Using logs in your application should be an automatism, , tries to make it both pleasant and powerful.,The main concept of Loguru is that , ,.,For convenience, it is pre-configured and outputs to , to begin with (but that's entirely configurable).,The , is just an interface which dispatches log messages to configured handlers. Simple, right?,How to add a handler? How to set up logs formatting? How to filter messages? How to set level?,One answer: the , function.,This function should be used to register , which are responsible for managing , contextualized with a ,. A sink can take many forms: a simple function, a string path, a file-like object, a coroutine function or a built-in Handler.,Note that you may also , a previously added handler by using the identifier returned while adding it. This is particularly useful if you want to supersede the default , handler: just call , to make a fresh start.,If you want to send logged messages to a file, you just have to use a string path as the sink. It can be automatically timed too for convenience:,It is also , if you need rotating logger, if you want to remove older logs, or if you wish to compress your files at closure.,Loguru favors the much more elegant and powerful , formatting over ,, logging functions are actually equivalent to ,.,Have you ever seen your program crashing unexpectedly without seeing anything in the log file? Did you ever notice that exceptions occurring in threads were not logged? This can be solved using the , decorator / context manager which ensures that any error is correctly propagated to the ,.,Loguru automatically adds colors to your logs if your terminal is compatible. You can define your favorite style by using , in the sink format.,All sinks added to the , are thread-safe by default. They are not multiprocess-safe, but you can , the messages to ensure logs integrity. This same argument can also be used if you want async logging.,Coroutine functions used as sinks are also supported and should be awaited with ,.,Logging exceptions that occur in your code is important to track bugs, but it's quite useless if you don't know why it failed. Loguru helps you identify problems by allowing the entire stack trace to be displayed, including values of variables (thanks , for this!).,The code:,Would result in:,Note that this feature won't work on default Python REPL due to unavailable frame data.,Want your logs to be serialized for easier parsing or to pass them around? Using the , argument, each log message will be converted to a JSON string before being sent to the configured sink.,Using , you can contextualize your logger messages by modifying the extra record attribute.,It is possible to modify a context-local state temporarily with ,:,You can also have more fine-grained control over your logs by combining , and ,:,Finally, the , method allows dynamic values to be attached to the record dict of each new message:,Sometime you would like to log verbose information without performance penalty in production, you can use the , method to achieve this.,Loguru comes with all standard , to which , and , are added. Do you need more? Then, just create it by using the , function.,The standard logging is bloated with arguments like , or ,, , and ,, naive datetimes without timezone information, not intuitive formatting, etc. Loguru ,:,Using the logger in your scripts is easy, and you can , it at start. To use Loguru from inside a library, remember to never call , but use , instead so logging functions become no-op. If a developer wishes to see your library's logs, they can , it again.,For additional convenience, you can also use the , library to setup the , directly from a configuration file.,Wish to use built-in logging , as a Loguru sink?,Need to propagate Loguru messages to standard logging?,Want to intercept standard logging messages toward your Loguru sinks?,Don't like the default logger formatting? Would prefer another , color? ,:,It is often useful to extract specific information from generated logs, this is why Loguru provides a , method which helps to deal with logs and regexes.,Loguru can easily be combined with the great , library (must be installed separately) to receive an e-mail when your program fail unexpectedly or to send many other kind of notifications.,Although logging impact on performances is in most cases negligible, a zero-cost logger would allow to use it anywhere without much concern. In an upcoming release, Loguru's critical functions will be implemented in C for maximum speed.,
      Python logging made (stupidly) simple
    "
name,content
gevent,"What is gevent?,sleep,gevent is a , -based , networking library that uses
, to provide a high-level synchronous API on top of the ,
or , event loop.,Features include:,Fast event loop based on , or ,.,Lightweight execution units based on greenlets.,API that re-uses concepts from the Python standard library (for
examples there are , and
,)., performed through a threadpool,
dnspython, or c-ares., to get 3rd party modules to become cooperative,TCP/UDP/HTTP servers,Subprocess support (through ,),Thread pools,gevent is , but features a more consistent API,
simpler implementation and better performance. Read why others , and check out the list of the ,.,gevent was written by ,.,Since version 1.1, gevent is maintained by Jason Madden for
, (through gevent 21) and
,
with help from the , and is
licensed under the MIT license.,See , in the latest major release.,Check out the detailed , for this version., »"
name,content
columnize,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,rocky/pycolumnize,Name already in use,colsep,displaywidth,arrange_vertical,ljust,arrange_array,True,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python module to align a simple (not nested) list in columns. Adapted from the routine of the same name inside cmd.py
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., ,In showing a long lists, sometimes one would prefer to see the value
arranged aligned in columns. Some examples include listing methods of an
object, listing debugger commands, or showing a numeric array with data
aligned.,This is a Python module to format a simple (i.e. not nested) list into
aligned columns. A string with embedded newline characters is returned.,Each column is only as wide as necessary. By default, columns are
separated by two spaces; one was not legible enough. Set , to
adjust the string separate columns. Set , to set the line
width.,Normally, consecutive items go down from the top to bottom from the
left-most column to the right-most. If , is set false,
consecutive items will go across, left to right, top to bottom.,By default entries are left justified:,but you can change that with , or if , is set to
,:,This module (essentially one function) was adapted from a private method
of the same name from Python's
, module. Some
adjustments and generalizations have been made.,Available as part of the Tidelift Subscription.,The maintainers of pycolumnize and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. ,To report a security vulnerability, please use the , and Tidelift will coordinate the fix and disclosure.,Authors: Rocky Bernstein ,License: MIT,
      Python module to align a simple (not nested) list in columns. Adapted from the routine of the same name inside cmd.py
    "
name,content
icecream,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,gruns/icecream,Name already in use,
  ,
,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        , Never use print() to debug again.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
  ,
  ,
  ,
  ,
,Do you ever use , or , to debug your code? Of course you
do. IceCream, or , for short, makes print debugging a little sweeter., is like ,, but better:,IceCream is well tested, ,, and
supports Python 2, Python 3, PyPy2, and PyPy3.,Have you ever printed variables or expressions to debug your program? If
you've ever typed something like,or the more thorough,then , will put a smile on your face. With arguments, ,
inspects itself and prints both its own arguments and the values of
those arguments.,Prints,Similarly,,Prints,Just give , a variable or expression and you're done. Easy.,Have you ever used , to determine which parts of your program are
executed, and in which order they're executed? For example, if you've ever added
print statements to debug code like,then , helps here, too. Without arguments, , inspects itself and
prints the calling filename, line number, and parent function.,Prints,Just call , and you're done. Simple., returns its argument(s), so , can easily be inserted into
pre-existing code., is like , but the output is returned as a string instead
of written to stderr.,Additionally, ,'s output can be entirely disabled, and later re-enabled, with
, and , respectively.,Prints, continues to return its arguments when disabled, of course; no existing
code with , breaks.,To make , available in every file without needing to be imported in
every file, you can , it. For example, in a root ,:,and then in ,, which is imported by ,, just call ,:, adds , to the
, module,
which is shared amongst all files imported by the interpreter.
Similarly, , can later be ,ed, too., can also be imported in a manner that fails gracefully if
IceCream isn't installed, like in production environments (i.e. not
development). To that end, this fallback import snippet may prove
useful:, controls ,'s output.,, if provided, adopts a custom output prefix. , can be a
string, like,or a function.,'s default value is ,.,, if provided, is called once for every , call with
,'s output, as a string, instead of that string being written to
stderr (the default).,, if provided, is called with argument values to be
serialized to displayable strings. The default is PrettyPrint's
,,
but this can be changed to, for example, handle non-standard datatypes
in a custom fashion.,The default , is ,, and
has methods to , and , functions to be dispatched
for specific classes using ,. It also has a
, property to view registered functions.,, if provided and True, adds the , call's filename,
line number, and parent function to ,'s output., is False by default.,, if provided and True, outputs absolute filepaths, like
,, over just filenames, like ,, when , is
called with ,. This is useful when debugging
multiple files that share the same filename(s). Moreover, some editors,
like VSCode, turn absolute filepaths into clickable links that open the
file where , was called., is False by default.,Installing IceCream with pip is easy., uses ,
by , to reliably locate
, calls in Python source. It's magic.,Delicious IceCream should be enjoyed in every language.,If you'd like a similar , function in your favorite language, please open a
pull request! IceCream's goal is to sweeten print debugging with a handy-dandy
, function in every language.,
      , Never use print() to debug again.
    "
name,content
Cython,"About Cython,🌷️ Your donation can help the Cython project! 🌷️️,Documentation,Download,People,Useful Links,
, is an , for both the
, programming
language and the extended Cython programming language (based on ,).
It makes writing C extensions for Python as easy as Python itself.
,
,
,
The Cython language is a superset of the , language that
additionally supports calling , and declaring
, on variables and class attributes.  This allows the
compiler to generate very , from Cython code.
The C code is , and then compiles with all major
C/C++ compilers in , 2.6, 2.7 (2.4+
with Cython 0.20.x) as well as 3.5 and all later versions.
We regularly run integration tests against all supported CPython versions and
their latest in-development branches to make sure that the generated code stays
widely compatible and well adapted to each version.
, support is work in progress (on both sides)
and is considered ,
since Cython 0.17.  The latest PyPy version is always recommended here.
,
All of this makes Cython the ideal language for ,
external C libraries, , CPython into existing
applications, and for , that speed up the
execution of Python code.
,
  ,
  ,,
  and keeping it up to speed with the Python ecosystem and the changing requirements
  of its diverse user bases, ,.
  To support the maintenance and
  ,,
  , can sponsor the work of , via:
,
  Note that PayPal takes 5 - 15% fees for small non-EUR payments,
  which is money that you pay without helping us.
  Consider signing up for a GitHub Sponsors subscription instead.
,
,
,External resources:
,
If you still have questions, feel free to send an email to the
,.
Aspects of the core development are discussed on the
,
mailing list.  If you are unsure which list to use, the cython users list is probably the right one to use, which has the larger audience.
There is also a , channel on the freenode IRC servers for Cython related chats.
,
,
Cython is freely available under the , ,.
,The , of Cython is 3.0.0 (released 2023-07-17).
Cython is available from the , ,.
,Christoph Gohlke has created Windows installers available for download on
,.
,
,
,:
,,
,,
David Woods,
Matúš Valo,
Lisandro Dalcín
,:
Marc Abramowitz,
Wichert Akkerman,
Martin Albrecht,
Peter Alexander,
Francesc Alted,
Ivan Andrus,
Arfrever Frehtes Taifersar Arahesis,
Philip Austin,
Josh Ayers,
Haoyu Bai,
Grant Baillie,
Nicolas Barbey,
Gustavo Barbieri,
David Barnett,
Andrea Bedini,
Brian Bishop,
Chuck Blake,
Alexey Borzenkov,
Georg Brandl,
Nils Braun,
Erik Bray,
Matthew Brett,
Nils Bruin,
Matthias Bussonnier,
Lars Buitinck,
Vladimir Cerny,
Ondrej Certik,
Shalabh Chaturvedi,
Eric Chlebek,
David Christenson,
Craig Citro,
Timothy Clemans,
Bryan Cole,
Favian Contreras,
Dave Cournapeau,
Andreas van Cranenburgh,
Antonio Cuni,
Armon Dadgar,
Julien Danjou,
Jeroen Demeyer,
Eric Dill,
Nicolas Dumazet,
Ali Ebrahim,
John Ehresman,
Michael Enßlin,
Jason Evans,
Isuru Fernando,
Eric Firing,
Mark Florisson,
Claudio Freire,
Danilo Freitas,
Bradley Froehle,
Gary Furnish,
Syam Gadde,
Martín Gaitán,
Gabriel Gellner,
Christoph Gohlke,
Evgeny Golyshev,
Brian Granger,
Olivier Grisel,
Christoph Groth,
Jason Grout,
Romain Guillebert,
Adrien Guinet,
Valentin Haenel,
Yaroslav Halchenko,
Richard Hansen,
Kay Hayen,
Ian Henriksen,
Philip Herron,
Magnus Lie Hetland,
David Hirschfeld,
Jiajun Huang,
Thomas Hunger,
Eric Huss,
Naoki Inada,
Joe Jevnik,
Omer Katz,
Karl Kempe,
Rafe Kettler,
Jerome Kieffer,
W. Trevor King,
Jim Kleckner,
Ronan Lamy,
Torsten Landschoff,
Chris Lasher,
Sergei Lebedev,
Antony Lee,
Björn Linse,
Mark Lodato,
Thomas Lotze,
Vitja Makarov,
Angus McMorland,
David McNab,
Jason Madden,
Syrtis Major,
Yesudeep Mangalapilly,
Tadeu Manoel,
Vasil Manolov,
Gabriel de Marmiesse,
Sturla Molden,
Mansour Moufid,
Nikita Nemkin,
David Nogueira,
Andrew Ohana,
Jay Oster,
Olivier Parcollet,
Brent Pedersen,
Mark Peek,
Chris Perkins,
Gabriel Pettier,
Emmanuel Gil Peyrot,
Matti Picus,
Antoine Pitrou,
Andrey Plotnikov,
Paul Prescod,
Prabhu Ramachandran,
Jeff Ramnani,
Holger Rapp,
Nikolaus Rath,
Peinthor Rene,
Armin Rigo,
Joon Ro,
Fabian Rost,
Ralf Schmitt,
Michael Seifert,
Dag Sverre Seljebotn.
Corbin Simpson,
Kirill Smelkov,
Ivan Smirnov,
Kurt Smith,
Nathaniel Smith,
William Stein,
Andrew Straw,
Boxiang Sun,
Arfrever Taifersar Arahesis,
Dimitri Tcaciuc,
Gregor Thalhammer,
Kevin R. Thornton,
Peter Todd,
Erik Tollerud,
David Vierra,
Petr Viktorin,
Mathieu Virbel,
Pauli Virtanen,
Jakub Wilk,
Carl Witty,
Felix Wu,
Yury Zaytsev,
Jelle Zijlstra.
,:
, and , funded Dag Seljebotn to greatly improve
,.
Kurt Smith and Danilo Freitas were funded through the , program to work on improved Fortran and C++ support respectively,
and in 2010 Haoyu Bai was funded to work on ,.
,
to Greg Ewing for inventing and developing Cython's predecessor
,
and for his valuable input in language design decisions.
,
,
,What users have to say about Cython:,»You would expect a whole lot of organizations and people to fancy a
language that's about as high-level as Python, yet almost as fast and
down-to-the-metal as C.,Add to that the ability to seamlessly integrate with both
your existing C/++ codebase and your Python codebase, easily mix very
high level abstractions with very low-level machine access... clear
winner.« →
, on c.l.py
,»You guys rock!
In scikit-learn, we have decided early on to do Cython, rather than C or
C++. That decision has been a clear win because the code is way more
maintainable. We have had to convince new contributors that Cython was
better for them, but the readability of the code, and the capacity to
support multiple Python versions, was worth it.« →
,
,»The biggest surprise (and of course this is Cython's selling
point) is how simple the interfacing between high level and low level
code becomes, and the fact that it is all very robust.,It's exiciting to see that there are several active projects around
that attempt to speed up Python.  The nice thing about Cython is that
it doesn't give you ""half the speed of C"" or ""maybe nearly the speed
of C, 3 years from now"" -- it gives the real deal, -O3 C, and it works
right now.« →
,
,»SciPy is approximately 50% Python, 25% Fortran, 20% C, 3% Cython
and 2% C++ … The distribution of secondary programming languages in SciPy
is a compromise between a powerful, performance-enhancing language that
interacts well with Python (that is, Cython) and the usage of languages
(and their libraries) that have proven reliable and performant over many
decades.,For implementing new functionality, Python is still the language
of choice. If Python performance is an issue, then we prefer the use of
Cython followed by C, C++ or Fortran (in that order). The main motivation
for this is maintainability: Cython has the highest abstraction level, and
most Python developers will understand it. C is also widely known, and
easier for the current core development team to manage than C++ and
especially Fortran.« →
,
,»Not to mention that the generated C often makes use of
performance tricks that are too tedious or arcane to write by hand,
partially motivated by scientific computing’s constant push.  And
through all that, Cython code maintains a high level of integration
with Python itself, right down to the stack trace and line numbers.,PayPal has certainly benefitted from their efforts through
high-performance Cython users like gevent, lxml, and NumPy.  While our
first go with Cython didn’t stick in 2011, since 2015, all native
extensions have been written and rewritten to use Cython.«
→
,
,
»I'm honestly never going back to writing C again. Cython gives
me all the expressiveness of Python combined with all the performance
and close-to-the-metal-godlike-powers of C. I've been using it to
implement high-performance graph traversal and routing algorithms and
to interface with C/C++ libraries, and it's been an absolute amazing
productivity boost.« →
,
,»A general rule of thumb is that your program spends 80% of
its time running 20% of the code.  Thus a good strategy for efficient
coding is to write everything, profile your code, and optimize the
parts that need it.  Python’s profilers are great, and Cython allows
you to do the latter step with minimal effort.« →
,
,»The question was, in auto-generated code, to what extent there
were bugs there, to what extent there were bugs in the generators.  The
first time I did this, I got lots and lots of warnings from the tool for
code generated by both SWIG and Cython [...],Basically, everything I found Cython emitting was a false positive and
a bug in my checker tool [CPyChecker].« →
,
,
»Basically, Cython is about 7x times faster than Boost.Python, which
astonished me.« →
,
,
,
»Using Cython allows you to just put effort into speeding up the
parts of code you need to work on, and to do so without having to
change very much.  This is vastly different from ditching all the code
and reimplementing it another language.  It also requires you to learn
a pretty minimal amount of stuff.  You also get to keep the niceness of
the Python syntax which may Python coders have come to
appreciate.« →
,
,
»If you have a piece of Python that you need to run fast, then I
would recommend you used Cython immediately. This means that I can
exploit the beauty of Python and the speed of C together, and that’s a
match made in heaven.« →
,
,»From 85 seconds (at the beginning of this post) down to 0.8
seconds: a reduction by a factor of 100 ...thank you cython!
:-)« →
,
,
»Writing a full-on CPython module from scratch would probably
offer better performance than Cython if you know the quirks and are
disciplined. But to someone who doesn't already drip CPython C
modules, Cython is a godsend.
,Ultimately, there's 5 commonly used ways (CPython [C-API],
Boost::Python, SWIG, Cython, ctypes) to integrate C into Python, and
right now you'd be crazy not to give Cython a shot, if that's your
need. It's very easy to learn for anyone familiar with both C and
Python.« →
,
,»What I loved about the Cython code is that I use a Python
list to manage the Vortex objects. This shows that we can use the
normal Python containers to manage objects. This is extremely
convenient. [...],Clearly, if you are building code from scratch and need speed,
Cython is an excellent option. For this I really must congratulate the
Cython and Pyrex developers.« →
,
,»I wrote a script that compute a distance matrix (O^2) in
Python with Numpy arrays and the same script in Cython. It took me 10
minutes to figure it out how Cython works and I gained a speed up of
550 times !!! Amazing« →
,
,»I would like to report on a successful Cython project.
Successful in the sense that it was much faster than all code written
by my predecessors mainly because the speed scales almost linearly
with the number of cores.  Also, the code is shorter and much easier
to read and maintain. [...],Making it this fast & short & readable & maintainable
would have been pretty hard without Cython.« →
,
,»At work, we’ve started using Cython with excellent success.
We rewrote one particular Perl script as Cython and achieved a 600%
speed improvement.  As a Perl lover, this was impressive.  We still
get all the benefits of Python such as rapid development and clean
object-oriented design patterns but with the speed of C.« →
,
,»The reason that I was interested in Cython was the long
calculation times I encountered while doing a multi-variable
optimization with a function evaluation that involved solving a
differential equation with scipy.integrate.odeint.  By simply
replacing the class that contained the differential equation with a
Cython version the calculation time dropped by a factor 5.  Not bad
for half a Sunday afternoons work.« →
,
,»I was surprised how simple it was to get it working both
under Windows and Linux.  I did not have to mess with make files or
configure the compiles.  Cython integrated well with NumPy and SciPy.
This expands the programming tasks you can do with Python
substantially.« →
,
,»This is why the Scipy folks keep harping about Cython – it’s
rapidly becoming (or has already become) the lingua franca of exposing
legacy libraries to Python.  Their user base has tons of legacy code
or external libraries that they need to interface, and most of the
reason Python has had such a great adoption curve in that space is
because Numpy has made the data portion of that interface easy.
Cython makes the code portion quite painless, as well.« →
,
,»Added an optional step of compiling fastavro with Cython.
Just doing that, with no Cython specific code reduced the time of
processing 10K records from 2.9sec to 1.7sec. Not bad for that little
work.« →
,
,»fastavro compiles the Python code without any specific
Cython code.  This way on machines that do not have a compiler users
can still use fastavro.,The end result is a package that reads Avro faster than Java
and supports both Python 2 and Python 3. Using Cython and a little bit
of work th[is] was achieved without too much effort.« →
,
,»... the binding needed to be rewritten, mainly because the
current binding is directly written in C++ and is a maintenance
nightmare.  This new binding is written in Cython« →
,
,
»
Code generation via Cython allows the production of smaller and more maintainable bindings, including increased compatibility with all supported Python releases without additional burden for NEST developers.
«
,
»
In conclusion, we hope that through a more widespread use of Cython, neuroscientific software developers will be able to focus their creative energy on refining their algorithms and implementing new features, instead of working to pay off the interest on the accumulating technical debt.
« →
,
,
»
The Cython version took about 30 minutes to write, and it runs just as fast as the C code — because, why wouldn’t it? It *is* C code, really, with just some syntactic sugar. And you don’t even have to learn or think about a foreign, complicated C API…You just, write C. Or C++ — although that’s a little more awkward. Both the Cython version and the C version are about 70x faster than the pure Python version, which uses Numpy arrays.
« →
,
,
»
I love this project. Fantastic way to write Python bindings for native libs or speed up computationally intensive code without having to write C yourself.
« →
,
,
»
I use a lot of pyrex/cython to bind to libraries - it's so much faster to code in python. It's been a huge boon. Having used swig, hand writing wrappers, and pyrex before i can say i much prefer cython.
Thank you for the hard work.
« →
,
,
»
I am not good with C so I mostly do pure python for my research. However, now dealing with clusters of 1000+ molecules, there was huge bottlenecks in my code.
,
Using cython it went from running single calculation in hours to seconds, focking nice...
« →
,
,
»
Cython saves you from a great many of the gotchas [that C has].
The worst you'll usually get is a lack of performance gain (at which point cython -a is your friend).
Wringing out all the performance you can get can require a reasonable working knowledge of C -- but you don't have to know it that well to do pretty darn well.
« →
,
,
»
[spaCy is] written in clean but efficient Cython code, which allows us
to manage both low level details and the high-level Python API in a
single codebase.
« →
,
,
»
[uvloop] is written in Cython, and by the way, Cython is just amazing.
It's unfortunate that it's not as wide-spread and I think it's kind-a
underappreciated what you can do in Cython.  Essentially, it's a
superset of the Python language, you can strictly type it and it will
compile to C and you will have C speed.  You can easily achieve it,
with a syntax more similar to Python.  Definitely check out Cython.
« →
,
,
»
300.000 req/sec is a number comparable to Go's built-in web server
(I'm saying this based on a rough test I made some years ago).
Given that Go is designed to do exactly that, this is really impressive.
My kudos to your choice to use Cython.
« →
,
,
»
Cython is one of the best kept secrets of Python. It extends Python
in a direction that addresses many of the shortcomings of the language
and the platform
« →
,
,
,
,
"
name,content
pkginfo,"lp:pkginfo,Prep 1.9.6 release.,Fix various typos in docs / docstrings.,Closes LP #2002232.,Prep 1.9.5 release,Fix markdownisms.,Add stricter mytype checks and fix,Matching the checks used in 'twine'.,Fix typing errors / gaps reported from  CI failure.  LP #2002104.,Fix packaging of stub file for Python typing support.,Prep 1.9.3 release.,Add stub files for Python typing support;  verify using `mypy`.,Closes ,.,Drop Py2-compatibility fossil."
name,content
constantly,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,twisted/constantly,Name already in use,Constantly,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Symbolic Constants in Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A library that provides symbolic constant support.
It includes collections and constants with text, numeric, and bit flag values.
Originally , from the , project.,constantly is available in ,,
and can be installed via pip:,Documentation is available at ,.,To run tests:,This will run tests on Python 2.7, 3.3, 3.4, and PyPy, as well as doing coverage and pyflakes checks.,
      Symbolic Constants in Python
    "
name,content
plaster,"plaster, is a loader interface around arbitrary config file formats. It exists to define a common API for applications to use when they wish to load configuration settings. The library itself does not aim to handle anything except a basic API that applications may use to find and load configuration settings. Any specific constraints should be implemented in a pluggable loader which can be registered via an entrypoint.,The library helps your application find an appropriate loader based on a , and a desired set of , identifiers.,Some possible , formats:,An example application that does not care what file format the settings are sourced from, as long as they are in a section named ,:,This script can support any config format so long as the application (or the user) has installed the loader they expect to use. For example, ,. The loader is then found by , based on the specific , provided. The application does not need to configure the loaders. They are discovered via , and registered for specific schemes., supports custom loader protocols which loaders may choose to implement to provide extra functionality over the basic , interface. A , is intentionally very loosely defined but it basically boils down to a loader object that supports extra methods with agreed-upon signatures. Right now the only officially-supported protocol is , which defines a loader that should implement the , interface., ,File types:,Protocols:,To install plaster, run this command in your terminal:,If you don’t have , installed, this , can guide you through the process.,The sources for plaster can be downloaded from the ,.,Once you have a copy of the source, you can install it with:,A goal of , is to allow a configuration source to be used for multiple purposes. For example, an INI file is split into separate sections which provide settings for separate applications. This works because each application can parse the INI file easily and pull out only the section it cares about. In order to load settings, use the ,.,The application may accept a path to a config file, allowing the user to specify the name of the section (,) to be loaded:,Alternatively, the application may depend on a specifically named section:, requires a , to provide a way to configure Python’s stdlib logging module. In order to utilize this feature, simply call , from your application.,At the heart of , is the , format. This format is basically , with a few variations. The , is used to find an ,.,A , may be a file path or an , URI. In the case of a file path, the file extension is used as the scheme. In either case the scheme and the protocols are the only items that , cares about with respect to finding an ,.,It’s also possible to lookup the exact loader by prefixing the scheme with the name of the package containing the loader:, finds loaders registered for the , entry point in your ,:,In this example the importable , class will be used as , for creating , objects. Each loader is passed a , instance, the result of parsing the , to determine the scheme and fragment.,If the loader should be found automatically via file extension then it should broadcast support for the special , scheme. For example, to support , instead of , the loader should be registered for the , scheme.,This loader may then be used:,By default, loaders are exposed via the , entry point. In order to register a loader that supports a custom protocol it should register itself on a , entry point.,A scheme , point to the same loader factory for every protocol, including the default (empty) protocol. If it does not then no compatible loader will be found if the end-user requests a loader satisfying both protocols.,This API is heavily inspired by conversations, contributions, and design put forth in , and ,."
name,content
docopt,"docopt,is,commands,options,optional,required,mutually exclusive,repeating,usage patterns,in,visibly,word,optional,only,only,not,optional,All elements are required by default,if one element is present,
then another one is required,one,none, helps you:, is based on conventions that have been used for decades in help messages and
man pages for describing a program's interface.  An interface description
in , , such a help message, but formalized.  Here is an example:,The example describes the interface of executable ,, which can be
invoked with different combinations of , (,, ,, ,,
etc.), , (,, ,, ,, etc.)  and positional
arguments (,, ,, ,).,The example uses brackets "","", parens "","", pipes "","" and ellipsis
"","" to
describe ,, ,, ,, and ,
elements.  Together, these elements form valid ,, each starting
with program's name ,.,Below the usage patterns, there is a list of options with descriptions.
They describe whether an option has short/long forms (,, ,), whether
an option has an argument (,), and whether that argument has a
default value (,).,A , implementation will extract all that information and generate a
command-line arguments parser, with the text of the interface description as the
help message shown when the program is invoked with
the , or , options.,Text occuring between keyword , (case-,sensitive) and a ,
empty line is interpreted as list of usage patterns.  The first word after
, is interpreted as the program's name.  Here is a minimal example for
program that takes no command-line arguments:,Program can have several patterns listed with various elements used to
describe the pattern:,Each of the elements and constructs is described below.
We will use the word "","" to describe a sequence of characters delimited
by either whitespace, one of "","" characters, or "","".,Words starting with "","", ending with "","" and upper-case words are
interpreted as positional arguments.,Words starting with one or two dashes (with exception of "","", "",""
by themselves) are interpreted as short (one-letter) or long options,
respectively.,Note, writing , (as opposed to ,) is ambiguous, meaning
it is not possible to tell whether , is option's argument or a positional
argument.  In usage patterns this will be interpreted as an option with argument
, if a description (covered below) for that option is
provided.  Otherwise it will be interpreted as an option and separate
positional argument.,There is the same ambiguity with the , and , notation. In the latter
case it is not possible to tell whether it is a number of stacked short
options, or an option with an argument.  These notations will be interpreted as an
option with argument , if a description for the option is provided.,All other words that do , follow the above conventions of , or
, are interpreted as (sub)commands.,Elements (options, arguments, commands) enclosed with square brackets "",""
are marked to be ,.  It does not matter if elements are enclosed
in the same or different pairs of brackets, for example:,is equivalent to:,, if not included in brackets "","".
However, sometimes it is necessary to mark elements as required explicitly
with parens "","".
For example, when you need to group mutually-exclusive elements (see next
section):,Another use case is when you need to specify that ,, which you can achieve as:,In this case, a valid program invocation could be with either no arguments,
or with 2 arguments.,Mutually-exclusive elements can be separated with a pipe "","" as follows:,Use parens "","" to group elements when , of the mutually exclusive
cases is required.  Use brackets "","" to group elements when , of the
mutually exclusive cases is required:,Note, that specifying several patterns works exactly like pipe "","", that is:,is equivalent to:,Use ellipsis "","" to specify that the argument (or group of arguments)
to the left could be repeated one or more times:,You can flexibly specify the number of arguments that are required.
Here are 3 (redundant) ways of requiring zero or more arguments:,One or more arguments:,Two or more arguments (and so on):,"","" is a shortcut that allows to avoid listing all options
(from list of options with descriptions) in a pattern.  For example:,is equivalent to:,This can be useful if you have many options and all of them are applicable
to one of patterns. Alternatively, if you have both short and long
versions of options (specified in option description part),
you can list either of them in a pattern:,More details on how to write options' descriptions will follow below.,A double dash "","", when not part of an option, is often used as a convention
to separate options and positional arguments, in order to handle cases when,
e.g., file names could be mistaken for options.  In order to support this
convention, add "","" into your patterns before positional arguments.,Apart from this special meaning, "","" is just a normal command, so you can
apply any previously-described operations, for example, make it required
(by dropping brackets "",""),A single dash "","", when not part of an option, is often used by convention
to signify that a program should process ,, as opposed to a file.
If you want to follow this convention add "","" to your pattern.
"","" by itself is just a normal command, which you can use with any meaning.,Option descriptions consist of a list of options that you put below your
usage patterns.  It is optional to specify them if there is no ambiguity
in usage patterns (described in the , section above).,An option's description allows to specify:,The rules are as follows:,Every line that starts with "","" or "","" (not counting spaces)
is treated as an option description, e.g.:,To specify that an option has an argument, put a word describing that
argument after a space (or equals "","" sign) as shown below. Follow
either , or , convention for options' arguments.
You can use a comma if you want to separate options. In the example below, both
lines are valid, however it is recommended to stick to a single style.,Use two spaces to separate options with their informal description.,If you want to set a default value for an option with an argument, put it
into the option's description, in the form ,., is available in numerous programming languages.
Official implementations are listed under the ,."
name,content
executing,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,alexmojaki/executing,Name already in use,executing,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Get information about what a Python frame is currently doing, particularly the AST node being executed
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , ,This mini-package lets you get information about what a frame is currently doing, particularly the AST node being executed.,Then , will be an AST node (from the , standard library module) or None if the node couldn't be identified (which may happen often and should always be checked)., will always be the same instance for multiple calls with frames at the same point of execution.,If you have a traceback object, pass it directly to , rather than the , attribute to get the correct node.,For this you will need to separately install the , library, then obtain an , object:,or:,or use one of the convenience methods:,or:,Everything goes through the , class. Only one instance of the class is created for each filename. Subclassing it to add more attributes on creation or methods is recommended. The classmethods such as , will respect this. See the source code and docstrings for more detail.,If you don't like that you can just copy the file ,, there are no dependencies (but of course you won't get updates).,Suppose the frame is executing this line:,and in particular it's currently obtaining the attribute ,. Looking at the bytecode, specifically ,, we can tell that it's loading an attribute, but it's not obvious which one. We can narrow down the statement being executed using , and find the two , nodes representing , and ,. How do we find out which one it is, without recreating the entire compiler in Python?,The trick is to modify the AST slightly for each candidate expression and observe the changes in the bytecode instructions. We change the AST to this:,and compile it, and the bytecode will be almost the same but there will be two new instructions:,and just before that will be a , instruction corresponding to ,. Seeing that it's in the same position as the original instruction lets us know we've found our match.,Yes - if it identifies a node, you can trust that it's identified the correct one. The tests are very thorough - in addition to unit tests which check various situations directly, there are property tests against a large number of files (see the filenames printed in ,) with real code. Specifically, for each file, the tests:,In other words, it shows that there is a one-to-one mapping between the nodes and the instructions that can be handled. This leaves very little room for a bug to creep in.,Furthermore, , checks that the instructions compiled from the modified AST exactly match the original code save for a few small known exceptions. This accounts for all the quirks and optimisations in the interpreter.,Currently it works in almost all cases for the following , nodes:,The plan is to extend to more operations in the future.,
      Get information about what a Python frame is currently doing, particularly the AST node being executed
    "
name,content
daphne,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,django/daphne,Name already in use,daphne,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Django Channels HTTP/WebSocket server
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Daphne is a HTTP, HTTP2 and WebSocket protocol server for
, and
,,
developed to power Django Channels.,It supports automatic negotiation of protocols; there's no need for URL
prefixing to determine WebSocket endpoints versus HTTP endpoints.,Simply point Daphne to your ASGI application, and optionally
set a bind address and port (defaults to localhost, port 8000):,If you intend to run daphne behind a proxy server you can use UNIX
sockets to communicate between the two:,If daphne is being run inside a process manager, you might
want it to bind to a file descriptor passed down from a parent process.
To achieve this you can use the --fd flag:,If you want more control over the port/socket bindings you can fall back to
using ,
by using the --endpoint (-e) flag, which can be used multiple times.
This line would start a SSL server on port 443, assuming that key.pem and crt.pem
exist in the current directory (requires pyopenssl to be installed):,Endpoints even let you use the , endpoint syntax to get automatic certificates
from Let's Encrypt, which you can read more about at ,.,To see all available command line options run daphne with the , flag.,Daphne supports terminating HTTP/2 connections natively. You'll
need to do a couple of things to get it working, though. First, you need to
make sure you install the Twisted , and , extras:,Next, because all current browsers only support HTTP/2 when using TLS, you will
need to start Daphne with TLS turned on, which can be done using the Twisted endpoint syntax:,Alternatively, you can use the , endpoint syntax or anything else that
enables TLS under the hood.,You will also need to be on a system that has ,; if you are
using Ubuntu, this means you need at least Ubuntu 16.04.,Now, when you start up Daphne, it should tell you this in the log:,Then, connect with a browser that supports HTTP/2, and everything should be
working. It's often hard to tell that HTTP/2 is working, as the log Daphne gives you
will be identical (it's HTTP, after all), and most browsers don't make it obvious
in their network inspector windows. There are browser extensions that will let
you know clearly if it's working or not.,Daphne only supports ""normal"" requests over HTTP/2 at this time; there is not
yet support for extended features like Server Push. It will, however, result in
much faster connections and lower overheads.,If you have a reverse proxy in front of your site to serve static files or
similar, HTTP/2 will only work if that proxy understands and passes through the
connection correctly.,In order to set the root path for Daphne, which is the equivalent of the
WSGI , setting, you have two options:,The header takes precedence if both are set. As with ,, the value
should start with a slash, but not end with one; for example:,Daphne requires Python 3.7 or later.,Please refer to the
,.,To run tests, make sure you have installed the , extra with the package:,To report security issues, please contact ,. For GPG
signatures and more security process information, see
,.,To report bugs or request new features, please open a new GitHub issue.,This repository is part of the Channels project. For the shepherd and maintenance team, please see the
,.,
      Django Channels HTTP/WebSocket server
    "
name,content
preshed,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,explosion/preshed,Name already in use,preshed: Cython Hash Table for Pre-Hashed Keys,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        , Cython hash tables that assume keys are pre-hashed
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Simple but high performance Cython hash table mapping pre-randomized keys to
, values. Inspired by
,.,
,
,
,
      , Cython hash tables that assume keys are pre-hashed
    "
name,content
jaraco.functools,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jaraco/jaraco.functools,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Additional functools in the spirit of stdlib's functools.,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,."
name,content
future,"Easy, clean, reliable Python 2/3 compatibility, is the missing compatibility layer between Python 2 and
Python 3. It allows you to use a single, clean Python 3.x-compatible
codebase to support both Python 2 and Python 3 with minimal overhead.,
      ,
      
    ,
        © Copyright 2013-2019, Python Charmers Pty Ltd, Australia.,
    "
name,content
Colr,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,welbornprod/colr,Name already in use,Colr,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Easy terminal colors, with chainable methods.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A python module for using terminal colors. It contains a simple
, function that accepts style and color names, and outputs a string
with escape codes, but also has all colors and styles as chainable methods
on the , object.,See also: , (Colr for C),There are no dependencies required for importing this library, however:,Colr is listed on ,,
and can be installed using ,:,Or you can clone the repo on ,
and install it from the command line:,Documentation for the , API can be found in the GitHub repo
(,):,The , package can be used as a command line tool. An entry point script
named , is created when installed with pip. Otherwise it can be executed
using the , method.,Basic usage involves passing text, or piping stdin data and setting the colors
by position or flag.,Using the positional arguments is faster for just setting fore colors, but
the flag method is needed for stdin data, or for picking just the background
color or style:,Extended and True colors are supported:,It will do fore, back, style, gradients, rainbows, justification,
and translation.
It can strip codes from text (as an argument or stdin), or explain the
codes found in the text., emulation:,The colr tool does not read files, but it's not a problem:,Also see ,.,A small command-runner is included, called ,. This
program will run another program, printing an animated message instead of the
normal output.,It is used to turn ""noisy"" commands into a nice single-line animation.,To run a program with the default settings, , is still required:,Any stderr output from the program will ruin the animation, which may be fine
if you are only looking for errors.,You can silence stderr output with , if you don't need it:,The exit status of , is the exit status of the command being
executed. For , errors, the exit status is , for basic errors,
and , for cancelled commands.,Colr provides a wrapper for docopt that will automatically colorize usage
strings. If you provide it a script name it will add a little more color by
colorizing the script name too.,As always contributions are welcome here. If you think you can improve something,
or have a good idea for a feature, please file an
, or a
,.,In the past, I used a simple , function because I'm not fond of the
string concatenation style that other libraries use. The 'clor' javascript
library uses method chaining because that style suits javascript, but I wanted
to make it available to Python also, at least as an option.,The reset code is appended only if some kind of text was given, and
colr/style args were used. The only values that are considered 'no text'
values are , and , (empty string). , is called on all other
values, so , and , will work, and the reset
code will be appended.,This makes it possible to build background colors and styles, but
also have separate styles for separate pieces of text.,I don't really have the desire to back-port this to Python 2.
It wouldn't need too many changes, but I like the Python 3 features
(,, ,).,Windows 10 finally has support for ANSI escape codes.
Colr can now be used on Windows 10+ by calling ,.
Older Windows versions are not supported and haven't been tested. If you are
using Colr for a tool that needs to support older Windows versions, you will
need to detect the current Windows version and call , for those
that aren't supported. Otherwise you will have ""junk"" characters printed to
the screen.,This library may be a little too flexible:,
      Easy terminal colors, with chainable methods.
    "
name,content
keyring,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jaraco/keyring,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,The Python keyring library provides an easy way to access the
system keyring service from python. It can be used in any
application that needs safe password storage.,These recommended keyring backends are supported:,Other keyring implementations are available through ,.,On Linux, the KWallet backend relies on ,, which does not always
install correctly when using pip (compilation is needed). For best results,
install dbus-python as a system package.,macOS keychain supports macOS 11 (Big Sur) and later requires Python 3.8.7
or later with the ""universal2"" binary. See
, for details.,The basic usage of keyring is pretty simple: just call
, and ,:,Keyring supplies a , command which is installed with the
package. After installing keyring in most environments, the
command should be available for setting, getting, and deleting
passwords. For more usage information, invoke with no arguments
or with , as so:,The command-line functionality is also exposed as an executable
package, suitable for invoking from Python like so:,If installed via a package manager (apt, pacman, nix, homebrew, etc),
these shell completions may already have been distributed with the package
(no action required).,Keyring provides tab completion if the , extra is installed:,Then, generate shell completions, something like:,: the path of /usr/share is mainly for GNU/Linux. For other OSs,
consider:,After installing the shell completions, enable them following your shell's
recommended instructions. e.g.:,The python keyring lib contains implementations for several backends. The
library will attempt to
automatically choose the most suitable backend for the current
environment. Users may also specify the preferred keyring in a
config file or by calling the , function.,The configuration is stored in a file named ""keyringrc.cfg""
found in a platform-specific location. To determine
where the config file is stored, run ,.,To specify a keyring backend, set the , option to the
full path of the class for that backend, such as
,.,If , is indicated, keyring will add that path to the Python
module search path before loading the backend.,For example, this config might be used to load the
, from the , module in
the , directory (not implemented):,In addition to the backends provided by the core keyring package for
the most common and secure use cases, there
are additional keyring backend implementations available for other
use cases. Simply install them to make them available:,The interface for the backend is defined by ,.
Every backend should derive from that base class and define a ,
attribute and three functions: ,, ,, and
,. The , function may be defined if
desired.,See the , module for more detail on the interface of this class.,Keyring employs entry points to allow any third-party package to implement
backends without any modification to the keyring itself. Those interested in
creating new backends are encouraged to create new, third-party packages
in the , namespace, in a manner modeled by the ,. See the
, file
in that project for hints on how to create the requisite entry points.
Backends that prove essential may be considered for inclusion in the core
library, although the ease of installing these third-party packages should
mean that extensions may be readily available.,To create an extension for Keyring, please submit a pull request to
have your extension mentioned as an available extension.,Keyring additionally allows programmatic configuration of the
backend calling the api ,. The indicated backend
will subsequently be used to store and retrieve passwords.,To invoke ,:,In many cases, uninstalling keyring will never be necessary.
Especially on Windows and macOS, the behavior of keyring is
usually degenerate, meaning it will return empty values to
the caller, allowing the caller to fall back to some other
behavior.,In some cases, the default behavior of keyring is undesirable and
it would be preferable to disable the keyring behavior altogether.
There are several mechanisms to disable keyring:,Keyring provides a mechanism to alter the keyring's behavior through
environment variables. Each backend implements a
,, which
when invoked will find all environment variables beginning with
, and will set a property for each
, on the keyring. This method is invoked during
initialization for the default/configured keyring.,This mechanism may be used to set some useful values on various
keyrings, including:,The following is a complete transcript for installing keyring in a
virtual environment on Ubuntu 16.04.  No config file was used:,It is possible to use the SecretService backend on Linux systems without
X11 server available (only D-Bus is required). In this case:,Install the , daemon.,Start a D-Bus session, e.g. run , and run
the following commands inside that shell.,Run , with , option. The description of
that option says:,Read a password from stdin, and use it to unlock the login keyring
or create it if the login keyring does not exist.,When that command is started, enter a password into stdin and
press Ctrl+D (end of data). After that, the daemon will fork into
the background (use , option to block).,Now you can use the SecretService backend of Keyring. Remember to
run your application in the same D-Bus session as the daemon.,It is possible to use keyring with the SecretService backend in Docker containers as well.
All you need to do is install the necessary dependencies and add the --privileged flag
to avoid any Operation not permitted errors when attempting to unlock the system's keyring.,The following is a complete transcript for installing keyring on a Ubuntu 18:04 container:,The keyring lib has a few functions:,In all cases, the parameters (,, ,, ,)
should be Unicode text.,The keyring lib raises the following exceptions:,Python keyring lib is an open community project and eagerly
welcomes contributors.,Each built-in backend may have security considerations to understand
before using this library. Authors of tools or libraries utilizing
, are encouraged to consider these concerns.,As with any list of known security concerns, this list is not exhaustive.
Additional issues can be added as needed.,This project makes use of automated releases and continuous
integration. The
simple workflow is to tag a commit and push it to Github. If it
passes tests in CI, it will be automatically deployed to PyPI.,Other things to consider when making a release:,Tests are continuously run in Github Actions.,To run the tests locally, install and invoke
,.,The project was based on Tarek Ziade's idea in ,. Kang Zhang
initially carried it out as a , project, and Tarek
mentored Kang on this project.,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,."
name,content
autobahn,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,crossbario/autobahn-python,Name already in use,Autobahn|Python,one,routed,Only use on CPython - not on PyPy (which is faster natively),We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        WebSocket and WAMP in Python for Twisted and asyncio
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,WebSocket & WAMP for Python on Twisted and asyncio., is a subproject of , and provides open-source
implementations of,for Python 3.7+ and running on , and ,.,You can use , to create clients and servers in Python speaking just plain WebSocket or WAMP., allows , and beyond, while , adds real-time application communication on top of WebSocket., provides asynchronous , and , for applications in , protocol running over ,. WAMP is a , protocol, so you need a , to connect your , based clients. We provide ,, but there are , as well.,Note, up to version v19.11.2 supported Python 2 and 3.4+,
and up to version v20.7.1 supported Python 3.5+,
and up to version v21.2.1 supported Python 3.6+.,To give you a first impression, here are two examples. We have lot more ,.,Here is a simple WebSocket Echo Server that will echo back any WebSocket
message received:,To actually run above server protocol, you need some lines of ,.,Here is a WAMP Application Component that performs all four types of
actions that WAMP provides:,Above code will work on Twisted and asyncio by changing a single line
(the base class of ,). To actually run above application component, you need some lines of , and a ,.,Autobahn runs on both Twisted and asyncio. To select the respective netoworking framework, install flavor:,Autobahn supports running over TLS (for WebSocket and all WAMP transports) as well as , authentication.,To install use this flavor:,Autobahn also supports , authentication. To install:,Autobahn includes support for ,. To install use this flavor:,To install:,or (Twisted, with more bells an whistles),or (asyncio, with more bells an whistles),> This is NOT yet complete - ALPHA!,Autobahn contains ,, a network accelerator library that provides SIMD accelerated native vector code for WebSocket (XOR masking) and UTF-8 validation.,To install Autobahn with all available serializers:,or (development install),Further, to speed up JSON on CPython using ,, set the environment variable:,Warning,Using , (on both CPython and PyPy) will break the ability of Autobahn
to transport and translate binary application payloads in WAMP transparently.
This ability depends on features of the regular JSON standard library module
not available on ,.,
      WebSocket and WAMP in Python for Twisted and asyncio
    "
name,content
nvidia-curand-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
mysqlclient,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,PyMySQL/mysqlclient,Name already in use,mysqlclient,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        MySQL database connector for Python (with Python 3 support)
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This project is a fork of ,.
This project adds Python 3 support and fixed many bugs.,When your question looks relating to Python rather than MySQL:,Or when you have question about MySQL:,Building mysqlclient on Windows is very hard.
But there are some binary wheels you can install easily.,If binary wheels do not exist for your version of Python, it may be possible to
build from source, but if this does not work, ,
To build from source, download the
, and install
it. It must be installed in the default location
(usually ""C:\Program Files\MariaDB\MariaDB Connector C"" or
""C:\Program Files (x86)\MariaDB\MariaDB Connector C"" for 32-bit). If you
build the connector yourself or install it in a different location, set the
environment variable , before installing. Once you have
the connector installed and an appropriate version of Visual Studio for your
version of Python:,Install MySQL and mysqlclient:,If you don't want to install MySQL server, you can use mysql-client instead:,You may need to install the Python 3 and MySQL development headers and libraries like so:,Then you can install mysqlclient via pip now:,mysqlclient uses , by default for finding
compiler/linker flags.,You can use , and , environment
variables to customize compiler/linker options.,Documentation is hosted on ,
      MySQL database connector for Python (with Python 3 support)
    "
name,content
contextlib2,"contextlib2 — Updated utilities for context management,Using the Module,Obtaining the Module,Indices and tables,This module provides backports of features in the latest version of the
standard library’s , module to earlier Python versions. It
also serves as a real world proving ground for potential future enhancements
to that module.,Like ,, this module provides utilities for common tasks
involving the , and , statements.,This module is primarily a backport of the Python 3.10 version of
, to earlier releases. The async context management features
require asynchronous generator support in the language runtime, so the oldest
supported version is now Python 3.6 (contextlib2 0.6.0 and earlier support
older Python versions by omitting all asynchronous features).,This module is also a proving ground for new features not yet part of the
standard library.  There are currently no such features in the module.,Finally, this module contains some deprecated APIs which never graduated to
standard library inclusion. These interfaces are no longer documented, but may
still be present in the code (emitting , if used).,This module can be installed directly from the , with
,:,Alternatively, you can download and unpack it manually from the ,.,There are no operating system or distribution specific versions of this
module - it is a pure Python module that should work on all platforms.,Supported Python versions are currently 3.6+.,contextlib2 is developed and maintained on ,. Problems and suggested
improvements can be posted to the ,.,
        © Copyright 2021, Nick Coghlan
      
        ,
      

    "
name,content
blis,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,explosion/cython-blis,Name already in use,Cython BLIS: Fast BLAS-like operations from Python and Cython, without the tears,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        💥 Fast matrix-multiplication as a self-contained Python library – no system dependencies!
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This repository provides the
, routines as a
self-contained Python C-extension.,Currently, we only supports single-threaded execution, as this is actually best
for our workloads (ML inference).,
,
,
,You can install the package via pip, first making sure that ,, ,,
and , are up-to-date:,Wheels should be available, so installation should be fast. If you want to
install from source and you're on Windows, you'll need to install LLVM.,The provided wheels should work on x86_64 and osx/arm64 architectures.
Unfortunately we do not currently know a way to provide different wheels for
alternative architectures, and we cannot provide a single binary that works
everywhere. So if the wheel doesn't work for your CPU, you'll need to specify
source distribution, and tell Blis your CPU architecture using the ,
environment variable.,Provide an architecture from the
,., , is not optimized for any particular CPU and is extremely slow.
Only recommended for testing!,In order to compile Blis, , bundles makefile scripts for specific
architectures, that are compiled by running the Blis build system and logging
the commands. We do not yet have logs for every architecture, as there are some
architectures we have not had access to., for list of
architectures. For example, here's how to build support for the Intel
architecture ,:,Fingers crossed, this will build you a wheel that supports your platform. You
could then , with
the , and ,
files so that you can run:,Two APIs are provided: a high-level Python API, and direct
, access, which provides fused-type, nogil Cython
bindings to the underlying Blis linear algebra library. Fused types are a simple
template mechanism, allowing just a touch of compile-time generic programming:,Bindings have been added as we've needed them. Please submit pull requests if
the library is missing some functions you require.,To build the source package, you should run the following command:,This populates the , folder for the various architectures, using the
, submodule.,In order to compile the Blis sources, we use jsonl files that provide the
explicit compiler flags. We build these jsonl files by running Blis's build
system, and then converting the log. This avoids us having to replicate the
build system within Python: we just use the jsonl to make a bunch of subprocess
calls. To support a new OS/architecture combination, we have to provide the
jsonl file and the header.,The Linux build files need to be produced from within the manylinux2014 Docker
container, so that they will be compatible with the wheel building process.,First, install docker. Then do the following to start the container:,Once within the container, the following commands should check out the repo and
build the jsonl files for the generic arch:,Then from a new terminal, retrieve the two files we need out of the container:,
      💥 Fast matrix-multiplication as a self-contained Python library – no system dependencies!
    "
name,content
iso8601,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,micktwomey/pyiso8601,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        ISO8601 formatted datetime parser for python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Simple module to parse ISO 8601 dates,pip install iso8601,Documentation: ,PyPI: ,Source: ,This module parses the most common forms of ISO 8601 date strings (e.g. 2007-01-14T20:34:22+00:00) into datetime objects.,See the LICENSE file for the license this package is released under.,If you want more full featured parsing look at:,You can parse full date + times, or just the date. In both cases a datetime instance is returned but with missing times defaulting to 0, and missing days / months defaulting to 1.,Known differences from the ISO 8601 spec:,Note that you need all the pythons installed to perform a tox run (see below). pyenv helps hugely, use pyenv install for the versions you need then use 'pyenv local version ...' to link them in (the tox-pyenv plugin will pick them up).,Alternatively, to test only with your current python:,Tested against:,Python 3 versions < 3.7 are untested but should work.,See ,.,
      ISO8601 formatted datetime parser for python
    "
name,content
mpmath," is a free (BSD licensed) Python library for real and complex floating-point arithmetic with arbitrary precision. It has been developed by , since 2007, with help from many contributors.,The following example computes 50 digits of pi by numerically evaluating the Gaussian integral with mpmath. See , and the documentation links below for many more examples!,mpmath works with both Python 2 and Python 3, with no other required dependencies. It can be used as a library, interactively via the Python interpreter, or from within the , or , computer algebra systems which include mpmath as standard component. , lets you use mpmath directly in the browser.,The latest version is 1.3.0, released 2023-03-07. Download: ,Source code git repository: ,Issue tracker: ,Feedback and questions are welcome on the , (mpmath@googlegroups.com),This project was previously hosted on Google Code. See , for the old site.,The documentation provides installation instructions and lots of interactive examples., (HTML),mpmath can be used as an arbitrary-precision substitute for Python's float/complex types and math/cmath modules, but also does much more ,. Almost any calculation can be performed just as well at 10-digit or 1000-digit precision, with either real or complex numbers, and in many cases mpmath implements efficient algorithms that scale well for extremely high precision work.,mpmath implements a huge number of ,, with arbitrary precision and full support for complex numbers:,mpmath also includes rudimentary support for interval arithmetic (only basic functions are available).,If , is available, mpmath provides a convenient plotting interface. The pictures at the top of this page were generated by the commands ,, ,, and the , script. See the , for more images.,mpmath internally uses Python's builtin long integers by default, but automatically switches to ,/, for much faster high-precision arithmetic if , is installed or if mpmath is imported from within ,.,The , computer algebra system includes mpmath as a standard component, and uses it for numerical evaluation of special functions. , and ,, Python computer algebra systems, use mpmath for numerical evaluation. Other software includes:,As of April 2014, Google Scholar , in the scientific literature. A very outdated hand-compiled list can be found ,.,If you use mpmath in your research, please cite it! In BibTeX format, the following entry can be used:"
name,content
openpyxl,"openpyxl - A Python library to read/write Excel 2010 xlsx/xlsm files,Indices and tables,your,openpyxl is a Python library to read/write Excel 2010 xlsx/xlsm/xltx/xltm files.,It was born from lack of existing library to read/write natively from Python
the Office Open XML format.,All kudos to the PHPExcel team as openpyxl was initially based on PHPExcel.,By default openpyxl does not guard against quadratic blowup or billion laughs
xml attacks. To guard against these attacks install defusedxml.,The user list can be found on ,Sample code:,The documentation is at: ,Release notes: ,This is an open source project, maintained by volunteers in their spare time.
This may well mean that particular features or functions that you would like
are missing. But things don’t have to stay that way. You can contribute the
project , yourself or contract a developer for particular
features.,Professional support for openpyxl is available from
, and
,. Donations to the project to support further
development and maintenance are welcome.,Bug reports and feature requests should be submitted using the ,. Please provide a full
traceback of any error you see and if possible a sample file. If for reasons
of confidentiality you are unable to make a file publicly available then
contact of one the developers.,The repository is being provided by , and
,.,Any help will be greatly appreciated, just follow those steps:,1.
Please join the group and create a branch (,) and
follow the ,.
for each independent feature, don’t try to fix all problems at the same
time, it’s easier for those who will review and merge your changes ;-),2.
Hack hack hack,3.
Don’t forget to add unit tests for your changes! (YES, even if it’s a
one-liner, changes without tests will , be accepted.) There are plenty
of examples in the source if you lack know-how or inspiration.,4.
If you added a whole new feature, or just improved something, you can
be proud of it, so add yourself to the AUTHORS file :-),5.
Let people know about the shiny thing you just implemented, update the
docs!,6.
When it’s done, just issue a pull request (click on the large “pull
request” button on , repository) and wait for your code to be
reviewed, and, if you followed all theses steps, merged into the main
repository.,For further information see ,There are several ways to contribute, even if you can’t code (or can’t code well):,
        © Copyright 2010 - 2023, See AUTHORS
      
        ,
      

    "
name,content
nltk,"
            ,
          ,Documentation,Natural Language Toolkit,Natural Language Processing with Python,NLTK is a leading platform for building Python programs to work with human language data.
It provides easy-to-use interfaces to , such as WordNet,
along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,
wrappers for industrial-strength NLP libraries,
and an active ,.,Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,
NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.
NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.,NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”
and “an amazing library to play with natural language.”, provides a practical
introduction to programming for language processing.
Written by the creators of NLTK, it guides the reader through the fundamentals
of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,
and more.
The online version of the book has been been updated for Python 3 and NLTK 3.
(The original Python 2 version is still available at ,.),Tokenize and tag some text:,Identify named entities:,Display a parse tree:,NB. If you publish work that uses NLTK, please cite the NLTK book as
follows:,Bird, Steven, Edward Loper and Ewan Klein (2009), ,.  O’Reilly Media Inc."
name,content
cffi,"CFFI documentation,C Foreign Function Interface for Python.  Interact with almost any C
code from Python, based on C-like declarations that you can often
copy-paste from header files or documentation.,
        © Copyright 2012-2018, Armin Rigo, Maciej Fijalkowski
      
        ,
      

    "
name,content
fsspec,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,fsspec/filesystem_spec,Name already in use,filesystem_spec,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A specification that python filesystems should adhere to.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,A specification for pythonic filesystems.,would install the base fsspec. Various optionally supported features might require specification of custom
extra require, e.g. , will install dependencies for , backends support.
Use , for installation of all known extra dependencies.,Up-to-date package also provided through conda-forge distribution:,To produce a template or specification for a file-system interface, that specific implementations should follow,
so that applications making use of them can rely on a common behaviour and not have to worry about the specific
internal implementation decisions with any given backend. Many such implementations are included in this package,
or in sister projects such as , and ,.,In addition, if this is well-designed, then additional functionality, such as a key-value store or FUSE
mounting of the file-system implementation may be available for all implementations ""for free"".,Please refer to ,fsspec uses GitHub Actions for CI. Environment files can be found
in the ""ci/"" directory. Note that the main environment is called ""py38"",
but it is expected that the version of python installed be adjustable at
CI runtime. For local use, pick a version suitable for you.,Tests can be run in the dev environment, if activated, via ,.,The full fsspec suite requires a system-level docker, docker-compose, and fuse
installation. If only making changes to one backend implementation, it is
not generally necessary to run all tests locally.,It is expected that contributors ensure that any change to fsspec does not
cause issues or regressions for either other fsspec-related packages such
as gcsfs and s3fs, nor for downstream users of fsspec. The ""downstream"" CI
run and corresponding environment file run a set of tests from the dask
test suite, and very minimal tests against pandas and zarr from the
test_downstream.py module in this repo.,fsspec uses , to ensure
a consistent code format throughout the project.
Run , from the root of the filesystem_spec repository to
auto-format your code. Additionally, many editors have plugins that will apply
, as you edit files. , is included in the , environments.,Optionally, you may wish to setup , to
automatically run , when you make a git commit.
Run , from the root of the
filesystem_spec repository to setup pre-commit hooks. , will now be run
before you commit, reformatting any changed files. You can format without
committing via , or skip these checks with ,.,
      A specification that python filesystems should adhere to.
    "
name,content
dnspython,"dnspython,
              Dnspython is a DNS toolkit for Python.  It can be used for queries, zone transfers, dynamic updates, nameserver testing, and many other things.
            ,
          ,
        ,
          ,
        ,
          ,
        ,
          ,
        ,
          ,
        ,
          ,
        ,
          ,
        ,
          ,
        ,
          ,
        ,
          ,
        ,
          Copyright © 2020, Dnspython Contributors
      "
name,content
Brotli,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,google/brotli,Name already in use,SECURITY NOTE,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Brotli compression format
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Please consider updating brotli to version 1.0.9 (latest).,Version 1.0.9 contains a fix to ""integer overflow"" problem. This happens when ""one-shot"" decoding API is used (or input chunk for streaming API is not limited), input size (chunk size) is larger than 2GiB, and input contains uncompressed blocks. After the overflow happens, , is invoked with a gigantic , value, that will likely cause the crash.,Brotli is a generic-purpose lossless compression algorithm that compresses data
using a combination of a modern variant of the LZ77 algorithm, Huffman coding
and 2nd order context modeling, with a compression ratio comparable to the best
currently available general-purpose compression methods. It is similar in speed
with deflate but offers more dense compression.,The specification of the Brotli Compressed Data Format is defined in ,.,Brotli is open-sourced under the MIT License, see the LICENSE file., brotli is a ""stream"" format; it does not contain
meta-information, like checksums or uncompresssed data length. It is possible
to modify ""raw"" ranges of the compressed stream and the decoder will not
notice that.,Brotli mailing list:
,
,You can download and install brotli using the , dependency manager:,The brotli port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please , on the vcpkg repository.,See ,The basic commands to build and install brotli are:,You can use other , configuration.,To install the latest release of the Python module, run the following:,To install the tip-of-the-tree version, run:,See the , for more details on installing
from source, development, and testing., Brotli authors take no responsibility for the third party projects mentioned in this section.,Independent , implementation by Mark Adler, based entirely on format specification.,JavaScript port of brotli ,. Could be used directly via ,Hand ported , in haxe by Dominik Homberger. Output source code: JavaScript, PHP, Python, Java and C#,7Zip ,Dart ,Dart compression framework with , with ready-to-use prebuilt binaries for Win/Linux/Mac,
      Brotli compression format
    "
name,content
agate-excel,"agate-excel 0.2.5,API,agate-excel adds read support for Excel files (xls and xlsx) to ,.,Important links:,agate             ,Documentation:    ,Repository:       ,Issues:           ,To install:,For details on development or supported platforms see the ,.,agate-excel uses a monkey patching pattern to add read for xls and xlsx files support to all , instances.,Importing agate-excel adds methods to ,. Once you’ve imported it, you can create tables from both XLS and XLSX files.,Both , methods accept a , argument to specify which sheet to create the table from.,Parse an XLS file., – Path to an XLS file to load or a file-like object for one., – The names or integer indices of the worksheets to load. If not specified
then the first sheet will be used., – The number of rows to skip from the top of the sheet., – If ,, the first row is assumed to contain column names., – Limit how many rows of data will be read.,Parse an XLSX file., – Path to an XLSX file to load or a file-like object for one., – The names or integer indices of the worksheets to load. If not specified
then the “active” sheet will be used., – The number of rows to skip from the top of the sheet., – If ,, the first row is assumed to contain column names., – If ,, do not trust the dimensions in the file’s properties,
and recalculate them based on the data in the file., – Limit how many rows of data will be read.,The following individuals have contributed code to agate-excel:,Add , to ,.,Add , keyword argument to , and ,. (#40),Preserve column types from XLS files. (#36),Add support for Compound File Binary File (CFBF) XLS files. (#44),Close XLSX file before raising error for non-existent sheet. (#34),Use less memory and close XLS files. (#39),Drop support for Python 3.4 (end-of-life was March 18, 2019).,Fix bug in accepting , as keyword argument.,Add a , argument to , to recalculate the data’s dimensions, instead of trusting those in the file’s properties.,Include tests and examples in distribution.,agate-excel is now tested against Python 3.6 and 3.7.,Drop support for Python 3.3 (end-of-life was September 29, 2017).,Add support for openpyxl 2.6.0.,Add an , argument to , to override the encoding of the input XLS file.,Add a , argument to , and , to indicate the presence of a header row.,Add a , argument to , to allow disabling read-only mode for ,.,Overload , and , to accept and return multiple sheets.,Add a , argument to , and , to skip rows from the top of the sheet.,Fix bug in handling ambiguous dates in XLS. (#9),Fix bug in handling an empty XLS.,Fix bug in handling non-string column names in XLSX.,Fix bug in handling of , in boolean columns for XLS. (#11),Removed usage of deprecated openpyxl method ,.,Remove monkeypatching.,Upgrade required agate version to ,.,Ensure columns with numbers for names (e.g. years) are parsed as strings.,Initial version.,The MIT License,Copyright (c) 2017 Christopher Groskopf and contributors,Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:,The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.,THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE."
name,content
ansiwrap,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jonathaneunice/ansiwrap,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        textwrap, but savvy to ANSI colors
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., wraps text, like the standard , module.
But it also correctly wraps text that contains ANSI control
sequences that colorize or style text.,Where , is fooled by the raw string length of those control codes,
, is not; it understands that however much those codes affect color
and display style, they have no logical length.,The API mirrors the ,, ,, and ,
functions of ,. For example:,It also exports several other functions:,See also the enclosed ,.,
      textwrap, but savvy to ANSI colors
    "
name,content
catalogue,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,explosion/catalogue,Name already in use,catalogue: Super lightweight function registries for your library,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Super lightweight function registries for your library
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a tiny, zero-dependencies library that makes it easy to , to your code. Function registries are helpful
when you have objects that need to be both easily serializable and fully
customizable. Instead of passing a function into your object, you pass in an
identifier name, which the object can use to lookup the function from the
registry. This makes the object easy to serialize, because the name is a simple
string. If you instead saved the function, you'd have to use Pickle for
serialization, which has many drawbacks.,
,
,
,
, , , v3.0+ is only compatible with Python 3.8+.
For Python 3.6+ compatibility, use , v2.x and for Python 2.7+
compatibility, use , v1.x.,Let's imagine you're developing a Python package that needs to load data
somewhere. You've already implemented some loader functions for the most common
data types, but you want to allow the user to easily add their own. Using
, you can create a new registry under the namespace
, → ,.,This gives you a , decorator that your users can import and
decorate their custom loader functions with.,The decorated function will be registered automatically and in your package,
you'll be able to access all loaders by calling ,.,The user can now refer to their custom loader using only its string name
(,) and your application will know what to do and will use their
custom function.,Sure, that's the more classic callback approach. Instead of a string ID,
, could also take a function, in which case you wouldn't need a
package like this. , helps you when you need to produce a serializable
record of which functions were passed in. For instance, you might want to write
a log message, or save a config to load back your object later. With
,, your functions can be parameterized by strings, so logging and
serialization remains easy – while still giving you full extensibility.,Decorators normally run when modules are imported. Relying on this side-effect
can sometimes lead to confusion, especially if there's no other reason the
module would be imported. One solution is to use
,.,For instance, in , we're starting to use function
registries to make the pipeline components much more customizable. Let's say one
user, Jo, develops a better tagging model using new machine learning research.
End-users of Jo's package should be able to write
,. They shouldn't need to remember to write
, first, just to run the function registries as a
side-effect. With entry points, the registration happens at install time – so
you don't need to rely on the import side-effects.,Create a new registry for a given namespace. Returns a setter function that can
be used as a decorator or called with a name and , keyword argument. If
, is set, the registry will check for
,
advertised for the given namespace, e.g. the entry point group
, for the namespace ,, in
, and ,. This allows other packages to
auto-register functions.,The registry object that can be used to register and retrieve functions. It's
usually created internally when you call ,.,Initialize a new registry. If , is set, the registry will
check for
,
advertised for the given namespace, e.g. the entry point group
, for the namespace ,, in
, and ,.,Check whether a name is in the registry.,Register a function in the registry's namespace. Can be used as a decorator or
called as a function with the , keyword argument supplying the function to
register. Delegates to ,.,Register a function in the registry's namespace. Can be used as a decorator or
called as a function with the , keyword argument supplying the function to
register.,Get a function registered in the namespace.,Get all functions in the registry's namespace.,Get registered entry points from other packages for this namespace. The name of
the entry point group is the namespace joined by ,.,Check if registered entry point is available for a given name in the namespace
and load it. Otherwise, return the default value.,Find the information about a registered function, including the module and path
to the file it's defined in, the line number and the docstring, if available.,Check if a namespace exists.,
      Super lightweight function registries for your library
    "
name,content
Pillow,"Pillow,
                , is 
                ,. 
                Please considering hiring him or 
                , 
                with your network. Any and all networking opportunities appreciated!
            ,This is the home of Pillow, the friendly PIL fork.,PIL is an acronym for Python Imaging Library. 
                            If you have ever worried or wondered about the future of PIL, please stop. We're here to save the day.,
                                    Our , is hosted by Read the Docs and includes 
                                        ,, 
                                        ,, 
                                        , and 
                                        ,.
                                ,
                                    Discussion about Pillow development, programming and technical issues occurs on 
                                    ,, 
                                    , and 
                                    ,.
                                ,
                                    Our , is hosted by GitHub and tested on 
                                        ,, 
                                        ,, 
                                        ,, 
                                        , and uploaded to the 
                                        ,.
                                ,Available as part of the Tidelift Subscription.,
                            The maintainers of Pillow and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use.
                        ,
                            ,
                        ,
                © 1995-2011 Fredrik Lundh and contributors. © 2010-2023 Jeffrey A. Clark (Alex) and 
                ,. 
                Logo by Alastair Houghton. Psychedelic art by Jeremy Kun.
            ,
                ,
            "
name,content
Flask-Humanize,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,vitalk/flask-humanize,Name already in use,Flask Humanize,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Common humanization utilities for Flask applications
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Provides an interface between , web framework
and , library.,Add new filter , to jinja environment, which can be easily used for
humanize different objects:,Integer numbers:,Floating point numbers:,File sizes:,Date & times:,Runtime i18n/l10n,In order to use UTC time instead of local time for humanize date and time
methods use , option, which is disabled by default:,Don't hesitate to open , for any bug or suggestions.,
      Common humanization utilities for Flask applications
    "
name,content
GitPython,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,gitpython-developers/GitPython,Name already in use,Important,Windows,changelog,Do not reuse milestones by renaming them,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        GitPython is a python library used to interact with Git repositories.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,I started working on GitPython in 2009, back in the days when Python was 'my thing' and I had great plans with it.
Of course, back in the days, I didn't really know what I was doing and this shows in many places. Somewhat similar to
Python this happens to be 'good enough', but at the same time is deeply flawed and broken beyond repair.,By now, GitPython is widely used and I am sure there is a good reason for that, it's something to be proud of and happy about.
The community is maintaining the software and is keeping it relevant for which I am absolutely grateful. For the time to come I am happy to continue maintaining GitPython, remaining hopeful that one day it won't be needed anymore.,More than 15 years after my first meeting with 'git' I am still in excited about it, and am happy to finally have the tools and
probably the skills to scratch that itch of mine: implement , in a way that makes tool creation a piece of cake for most.,If you like the idea and want to learn more, please head over to ,, an
implementation of 'git' in ,.,GitPython is a python library used to interact with git repositories, high-level like git-porcelain,
or low-level like git-plumbing.,It provides abstractions of git objects for easy access of repository data often backed by calling the ,
command-line program.,This project is in ,, which means that,The project is open to contributions of all kinds, as well as new maintainers.,GitPython needs the , executable to be installed on the system and available in your , for most operations.
If it is not in your ,, you can help GitPython find it by setting
the , environment variable.,The list of dependencies are listed in , and ,.
The installer takes care of installing them for you.,If you have downloaded the source code:,or if you want to obtain a copy from the Pypi repository:,Both commands will install the required package dependencies.,A distribution package can be obtained for manual installation at: ,.,If you like to clone from source, you can do it like so:,GitPython is not suited for long-running processes (like daemons) as it tends to
leak system resources. It was written in a time where destructors (as implemented
in the , method) still ran deterministically.,In case you still want to use it in such a context, you will want to search the
codebase for , implementations and call these yourself when you see fit.,Another way assure proper cleanup of resources is to factor out GitPython into a
separate process which can be dropped periodically.,See ,.,: Right after cloning this repository, please be sure to have executed
the , script in the repository root. Otherwise
you will encounter test failures.,On ,, make sure you have , in your PATH. For MINGW-git, the ,
exists in ,; CYGWIN has no daemon, but should get along fine
with MINGW's.,Ensure testing libraries are installed.
In the root directory, run: ,To lint, run: ,To typecheck, run: ,To test, run: ,For automatic code formatting run: ,Configuration for flake8 is in the ./.flake8 file.,Configurations for mypy, pytest and coverage.py are in ./pyproject.toml.,The same linting and testing will also be performed against different supported python versions
upon submitting a pull request (or on each push if you have a fork with a ""main"" branch and actions enabled).,Please have a look at the ,.,Note that what follows is deprecated and future releases won't be signed anymore.
More details about how it came to that can be found ,.,Please only use releases from , as you can verify the respective source
tarballs.,This script shows how to verify the tarball was indeed created by the authors of
this project:,which outputs,You can verify that the keyid indeed matches the release-signature key provided in this
repository by looking at the keys details:,You can verify that the commit adding it was also signed by it using:,If you would like to trust it permanently, you can import and sign it:,New BSD License. See the LICENSE file.,
      GitPython is a python library used to interact with Git repositories.
    "
name,content
itsdangerous,"ItsDangerous,It's dangerous, so better sign this.,Various helpers to pass data to untrusted environments and to get it back safe and sound. Data is cryptographically signed to ensure that a token has not been tampered with.,It's possible to customize how data is serialized. Data is compressed as needed. A timestamp can be added and verified automatically while loading a token.,
          ,
        
        , ,
        , ,
        , ,
      "
name,content
fastjsonschema,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,horejsek/python-fastjsonschema,Name already in use,Fast JSON schema for Python,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Fast JSON schema validator for Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., ,See ,.,
      Fast JSON schema validator for Python.
    "
name,content
apsw,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,rogerbinns/apsw,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Another Python SQLite wrapper
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,APSW stands for ,nother ,ython ,QLite ,rapper.   APSW
supports CPython 3.6 onwards.,APSW lets you get the most out of the ,
embedded relational database engine from Python, and the most out of
Python from SQLite.  APSW glues together the complete , and ,, staying up to date
with both SQLite and Python.,It is recommended to use the builtin , if you want SQLite
to appear interchangeable with the other database drivers.,Use APSW when you want to use SQLite fully, and have an improved
developer experience.  The , has a section on
the differences between APSW and sqlite3.,There is a tour and example code using APSW at
,The latest documentation is at ,Releases are made to ,
(install using pip) and ,New release announcements are sent to the , and there is
an ,.,You can find existing and fixed bugs by clicking on , and using ""New Issue""
to report previously unknown issues.,See , - in
essence any OSI approved open source license.,A ,
from January 2022 supports all CPython versions back to 2.3.  The
, include more
information about versions.,
      Another Python SQLite wrapper
    "
name,content
agate,"agate 1.7.1,agate is a Python data analysis library that is optimized for humans instead of machines. It is an alternative to numpy and pandas that solves real-world problems with readable code.,agate was previously known as journalism.,Important links:,Documentation:    ,Repository:       ,Issues:           , - why you should use agate and the principles that guide its development, - how to install for users and developers, - a step-by-step guide to start using agate, - sample code showing how to accomplish dozens of common tasks, including comparisons to SQL, R, etc., - a list of libraries that extend agate functionality and how to build your own, - technical documentation for every agate feature, - a record of every change made to agate for each release,This example, along with detailed comments, are available as a ,., - guidance for developers who want to contribute to agate, - the process for maintainers to publish new releases, - a copy of the MIT open source license covering agate,agate is made by a community. The following individuals have contributed code, documentation, or expertise to agate:"
name,content
mock,"Mock - Mocking and Testing Library,mock is a library for testing in Python. It allows you to replace parts of
your system under test with mock objects and make assertions about how they
have been used.,mock is now part of the Python standard library, available as , in Python 3.3
onwards.,This package contains a rolling backport of the standard library mock code
compatible with Python 3.6 and up.,Please see the standard library documentation for more details., ,Version 1.0.1 is the last version compatible with Python < 2.6.,Version 1.3.0 is the last version compatible with Python 3.2.,Version 2.0.0 is the last version compatible with Python 2.6.,Version 2.0.0 is the last version offering official Jython support.,version 3.0.5 is the last version supporting Python 3.5 and lower.,You can checkout the latest development version from GitHub
repository with the following command:,You can install mock with pip:,Issues with the backport process, such as compatibility with a particular
Python, should be reported to the ,. Feature requests and issues
with Mock functionality should be reported to the ,.,See the ,.,Checkout from git (see ,) and submit pull requests.,Committers can just push as desired: since all semantic development takes
place in cPython, the backport process is as lightweight as we can make it.,If you end up fixing anything backport-specific, please add an entry
to the top of , so it shows up in the next release
notes.,NB: please use semver. Bump the major component on API breaks, minor on all
non-bugfix changes, patch on bugfix only changes.,Run , which will roll out new
NEWS items, bump the version number and create a commit for the release.,Review that commit, feel free to amend it if you want to note anything
manually in ,.,Push to the , branch on
, and the Circle CI
automation will take care of pushing releases to PyPI and
creating a tag.,If code such as this causes coverage checking to drop below 100%:,It should be adjusted to the following pattern, preferably upstream,
so that the , in this repo knows to ignore it:,If code such as this causes coverage checking to drop below 100%:,It should be adjusted to the following pattern, preferably upstream,
so that the , in this repo knows to ignore it:,If a backported patch applies cleanly, but ends up needing to be skipped,
then commit the latest sync point and then revert the problematic commit in an immediately
subsequent commit and make a note of the reason for the revert in that commit message.,See , for an example where , broke compatibility for all Python
versions earlier than 3.10.,Clone cpython and mock into the same directory, eg:,Make sure , branch is fully up to date!
Make sure , is on master and up fully up to date!,Create a branch in your , clone and switch to it.,Make sure you build a suitable virtualenv for Mock development
and activate it. For backporting, this should use Python 3.7+.,Run ,:,This will find the next cpython patch that needs to be applied, munge it
and attempt to apply it with ,.,If it succeeds, run the tests and/or push your branch up to a fork and
do a pull request into the master branch of the main repo to kick off
the continuous integration tests.,If it fails, you’ll have to manually work with what , shows
to get the patch committed.,If it turns out that there’s nothing that should be applied from the failed commit,
run ,, maybe with ,.,If you have to make changes, please do a , and add notes
about what needed doing below the , block.,If you have to make changes because tests fail with an applied patch, please
make those changes in a followup commit and take note of the “Backporting rules”
above.,Rinse and repeat until , reports no more patches need applying.,If , has updated , but not committed it,
now would be a good time to commit that change.,Assuming you have the checkout structure as above, and you have compiled your cpython
master branch, then roughly as follows:,Ignore , as these aren’t present in the backport."
name,content
pangocairocffi,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,leifgehrmann/pangocairocffi,Name already in use,pangocairocffi,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        CFFI-based pango-cairo bindings for Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,pangocairocffi is a ,-based set of Python bindings for the
,. It is meant to be used in
conjunction with , and ,.,The bindings are currently not fully implemented. Feel free to make a pull
request to contribute!,See , for information on how to install the necessary libraries.,See , for additional information on all the objects.,If you would like to contribute to this project, either by leaving feedback or
submitting a pull request, please read ','.,
      CFFI-based pango-cairo bindings for Python.
    "
name,content
async-timeout,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,aio-libs/async-timeout,Name already in use,async-timeout,timeout,timeout,Apache 2,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        asyncio-compatible timeout class
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,asyncio-compatible timeout context manager.,The context manager is useful in cases when you want to apply timeout
logic around block of code or in cases when , is
not suitable. Also it's much faster than ,
because , doesn't create a new task.,The , call returns a context manager
that cancels a block on , expiring:, parameter could be , for skipping timeout functionality.,Alternatively, , can be used for scheduling
at the absolute time:,Please note: it is not POSIX time but a time with
undefined starting base, e.g. the time of the system power on.,Context manager has , property for check if timeout happens
exactly in context manager:,The property is , if , execution is cancelled by
timeout context manager.,If , call explicitly raises , ,
is ,.,The scheduled deadline time is available as , property:,Not finished yet timeout can be rescheduled by ,
or , methods:,Rescheduling is forbidden if the timeout is expired or after exit from ,
code block.,The library is Python 3 only!,The module is written by Andrew Svetlov.,It's , licensed and freely available.,
      asyncio-compatible timeout class
    "
name,content
eventlet,"Eventlet,why,what,Eventlet is a concurrent networking library for Python that allows you to change how you run your code, not how you write it.,It's easy to get started using Eventlet, and easy to convert existing applications to use it. Start off by looking at ,, ,, and the list of the ,.,License: ,Currently CPython 2.7 and 3.4+ are supported, but ,, only CPython 3.5+ support will remain.,To install latest PyPI release:
        ,
        ,Manually lock version in requirements, if your build/development process doesn't automate it:
        ,Eventlet team is commited to have only stable code in master branch, so recommended way to install is from latest master commit:
        ,
        ,Beware, http…zip link in requirements.txt will repeat download and installation even if you specify link to particular commit.,Earlier versions available at ,
        ,Development, issue tracking happens at ,We had ,, but it's not used anymore.,If you don't like these rules, raw patches are more than welcome!,Please be sure to report bugs ,, to ensure that we understand and act on them quickly.,Usually ,In special cases, to contact current maintainers directly, look up info on Github project page.,This is a simple web “crawler” that fetches a bunch of urls using a coroutine pool.  It has as much concurrency (i.e. pages being fetched simultaneously) as coroutines in the pool.,
  ,
  ,
  ,
"
name,content
linkify-it-py,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,tsutsu3/linkify-it-py,Name already in use,linkify-it-py,with astral characters,str,dict,validate,self,text,pos,text,pos,pos,self,normalize,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Links recognition library with full unicode support 
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,This is Python port of ,.,Links recognition library with FULL unicode support.
Focused on high quality link patterns detection in plain text.,Why it's awesome:,or,Creates new linkifier instance with optional additional schemas.,By default understands:, is an dict, where each key/value describes protocol/rule:,:,Searches linkifiable pattern and returns , on success or , on fail.,Quick check if link MAY BE can exist. Can be used to optimize more expensive
, calls. Return , if link can not be found, , - if ,
call needed to know exactly.,Similar to , but checks only specific protocol tail exactly at given
position. Returns length of found pattern (0 on fail).,Returns , of found link matches or null if nothing found.,Each match has:,Checks if a match exists at the start of the string. Returns ,
(see docs for ,) or null if no URL is at the start.
Doesn't work with fuzzy links.,Load (or merge) new tlds list. Those are needed for fuzzy links (without schema)
to avoid false positives. By default:,If that's not enough, you can reload defaults with more detailed zones list.,Add a new schema to the schemas object. As described in the constructor
definition, , is a link prefix (,, for example), and ,
is a , to alias to another schema, or an , with , and
optionally , definitions.  To disable an existing rule, use
,.,Override default options. Missed properties will not be changed.,
      Links recognition library with full unicode support 
    "
name,content
keybert,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,MaartenGr/KeyBERT,Name already in use,KeyBERT,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Minimal keyword extraction with BERT
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,KeyBERT is a minimal and easy-to-use keyword extraction technique that leverages BERT embeddings to
create keywords and keyphrases that are most similar to a document.,Corresponding medium post can be found ,.,Although there are already many methods available for keyword generation
(e.g.,
,,
,, TF-IDF, etc.)
I wanted to create a very basic, but powerful method for extracting keywords and keyphrases.
This is where , comes in! Which uses BERT-embeddings and simple cosine similarity
to find the sub-phrases in a document that are the most similar to the document itself.,First, document embeddings are extracted with BERT to get a document-level representation.
Then, word embeddings are extracted for N-gram words/phrases. Finally, we use cosine similarity
to find the words/phrases that are the most similar to the document. The most similar words could
then be identified as the words that best describe the entire document.,KeyBERT is by no means unique and is created as a quick and easy method
for creating keywords and keyphrases. Although there are many great
papers and solutions out there that use BERT-embeddings
(e.g.,
,,
,,
,,
), I could not find a BERT-based solution that did not have to be trained from scratch and
could be used for beginners (,).
Thus, the goal was a , and at most 3 lines of code in usage.,Installation can be done using ,:,You may want to install more depending on the transformers and language backends that you will be using. The possible installations are:,The most minimal example can be seen below for the extraction of keywords:,You can set , to set the length of the resulting keywords/keyphrases:,To extract keyphrases, simply set , to (1, 2) or higher depending on the number
of words you would like in the resulting keyphrases:,We can highlight the keywords in the document by simply setting ,:,: For a full overview of all possible transformer models see ,.
I would advise either , for English documents or ,
for multi-lingual documents or any other language.,To diversify the results, we take the 2 x top_n most similar words/phrases to the document.
Then, we take all top_n combinations from the 2 x top_n words and extract the combination
that are the least similar to each other by cosine similarity.,To diversify the results, we can use Maximal Margin Relevance (MMR) to create
keywords / keyphrases which is also based on cosine similarity. The results
with ,:,The results with ,:,KeyBERT supports many embedding models that can be used to embed the documents and words:,Click , for a full overview of all supported embedding models.,
You can select any model from , ,
and pass it through KeyBERT with ,:,Or select a SentenceTransformer model with your own parameters:,
, allows you to choose almost any embedding model that
is publicly available. Flair can be used as follows:,You can select any , transformers model ,.,To cite KeyBERT in your work, please use the following bibtex reference:,Below, you can find several resources that were used for the creation of KeyBERT
but most importantly, these are amazing resources for creating impressive keyword extraction models:,:,:,:
The selection of keywords/keyphrases was modeled after:,: If you find a paper or github repo that has an easy-to-use implementation
of BERT-embeddings for keyword/keyphrase extraction, let me know! I'll make sure to
add a reference to this repo.,
      Minimal keyword extraction with BERT
    "
name,content
cmake,"Sep. 6 – 8, 2023,1 pm to 5 pm EST,CMake is part of Kitware’s collection of commercially supported , for software development.,Attend an upcoming CMake training course, , , ,CMake 3.27.1 is available for download,Kitware is hosting live training courses for our popular open source platforms. Our courses are taught by Kitware’s software R&D experts who champion these platforms. They mix theory and application with a set of tutorials and exercises. If you are interested in taking one of our upcoming courses, register now to take advantage of our […],CMake 3.26.5 is available for download,
	, | 
	, | 
	, | 
	, | 
	,
				"
name,content
parsedatetime,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,bear/parsedatetime,Name already in use,parsedatetime,Using parsedatetime,Note,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Parse human-readable date/time strings
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Parse human-readable date/time strings.,
,
,Parsedatetime now targets Python 3 and is currently tested with Python 3.9,Use , if you need Python 2.7 compatibility.,You can install parsedatetime using,Development is done using a , virtural environment,: , is still listed as a beta library, and as such, must be installed with the , flag,From the source directory,To run tests on several Python versions that are installed in the , virtual environment,The tests depend on PyICU being installed using the , package which removes the source build step. PyICU depends on icu4c which on macOS requires homebrew,Detailed examples can be found in the , directory.,as a time ,as a Python , object,with timezone support using ,The generated documentation is included by default in the , directory and can also be viewed online at ,The documentation is generated with,The , class has a member property named , which is created during the class init method to be an instance of ,.,The code in , has been implemented over the years in many different languages (C, Clipper, Delphi) as part of different custom/proprietary systems I've worked on.  Sadly the previous code is not ""open"" in any sense of that word.,When I went to work for Open Source Applications Foundation and realized that the Chandler project could benefit from my experience with parsing of date/time text I decided to start from scratch and implement the code using Python and make it truly open.,After working on the initial concept and creating something that could be shown to the Chandler folks, the code has now evolved to its current state with the help of the Chandler folks, most especially Darshana.,
      Parse human-readable date/time strings
    "
name,content
line-profiler,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pyutils/line_profiler,Name already in use,line_profiler and kernprof,not,t_end,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Line-by-line profiling for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , , ,NOTICE: This is the official line_profiler repository. The most recent
version of , on pypi
points to this repo. The original
, package by
, is currently unmaintained. This fork
seeks to simply maintain the original code so it continues to work in new
versions of Python.,line_profiler is a module for doing line-by-line profiling of functions.
kernprof is a convenient script for running either line_profiler or the Python
standard library's cProfile or profile modules, depending on what is available.,They are available under a ,.,Contents,To profile a python script:,Releases of line_profiler can be installed using pip:,Installation while ensuring a compatible IPython version can also be installed using pip:,To check out the development sources, you can use ,:,You may also download source tarballs of any snapshot from that URL.,Source releases will require a C compiler in order to build line_profiler.
In addition, git checkouts will also require Cython. Source releases
on PyPI should contain the pregenerated C sources, so Cython should not be
required in that case.,kernprof is a single-file pure Python script and does not require
a compiler.  If you wish to use it to run cProfile and not line-by-line
profiling, you may copy it to a directory on your PATH manually and avoid
trying to build any C extensions.,As of 2021-06-04 Linux (x86_64 and i686), OSX (10_9_x86_64), and Win32 (win32,
and amd64) binaries are available on pypi.,Alternatively on windows you might consider using Christoph Gohlke's
unofficial line-profiler
,.,The last version of line profiler to support Python 2.7 was 3.1.0 and the last
version to support Python 3.5 was 3.3.1.,The current profiling tools supported in Python only time
function calls. This is a good first step for locating hotspots in one's program
and is frequently all one needs to do to optimize the program. However,
sometimes the cause of the hotspot is actually a single line in the function,
and that line may not be obvious from just reading the source code. These cases
are particularly frequent in scientific computing. Functions tend to be larger
(sometimes because of legitimate algorithmic complexity, sometimes because the
programmer is still trying to write FORTRAN code), and a single statement
without function calls can trigger lots of computation when using libraries like
numpy. cProfile only times explicit function calls, not special methods called
because of syntax. Consequently, a relatively slow numpy operation on large
arrays like this,,is a hotspot that never gets broken out by cProfile because there is no explicit
function call in that statement.,LineProfiler can be given functions to profile, and it will time the execution
of each individual line inside those functions. In a typical workflow, one only
cares about line timings of a few functions because wading through the results
of timing every single line of code would be overwhelming. However, LineProfiler
does need to be explicitly told what functions to profile. The easiest way to
get started is to use the kernprof script.,kernprof will create an instance of LineProfiler and insert it into the
__builtins__ namespace with the name profile. It has been written to be
used as a decorator, so in your script, you decorate the functions you want
to profile with @profile.,The default behavior of kernprof is to put the results into a binary file
script_to_profile.py.lprof . You can tell kernprof to immediately view the
formatted results at the terminal with the [-v/--view] option. Otherwise, you
can view the results later like so:,For example, here are the results of profiling a single function from
a decorated version of the pystone.py benchmark (the first two lines are output
from pystone.py, not kernprof):,The source code of the function is printed with the timing information for each
line. There are six columns of information.,If you are using IPython, there is an implementation of an %lprun magic command
which will let you specify functions to profile and a statement to execute. It
will also add its LineProfiler instance into the __builtins__, but typically,
you would not use it like that.,For IPython 0.11+, you can install it by editing the IPython configuration file
~/.ipython/profile_default/ipython_config.py to add the 'line_profiler'
item to the extensions list:,To get usage help for %lprun, use the standard IPython help mechanism:,These two methods are expected to be the most frequent user-level ways of using
LineProfiler and will usually be the easiest. However, if you are building other
tools with LineProfiler, you will need to use the API. There are two ways to
inform LineProfiler of functions to profile: you can pass them as arguments to
the constructor or use the add_function(f) method after instantiation.,LineProfiler has the same run(), runctx(), and runcall() methods as
cProfile.Profile as well as enable() and disable(). It should be noted,
though, that enable() and disable() are not entirely safe when nested.
Nesting is common when using LineProfiler as a decorator. In order to support
nesting, use enable_by_count() and disable_by_count(). These functions will
increment and decrement a counter and only actually enable or disable the
profiler when the count transitions from or to 0.,After profiling, the dump_stats(filename) method will pickle the results out
to the given file. print_stats([stream]) will print the formatted results to
sys.stdout or whatever stream you specify. get_stats() will return LineStats
object, which just holds two attributes: a dictionary containing the results and
the timer unit.,kernprof also works with cProfile, its third-party incarnation lsprof, or the
pure-Python profile module depending on what is available. It has a few main
features:,The results of profile script_to_profile.py will be written to
script_to_profile.py.prof by default. It will be a typical marshalled file that
can be read with pstats.Stats(). They may be interactively viewed with the
command:,Such files may also be viewed with graphical tools. A list of 3rd party tools
built on , or , are as follows:,Why the name ""kernprof""?,I didn't manage to come up with a meaningful name, so I named it after
myself.,Why not use hotshot instead of line_profile?,hotshot can do line-by-line timings, too. However, it is deprecated and may
disappear from the standard library. Also, it can take a long time to
process the results while I want quick turnaround in my workflows. hotshot
pays this processing time in order to make itself minimally intrusive to the
code it is profiling. Code that does network operations, for example, may
even go down different code paths if profiling slows down execution too
much. For my use cases, and I think those of many other people, their
line-by-line profiling is not affected much by this concern.,Why not allow using hotshot from kernprof.py?,I don't use hotshot, myself. I will accept contributions in this vein,
though.,The line-by-line timings don't add up when one profiled function calls
another. What's up with that?,Let's say you have function F() calling function G(), and you are using
LineProfiler on both. The total time reported for G() is less than the time
reported on the line in F() that calls G(). The reason is that I'm being
reasonably clever (and possibly too clever) in recording the times.
Basically, I try to prevent recording the time spent inside LineProfiler
doing all of the bookkeeping for each line. Each time Python's tracing
facility issues a line event (which happens just before a line actually gets
executed), LineProfiler will find two timestamps, one at the beginning
before it does anything (t_begin) and one as close to the end as possible
(t_end). Almost all of the overhead of LineProfiler's data structures
happens in between these two times.,When a line event comes in, LineProfiler finds the function it belongs to.
If it's the first line in the function, we record the line number and
, associated with the function. The next time we see a line event
belonging to that function, we take t_begin of the new event and subtract
the old t_end from it to find the amount of time spent in the old line. Then
we record the new t_end as the active line for this function. This way, we
are removing most of LineProfiler's overhead from the results. Well almost.
When one profiled function F calls another profiled function G, the line in
F that calls G basically records the total time spent executing the line,
which includes the time spent inside the profiler while inside G.,The first time this question was asked, the questioner had the G() function
call as part of a larger expression, and he wanted to try to estimate how
much time was being spent in the function as opposed to the rest of the
expression. My response was that, even if I could remove the effect, it
might still be misleading. G() might be called elsewhere, not just from the
relevant line in F(). The workaround would be to modify the code to split it
up into two lines, one which just assigns the result of G() to a temporary
variable and the other with the rest of the expression.,I am open to suggestions on how to make this more robust. Or simple
admonitions against trying to be clever.,Why do my list comprehensions have so many hits when I use the LineProfiler?,LineProfiler records the line with the list comprehension once for each
iteration of the list comprehension.,Why is kernprof distributed with line_profiler? It works with just cProfile,
right?,Partly because kernprof.py is essential to using line_profiler effectively,
but mostly because I'm lazy and don't want to maintain the overhead of two
projects for modules as small as these. However, kernprof.py is
a standalone, pure Python script that can be used to do function profiling
with just the Python standard library. You may grab it and install it by
itself without line_profiler.,Do I need a C compiler to build line_profiler? kernprof.py?,You do need a C compiler for line_profiler. kernprof.py is a pure Python
script and can be installed separately, though.,Do I need Cython to build line_profiler?,You should not have to if you are building from a released source tarball.
It should contain the generated C sources already. If you are running into
problems, that may be a bug; let me know. If you are building from
a git checkout or snapshot, you will need Cython to generate the
C sources.,As of version , manylinux wheels containing the binaries are
available on pypi. Work is still needed to publish osx and win32 wheels.
(PRs for this would be helpful!),What version of Python do I need?,Both line_profiler and kernprof have been tested with Python 3.5-3.9.
Older versions of line_profiler support older versions of Python.,cProfile uses a neat ""rotating trees"" data structure to minimize the overhead of
looking up and recording entries. LineProfiler uses Python dictionaries and
extension objects thanks to Cython. This mostly started out as a prototype that
I wanted to play with as quickly as possible, so I passed on stealing the
rotating trees for now. As usual, I got it working, and it seems to have
acceptable performance, so I am much less motivated to use a different strategy
now. Maybe later. Contributions accepted!,Bugs and pull requested can be submitted on ,.,See ,.,
      Line-by-line profiling for Python
    "
name,content
nvidia-nvtx-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
huggingface-hub,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,huggingface/huggingface_hub,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        All the open source things related to the Hugging Face Hub.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
  ,
    ,
  ,
,
    ,
,
    ,
    ,
    ,
    ,
    ,
,: ,: ,The , library allows you to interact with the ,, a platform democratizing open-source Machine Learning for creators and collaborators. Discover pre-trained models and datasets for your projects or play with the thousands of machine learning apps hosted on the Hub. You can also create and share your own models, datasets and demos with the community. The , library provides a simple way to do all these things with Python.,Install the , package with ,:,If you prefer, you can also install it with ,.,In order to keep the package minimal by default, , comes with optional dependencies useful for some use cases. For example, if you want have a complete experience for Inference, run:,To learn more installation and optional dependencies, check out the ,.,Download a single file,Or an entire repository,Files will be downloaded in a local cache folder. More details in ,.,The Hugging Face Hub uses tokens to authenticate applications (see ,). To login your machine, run the following CLI:,Upload a single file,Or an entire folder,For details in the ,.,We're partnering with cool open source ML libraries to provide free model hosting and versioning. You can find the existing integrations ,.,The advantages are:,If you would like to integrate your library, feel free to open an issue to begin the discussion. We wrote a , with ❤️ showing how to do this integration.,Everyone is welcome to contribute, and we value everybody's contribution. Code is not the only way to help the community.
Answering questions, helping others, reaching out and improving the documentations are immensely valuable to the community.
We wrote a , to summarize
how to get started to contribute to this repository.,
      All the open source things related to the Hugging Face Hub.
    "
name,content
mdv,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,axiros/terminal_markdown_viewer,Name already in use,Terminal Markdown Viewer,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Styled Terminal Markdown Viewer
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,When you edit multiple md files remotely, like in a larger
, project, context switches between editing
terminal(s) and viewing browser may have some efficiency impact.
Also sometimes there is just no browser, like via security gateways offering
just a fixed set of applications on the hop in machine.
Further, reading efficiency and convenience is often significantly improved
by using colors.
And lastly, using such a thing for cli applications might improve user output,
e.g. for help texts.,This is where mdv, a Python based Markdown viewer for the terminal might be
a good option.,If markdown is often ""simple"" enough to be somewhat readable on 256 color terminals (except images that is).,from,You can also use mdv as a , viewer, best when you have docstrings with markdown in your code:,from,(the '_' after the docstring telling mdv that markdown follows),mdv is a proof of concept hack: While for simple structures it does its job quite well, for complex markdown you want to use other tools.
Especially for inlined html it simply fails.,The ones I know of (and which made me write mdv ;-) ):,Summary: For production ready robust markdown viewing (e.g. for your customers) I recommend nd still, due to the early state of mdv. For playing around, especially with theming or when with Python, this one might be a valid alternative to look at.,If you get ,: update your markdown package., is a macport (thanks Aljaž).,mdv is also available in the FreeBSD package repositories via , (the Python version might change in the future).,Further a 256 color terminal (for now best with dark background) and font support for a few special separator characters (which you could change via config).,For light terms you'd just need to revert the 5 colors from the themes, since they are sorted by luminocity.,I did not test anything on windows.,Regarding the strange theme ids: Those numbers are the calculated total luminocity of the 5 theme colors.,mdv is designed to be used well from other (Py2) programs when they have md at hand which should be displayed to the user:,Note that I set the defaultencoding to utf-8  in ,. I have this as my default python2 setup and did not test inline usage w/o. Check , for risks.,'s
, is a great framework for writing larger CLI apps - but its help texts are a bit boring, intended to be customized.,Here is how:,Write a normal click module with a function but w/o a doc string as shown:,On module level you provide markdown for it, like:,which you set at click module import time:,Lastly do this in your app module:,The output has then colors:,and at smaller terms rewraps nicely:,Further, having markdown in the module , makes it simple to add into a global project docu framework, like mkdocs.,You can supply all CLI args in ,, in yaml format.,More flex you have via ,, which is execed if present, when
running ,.,Alternatively, in , you can change some config straight forward.,Any importing module can overwrite those module global variables as well.,Should you need yet additional themes, add them to , file by adding your ansi codes there.,Random results, using the theme roller feature:,Note the table block splitting when the table does not fit (last picture).,Rendering this readme ,:,markdown did better than commonmark w/o extensions but table and fenced code
are definitelly required for 99% users.,paka is a wrapper around the C reference lib -> requires compilation.,mistletoe is pure python, crazy that they are so much faster than CommonMark.
They say in pypy they are speed up even much more.,mistletoe downside: py2 only via a fork., (using their lexer),and, naturally, the ,Update: Next version will be CommonMark based though...,Sort of an excuse for the long long time w/o an update:
I did actually start working on a more solid version based on CommonMark but
that went a bit out of scope, into a general html terminal viewer, which will
probably never be finished :-/,So at least here an update containing the stuff you guys sent as PRs, thanks all!!,Also:,travis,Inline link tables,
      Styled Terminal Markdown Viewer
    "
name,content
multidict,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,aio-libs/multidict,Name already in use,multidict,key-value pairs,HTTP Headers,URL query string,multidict,values,key,preserves insertion ordering,key,Case insensitive,keys,Keys,Alpine Linux,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        The multidict implementation
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Multidict is dict-like collection of , where key
might occur more than once in the container., and , require specific data structure:
,. It behaves mostly like a regular , but it may have
several , for the same , and ,.,The , is , (or , for case-insensitive dictionaries)., has four multidict classes:
,, ,, ,
and ,.,Immutable proxies (, and
,) provide a dynamic view for the
proxied multidict, the view reflects underlying collection changes. They
implement the , interface.,Regular mutable (, and ,) classes
implement , and allows them to change
their own content., (, and
,) assume the , are case
insensitive, e.g.:, should be , or , instances.,The library has optional C Extensions for speed.,Apache 2,The library is Python 3 only!,PyPI contains binary wheels for Linux, Windows and MacOS.  If you want to install
, on another operating system (or , inside a Docker) the
tarball will be used to compile the library from source.  It requires a C compiler and
Python headers to be installed.,To skip the compilation, please use the MULTIDICT_NO_EXTENSIONS environment variable,
e.g.:,Please note, the pure Python (uncompiled) version is about 20-50 times slower depending on
the usage scenario!!!,See ,.,
      The multidict implementation
    "
name,content
billiard,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,celery/billiard,Name already in use,billiard,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Multiprocessing Pool Extensions
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , , , , is a fork of the Python 2.7 ,
package. The multiprocessing package itself is a renamed and updated version of
R Oudkerk's , package.
This standalone variant draws its fixes/improvements from python-trunk and provides
additional bug fixes and improvements.,The documentation for , is available on ,.,Please report bugs related to multiprocessing at the
,. Issues related to billiard
should be reported at ,.,The maintainers of , and thousands of other packages are working
with Tidelift to deliver commercial support and maintenance for the open source
dependencies you use to build your applications. Save time, reduce risk, and
improve code health, while paying the maintainers of the exact dependencies you
use. ,.,
      Multiprocessing Pool Extensions
    "
name,content
frozendict,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Marco-Sulla/python-frozendict,Name already in use,frozendict,Introduction,API,Examples,Building,Benchmarks,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A simple immutable dictionary for python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Welcome, fellow programmer!, is a simple immutable dictionary. It's fast as ,, and
,!,Unlike other similar implementations, immutability is guaranteed: you can't
change the internal variables of the class, and they are all immutable
objects.  Reinvoking , does not alter the object.,The API is the same as ,, without methods that can change the
immutability. So it supports also ,, unlike other implementations.
Furthermore it can be ,d, un,d and have an hash, if all values
are hashable.,You can also add any , to a , using the , operator. The result is a new ,.,The API is the same of , of Python 3.10, without the methods and operands which alter the map. Additionally, , supports these methods:,If all the values of the , are hashable, returns an hash, otherwise raises a TypeError.,It returns a new ,. If key is already in the original ,, the new one will have it with the new value associated. Otherwise, the new , will contain the new (key, value) item.,It returns a new , without the item corresponding to the key. If the key is not present, a KeyError is raised.,If key is already in ,, the object itself is returned unchanged. Otherwise, the new , will contain the new (key, default) item. The parameter default defaults to None.,It returns the key at the specified index (determined by the insertion order). If index is not passed, it defaults to 0. If the index is negative, the position will be the size of the , + index,Same as ,, but it returns the value at the given index.,Same as ,, but it returns a tuple with (key, value) at the given index.,You can build , directly from the code, using,The C Extension is optional by default from version 2.3.5. You can make it mandatory by passing the environment variable , with value ,Some benchmarks between , and ,[1]:,[1] Benchmarks done under Linux 64 bit, Python 3.10.2, using the C Extension.,
      A simple immutable dictionary for python
    "
name,content
channels,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,django/channels,Name already in use,Django Channels,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Developer-friendly asynchrony for Django
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Channels augments Django to bring WebSocket, long-poll HTTP,
task offloading and other async support to your code, using familiar Django
design patterns and a flexible underlying framework that lets you not only
customize behaviours but also write support for your own protocols and needs.,Documentation, installation and getting started instructions are at
,Channels is an official Django Project and as such has a deprecation policy.
Details about what's deprecated or pending deprecation for each release is in
the ,.,Support can be obtained through several locations - see our
, for more.,You can install channels from PyPI as the , package.
See our ,
and , docs for more.,All Channels projects currently support Python 3.7 and up. , is
compatible with Django 3.2, 4.0, 4.1, and 4.2.,To learn more about contributing, please ,.,To report security issues, please contact ,. For GPG
signatures and more security process information, see
,.,To report bugs or request new features, please open a new GitHub issue. For
larger discussions, please post to the
,.,Maintenance is overseen by Carlton Gibson with help from others. It is a
best-effort basis - we unfortunately can only dedicate guaranteed time to fixing
security holes.,If you are interested in joining the maintenance team, please
,
and get in touch!,The Channels project is made up of several packages; the others are:,
      Developer-friendly asynchrony for Django
    "
name,content
jinja2-time,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,hackebrot/jinja2-time,Name already in use,Jinja2 Time,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        , Jinja2 Extension for Dates and Times
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , ,Jinja2 Extension for Dates and Times, is available for download from , via ,:,It will automatically install , along with ,.,The extension comes with a , tag that provides convenient access to the
, API from your templates.,You can control the output by specifying a format, that will be passed to
Python's ,:, extends the environment with a , attribute.,It is used as a fallback if you omit the format for ,., implements a convenient interface to modify , by a
relative time offset:,Further documentation on the underlying functionality can be found in the
,.,If you encounter any problems, please , along with a detailed description.,Everyone interacting in the jinja2-time project's codebases, issue trackers, chat
rooms, and mailing lists is expected to follow the ,.,Distributed under the terms of the , license, jinja2-time is free and open source software,
      , Jinja2 Extension for Dates and Times
    "
name,content
colander,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Pylons/colander,Name already in use,Colander,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A serialization/deserialization/validation library for strings, mappings and lists.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,An extensible package which can be used to:,It is tested on Python 3.7, 3.8, 3.9, 3.10, and 3.11, and PyPy 3.8.,Please see ,
for documentation.,See , for in-development version.,
      A serialization/deserialization/validation library for strings, mappings and lists.
    "
name,content
pip,"pip,pip is the ,. You can use it to
install packages from the , and other indexes.,If you want to learn about how to use pip, check out the following resources:,If you find bugs, need help, or want to talk to the developers, use our mailing
lists or chat rooms:,If you find any security issues, please report to "
name,content
matplotlib,"Matplotlib: Visualization with Python,Matplotlib,
Matplotlib is a comprehensive library for creating static, animated,
and interactive visualizations in Python. Matplotlib makes easy things
easy and hard things possible.
,
Thanks to the Google Summer of Code (GSOC) program, Ratnabali Dutta joins us this summer to work on improving our mathematical typesetting module ,.
,
Thanks to funding from the Google Season of Docs (GSOD) program, Eva Sibinga will be joining us to work on ,.
,
How can we be better when it comes to diversity and inclusion?
,
Be sure to check the
, and the
,. The full text
, is a
good way to discover the docs including the many examples.
,
Join our community at
,
to get help, share your work, and discuss contributing &
development.
,
Check out the Matplotlib tag on
,.
,
Meet us at our monthly call for new contributors to the Matplotlib
project. Subscribe to our
,
at Scientific Python to get access to all our community meetings.
,
Short questions related to contributing to Matplotlib may be posted on the
,
channel.
,
A large number of third party packages extend and build on Matplotlib
functionality, including several higher-level plotting interfaces
(seaborn, HoloViews, ggplot, ...), and a projection and mapping
toolkit (Cartopy).
,
seaborn is a high level interface for drawing statistical graphics
with Matplotlib. It aims to make visualization a central part of
exploring and understanding complex datasets.
,
Cartopy is a Python package designed for geospatial data
processing in order to produce maps and other geospatial data
analyses.
,
DNA Features Viewer is a Python library to visualize DNA features,
e.g. from GenBank or Gff files, or Biopython SeqRecords.
,
plotnine is an implementation of a grammar of graphics in Python.
The grammar allows users to compose plots by explicitly mapping
data to the visual objects that make up the plot.
,
WCSAxes is a framework for making plots of Astronomical data in
Matplotlib.
,
Matplotlib is a community project maintained for and by its users
,
You can help by answering questions
,,
reporting a bug or requesting a feature
,, or improving the
,!
,
Matplotlib is the result of development efforts by John Hunter
(1968–2012) and the project's
,.
,
If Matplotlib contributes to a project that leads to a scientific
publication, please acknowledge this work by citing the project!
,
If you would like to support Matplotlib financially you can
donate by
,
or making a (USA) tax-deductible donation
,.
,© 2012 – 2023 The Matplotlib development team"
name,content
backcall,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,takluyver/backcall,Name already in use,backcall,backcall,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Backwards compatible callback APIs
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Specifications for callback functions passed in to an API,If your code lets other people supply callback functions, it's important to
specify the function signature you expect, and check that functions support that.
Adding extra parameters later would break other peoples code unless you're careful.,backcall provides a way of specifying the callback signature using a prototype
function:,If the callback takes fewer parameters than your prototype, , will wrap
it in a function that discards the extra arguments. If the callback expects
more arguments, a TypeError is thrown when it is registered.,For more details, see the , or
the ,.,The tests are run with ,. In the root directory,
execute:,
      Backwards compatible callback APIs
    "
name,content
importlib-resources,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python/importlib_resources,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Backport of the importlib.resources module
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a backport of Python standard library
,
module for older Pythons.,The key goal of this module is to replace parts of , with a
solution in Python's stdlib that relies on well-defined APIs.  This makes
reading resources included in packages easier, with more stable and consistent
semantics.,New features are introduced in this third-party library and later merged
into CPython. The following table indicates which versions of this library
were contributed to different versions in the standard library:,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,.,
      Backport of the importlib.resources module
    "
name,content
json5,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,dpranke/pyjson5,Name already in use,pyjson5,is,Note: This is a
potentially breaking change.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A Python implementation of the JSON5 data format
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A Python implementation of the JSON5 data format., extends the
, data interchange format to make it
slightly more usable as a configuration language:,JavaScript-style comments (both single and multi-line) are legal.,Object keys may be unquoted if they are legal ECMAScript identifiers,Objects and arrays may end with trailing commas.,Strings can be single-quoted, and multi-line string literals are allowed.,There are a few other more minor extensions to JSON; see the above page for
the full details.,This project implements a reader and writer implementation for Python;
where possible, it mirrors the
,
package for ease of use.,There is one notable difference from the JSON api: the , and
, methods support optionally checking for (and rejecting) duplicate
object keys; pass , to do so (duplicates are
allowed by default).,This is an early release. It has been reasonably well-tested, but it is
,. It can be 1000-6000x slower than the C-optimized JSON module,
and is 200x slower (or more) than the pure Python JSON module., This library only handles JSON5 documents, it does not
allow you to read arbitrary JavaScript. For example, bare integers can
be legal object keys in JavaScript, but they aren't in JSON5.,Did I mention that it is ,?,The implementation follows Python3's , implementation where
possible. This means that the , method to , is
ignored, and unicode strings are always returned.,The , keyword argument that ,/, accepts
to specify a custom subclass of , is not and will not be
supported, because this implementation uses a completely different
approach to parsing strings and doesn't have anything like the
, class.,The , keyword argument that ,/, accepts
is also not supported, for consistency with ,. The ,
keyword , supported, though, and might be able to serve as a
workaround.,To run the tests, setup a venv and install the required dependencies with
,, then run the tests with ,.,v0.9.14 (2023-05-14),v0.9.13 (2023-03-16),v0.9.12 (2023-01-02),v0.9.11 (2023-01-02),v0.9.10 (2022-08-18),v0.9.9 (2022-08-01),v0.9.8 (2022-05-08),v0.9.7 (2022-05-06),v0.9.6 (2021-06-21),v0.9.5 (2020-05-26),v0.9.4 (2020-03-26),v0.9.3 (2020-03-17),v0.9.2 (2020-03-02),v0.9.1 (2020-02-09),v0.9.0 (2020-01-30),v0.8.5 (2019-07-04),v0.8.4 (2019-06-11),v0.8.3 (2019-06-11),v0.8.2 (2019-06-11),v0.8.1 (2019-06-11),v0.8.0 (2019-06-11),v0.7 (2019-03-31),v0.6.2 (2019-03-08),v0.6.1 (2018-05-22),v0.6.0 (2017-11-28),v0.5.0 (2017-09-04),
      A Python implementation of the JSON5 data format
    "
name,content
jaraco.context,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jaraco/jaraco.context,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,."
name,content
evdev,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,gvalkov/python-evdev,Name already in use,evdev,evdev,uinput,Uinput,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python bindings for the Linux input subsystem
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This package provides bindings to the generic input event interface in
Linux. The , interface serves the purpose of passing events
generated in the kernel directly to userspace through character
devices that are typically located in ,.,This package also comes with bindings to ,, the userspace input
subsystem. , allows userspace programs to create and handle
input devices that can inject events directly into the input
subsystem.,
      Python bindings for the Linux input subsystem
    "
name,content
cloudpickle,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,cloudpipe/cloudpickle,Name already in use,cloudpickle,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Extended pickling support for Python objects
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
, makes it possible to serialize Python constructs not supported
by the default , module from the Python standard library., is especially useful for , where Python
code is shipped over the network to execute on remote hosts, possibly close
to the data.,Among other things, , supports pickling for ,
along with , in the
, module (for instance in a script, a shell or a Jupyter notebook).,Cloudpickle can only be used to send objects between the ,.,Using , for ,: one should , as
otherwise , can lead to arbitrary code execution resulting in a critical
security vulnerability.,The latest release of , is available from
,:,Pickling a lambda expression:,Pickling a function interactively defined in a Python shell session
(in the , module):,An important difference between , and , is that
, can serialize a function or class ,, whereas ,
can only serialize it ,. Serialization by reference treats
functions and classes as attributes of modules, and pickles them through
instructions that trigger the import of their module at load time.
Serialization by reference is thus limited in that it assumes that the module
containing the function or class is available/importable in the unpickling
environment. This assumption breaks when pickling constructs defined in an
interactive session, a case that is automatically detected by ,,
that pickles such constructs ,.,Another case where the importability assumption is expected to break is when
developing a module in a distributed execution environment: the worker
processes may not have access to the said module, for example if they live on a
different machine than the process in which the module is being developed.
By itself, , cannot detect such ""locally importable"" modules and
switch to serialization by value; instead, it relies on its default mode,
which is serialization by reference. However, since ,, one
can explicitly specify modules for which serialization by value should be used,
using the ,/, API:,Using this API, there is no need to re-install the new version of the module on
all the worker nodes nor to restart the workers: restarting the client Python
process with the new source code is enough.,Note that this feature is still ,, and may fail in the following
situations:,If the body of a function/class pickled by value contains an , statement:,If a function pickled by reference uses a function pickled by value during its execution.,With ,, to test run the tests for all the supported versions of
Python and PyPy:,or alternatively for a specific environment:,With , to only run the tests for your current version of
Python:, was initially developed by , and shipped as part of
the client SDK.,A copy of , was included as part of PySpark, the Python
interface to ,. Davies Liu, Josh
Rosen, Thom Neale and other Apache Spark developers improved it significantly,
most notably to add support for PyPy and Python 3.,The aim of the , project is to make that work available to a wider
audience outside of the Spark ecosystem and to make it easier to improve it
further notably with the help of a dedicated non-regression test suite.,
      Extended pickling support for Python objects
    "
name,content
pip-search,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,victorgarric/pip_search,Name already in use,pip_search,(deleted for compatibility issues with python 3.8 to 3.10),We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Searching thought pip when hard times strike
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Install with ,Use with ,You can specify sorting options :,To use as the traditional , method, add this alias to your ,For fish users, run on fish shell:,Then run with ,Hold the , or , key to click on the folder icons as a hyperlink.,0.0.12,0.0.11,0.0.10,0.0.9,0.0.8 ,0.0.7,0.0.6,0.0.4,
      Searching thought pip when hard times strike
    "
name,content
agate-dbf,"agate-dbf 0.2.3,API,agate-dbf adds read support for dbf files to ,.,Important links:,agate             ,Documentation:    ,Repository:       ,Issues:           ,To install:,For details on development or supported platforms see the ,.,agate-dbf uses a monkey patching pattern to add read for dbf files support to all , instances.,Importing agate-dbf adds new methods to ,.,Parse a DBF file., – Path to an DBF file to load. Note that due to limitations of the
dependency you can not pass a file handle. It must be a path.,The following individuals have contributed code to agate-excel:,Drop support for Python 2.7 (EOL 2020-01-01), 3.4 (2019-03-18), 3.5 (2020-09-13).,No longer lowercase column names.,agate-dbf is now tested against Python 3.6 and 3.7.,Drop support for Python 3.3 (EOL 2017-09-29).,Remove dependency on monkeypatching.,Upgrade required agate to ,.,Initial version.,The MIT License,Copyright (c) 2016 Christopher Groskopf and contributors,Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:,The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.,THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE."
name,content
case,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,celery/case,Name already in use,Python unittest utilities,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python unittest Utilities
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , , , ,You can install case either via the Python Package Index (PyPI)
or from source.,To install using pip,:,To install using easy_install,:,Download the latest version of case from
,You can install it by doing the following,:,The last command must be executed as a privileged user if
you are not currently using a virtualenv.,You can install the latest snapshot of case using the following
pip command:,
      Python unittest Utilities
    "
name,content
outcome,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-trio/outcome,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Capture the outcome of Python function calls
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Welcome to ,!,Capture the outcome of Python function calls. Extracted from the
, project.,License: Your choice of MIT or Apache License 2.0,
      Capture the outcome of Python function calls
    "
name,content
priority,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-hyper/priority,Name already in use,Priority: A HTTP/2 Priority Implementation,blocked,may,will,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A pure-Python implementation of the HTTP/2 priority tree.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Priority is a pure-Python implementation of the priority logic for HTTP/2, set
out in ,. This logic allows for clients
to express a preference for how the server allocates its (limited) resources to
the many outstanding HTTP requests that may be running over a single HTTP/2
connection.,Specifically, this Python implementation uses a variant of the implementation
used in the excellent , project. This original implementation is also the
inspiration for , priority implementation, and generally produces a
very clean and even priority stream. The only notable changes from H2O's
implementation are small modifications to allow the priority implementation to
work cleanly as a separate implementation, rather than being embedded in a
HTTP/2 stack directly.,While priority information in HTTP/2 is only a suggestion, rather than an
enforceable constraint, where possible servers should respect the priority
requests of their clients.,Priority has a simple API. Streams are inserted into the tree: when they are
inserted, they may optionally have a weight, depend on another stream, or
become an exclusive dependent of another stream.,Once streams are inserted, the stream priorities can be requested. This allows
the server to make decisions about how to allocate resources.,The tree in this algorithm acts as a gate. Its goal is to allow one stream
""through"" at a time, in such a manner that all the active streams are served as
evenly as possible in proportion to their weights.,This is handled in Priority by iterating over the tree. The tree itself is an
iterator, and each time it is advanced it will yield a stream ID. This is the
ID of the stream that should next send data.,This looks like this:,If each stream only sends when it is 'ungated' by this mechanism, the server
will automatically be emitting stream data in conformance to RFC 7540.,If for any reason a stream is unable to proceed (for example, it is blocked on
HTTP/2 flow control, or it is waiting for more data from another service), that
stream is ,. The , should be informed that the stream is
blocked so that other dependent streams get a chance to proceed. This can be
done by calling the , method of the tree with the stream ID that is
currently unable to proceed. This will automatically update the tree, and it
will adjust on the fly to correctly allow any streams that were dependent on
the blocked one to progress.,For example:,When a stream goes from being blocked to being unblocked, call the ,
method to place it back into the sequence. Both the , and ,
methods are idempotent and safe to call repeatedly.,Additionally, the priority of a stream may change. When it does, the
, method can be used to update the tree in the wake of that
change. , has the same signature as ,, but
applies only to streams already in the tree.,A stream can be entirely removed from the tree by calling ,.
Note that this is not idempotent. Further, calling , and then
re-adding it , cause a substantial change in the shape of the priority
tree, and , cause the iteration order to change.,Priority is made available under the MIT License. For more details, see the
LICENSE file in the repository.,Priority is maintained by Cory Benfield, with contributions from others. For
more details about the contributors, please see CONTRIBUTORS.rst in the
repository.,
      A pure-Python implementation of the HTTP/2 priority tree.
    "
name,content
grapheme,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,alvinlindstam/grapheme,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A python package for grapheme aware string handling
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A Python package for working with user perceived characters. More specifically,
string manipulation and calculation functions for working with grapheme cluster
groups (graphemes) as defined by the ,.,The currently supported version of Unicode: 13.0.0.,Unicode strings are made up of a series of unicode characters, but a unicode character does not
always map to a user perceived character. Some human perceived characters are represented as two
or more unicode characters.,However, all built in python string functions and string methods work with single unicode characters
without considering their connection to each other.,This library implements the unicode default rules for extended grapheme clusters, and provides
a set of functions for string manipulation based on graphemes.,See ,.,You should consider working with graphemes over unicode code points when:,You should work with normal python string functions when:,Calculating graphemes require traversing the string and checking each character
against a set of rules and the previous character(s). Because of this, all
functions in this module will scale linearly to the string length.,Whenever possible, they will only traverse the string for as long as needed and return
early as soon as the requested output is generated. For example, the grapheme.slice
function only has to traverse the string until the last requested grapheme is found, and
does not care about the rest of the string.,You should probably only use this package for testing/manipulating fairly short strings
or with the beginning of long strings.,When testing with a string of 10 000 ascii characters, and a 3.1 GHz processor, the execution
time for some possible calls is roughly:,Execution times may improve in later releases, but calculating graphemes is and will continue
to be notably slower than just counting unicode code points.,This is not a complete list, but a some examples of when graphemes use multiple
characters:,If you wish to contribute or edit this package, create a fork and clone it.,Then install in locally editable (,) mode and run the tests.,The library will issue a new release for each new unicode version.,The steps necessary for this:,
      A python package for grapheme aware string handling
    "
name,content
dateparser,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,scrapinghub/dateparser,Name already in use,
    ,
    ,
    ,
,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        python parser for human readable dates
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
    ,
    ,
    ,
    ,
    ,
,
    , •
    , •
    , •
    , •
    , •
    ,
,Do you want to try it out without installing any dependency? Now you can test
it quickly by visiting ,!,The most straightforward way to parse dates with , is to
use the , function, that wraps around most of the
functionality of the module.,As you can see, , works with different date formats, but it
can also be used directly with strings in different languages:,You can control multiple behaviors by using the , parameter:,To see more examples on how to use the ,, check the ,
in the docs., will do its best to return a date, dealing with multiple formats and different locales.
For that reason it is important that the input is a valid date, otherwise it could return false positives.,To reduce the possibility of receiving false positives, make sure that:,On the other hand, if you want to exclude any of the default parsers
(,, ,...) or change the order in which they
are executed, you can do so through the
,.,Dateparser supports Python >= 3.7. You can install it by doing:,If you want to use the jalali or hijri calendar, you need to install the
, extra:, can be used with a really different number of purposes,
but it stands out when it comes to:,
      python parser for human readable dates
    "
name,content
beautifulsoup4,"Beautiful Soup,[ , | , | , | , | , | , | ,  | , ],You didn't write that awful page. You're just trying to get some
data out of it. Beautiful Soup is here to help. Since 2004, it's been
saving programmers hours or days of work on quick-turnaround
screen scraping projects.,Beautiful Soup is a Python library designed for quick turnaround
projects like screen-scraping. Three features make it powerful:

,Beautiful Soup parses anything you give it, and does the tree
traversal stuff for you. You can tell it ""Find all the links"", or
""Find all the links of class ,"", or ""Find all the
links whose urls match ""foo.com"", or ""Find the table heading that's
got bold text, then give me that text.""

,Valuable data that was once locked up in poorly-designed websites
is now within your reach. Projects that would have taken hours take
only minutes with Beautiful Soup.

,Interested? ,

,If you have questions, send them to ,. If you find a bug, ,. If it's a security vulnerability, report it confidentially through ,.,If you use Beautiful Soup as part of your work, please consider a ,. This will support many of the free software projects your organization depends on, not just Beautiful Soup.


,If Beautiful Soup is useful to you on a personal level, you might like to read ,, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!,The current release is , (April 7, 2023). You can install Beautiful Soup 4 with
,.

,In Debian and Ubuntu, Beautiful Soup is available as the
, package. In Fedora it's
available as the , package.

,Beautiful Soup is licensed under the MIT license, so you can also
download the tarball, drop the , directory into almost
any Python application (or into your library path) and start using it
immediately.

,Beautiful Soup 4 is supported on Python versions 3.6 and
greater. Support for Python 2 was discontinued on January 1, 2021—one
year after the Python 2 sunsetting date.

,Beautiful Soup 3 was the official release line of Beautiful Soup
from May 2006 to March 2012. It does not support Python 3 and was
discontinued or January 1, 2021—one year after the Python 2
sunsetting date. If you have any active projects using Beautiful Soup
3, you should migrate to Beautiful Soup 4 as part of your Python 3
conversion.

,

,The current and hopefully final release of Beautiful Soup 3 is , (October 5,
2019). It's the , package on pip. It's also
available as , in Debian and Ubuntu,
and as , in Fedora.

,Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.

,Beautiful Soup 3, like Beautiful Soup 4, is ,.,Over the years, Beautiful Soup has been used in hundreds of
different projects. There's no way I can list them all, but I want to
highlight a few high-profile projects. Beautiful Soup isn't what makes
these projects interesting, but it did make their completion easier:

,If you've used Beautiful Soup in a project you'd like me to know
about, please do send email to me or ,.

,Development happens at ,. You can , or ,.,This document is part of Crummy, the webspace of , (,). It was last modified on Friday, April 07 2023, 19:56:57 Nowhere Standard Time and last built on Thursday, July 27 2023, 01:00:01 Nowhere Standard Time.,
"
name,content
defusedxml,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,tiran/defusedxml,Name already in use,defusedxml -- defusing XML bombs and other exploits,Changelog,DTDForbidden,EntitiesForbidden,ExternalReferenceForbidden,experimental,example,Release date: 4-Mar-2021,Release date: 12-Jan-2021,Release date: 04-May-2020,Release date: 17-Apr-2019,Release date: 14-Apr-2019,html,Release date: 07-Feb-2017,Release date: 28-Jan-2017,Release date: 28-Mar-2013,Release date: 25-Feb-2013,Release date: 19-Feb-2013,Release date: 15-Feb-2013,Release date: 08-Feb-2013,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,Christian Heimes <,>,The results of an attack on a vulnerable XML library can be fairly
dramatic. With just a few hundred , of XML data an attacker can
occupy several , of memory within ,. An attacker
can also keep CPUs busy for a long time with a small to medium size
request. Under some circumstances it is even possible to access local
files on your server, to circumvent a firewall, or to abuse services to
rebound attacks to third parties.,The attacks use and abuse less common features of XML and its parsers.
The majority of developers are unacquainted with features such as
processing instructions and entity expansions that XML inherited from
SGML. At best they know about , from experience with HTML but
they are not aware that a document type definition (DTD) can generate an
HTTP request or load a file from the file system.,None of the issues is new. They have been known for a long time. Billion
laughs was first reported in 2003. Nevertheless some XML libraries and
applications are still vulnerable and even heavy users of XML are
surprised by these features. It's hard to say whom to blame for the
situation. It's too short sighted to shift all blame on XML parsers and
XML libraries for using insecure default settings. After all they
properly implement XML specifications. Application developers must not
rely that a library is always configured for security and potential
harmful data by default.,Table of Contents,The ,
attack -- also known as exponential entity expansion --uses multiple
levels of nested entities. The original example uses 9 levels of 10
expansions in each level to expand the string , to a string of 3 *
10 , bytes, hence the name ""billion laughs"". The resulting
string occupies 3 GB (2.79 GiB) of memory; intermediate strings require
additional memory. Because most parsers don't cache the intermediate
step for every expansion it is repeated over and over again. It
increases the CPU load even more.,An XML document of just a few hundred bytes can disrupt all services on
a machine within seconds.,Example XML:,A quadratic blowup attack is similar to a , attack; it abuses
entity expansion, too. Instead of nested entities it repeats one large
entity with a couple of thousand chars over and over again. The attack
isn't as efficient as the exponential case but it avoids triggering
countermeasures of parsers against heavily nested entities. Some parsers
limit the depth and breadth of a single entity but not the total amount
of expanded text throughout an entire XML document.,A medium-sized XML document with a couple of hundred kilobytes can
require a couple of hundred MB to several GB of memory. When the attack
is combined with some level of nested expansion an attacker is able to
achieve a higher ratio of success.,Entity declarations can contain more than just text for replacement.
They can also point to external resources by public identifiers or
system identifiers. System identifiers are standard URIs. When the URI
is a URL (e.g. a , locator) some parsers download the resource
from the remote location and embed them into the XML document verbatim.,Simple example of a parsed external entity:,The case of parsed external entities works only for valid XML content.
The XML standard also supports unparsed external entities with a ,.,External entity expansion opens the door to plenty of exploits. An
attacker can abuse a vulnerable XML library and application to rebound
and forward network requests with the IP address of the server. It
highly depends on the parser and the application what kind of exploit is
possible. For example:,External entities with references to local files are a sub-case of
external entity expansion. It's listed as an extra attack because it
deserves extra attention. Some XML libraries such as lxml disable
network access by default but still allow entity expansion with local
file access by default. Local files are either referenced with a
, URL or by a file path (either relative or absolute).,An attacker may be able to access and download all files that can be
read by the application process. This may include critical configuration
files, too.,This case is similar to external entity expansion, too. Some XML
libraries like Python's xml.dom.pulldom retrieve document type
definitions from remote or local locations. Several attack scenarios
from the external entity case apply to this issue as well.,vulnerabilities and features,feature_external_ges
(,),
disables external entity expansion,feature_external_pes
(,),
the option is ignored and doesn't modify any functionality,external_parameter_entities,
ignored,external_general_entities,
ignored,external_dtd_subset,
ignored,entities,
unsure,The ,
(,) contains
several Python-only workarounds and fixes for denial of service and
other vulnerabilities in Python's XML libraries. In order to benefit
from the protection you just have to import and use the listed functions
/ classes from the right defusedxml module instead of the original
module. Merely , is implemented as
monkey patch.,Instead of:,alter code to:,Additionally the package has an , function to monkey patch
all stdlib modules with ,.,All functions and parser classes accept three additional keyword
arguments. They return either the same objects as the original functions
or compatible subclasses.,forbid_dtd (default: False),
disallow XML with a , processing instruction and raise a
, exception when a DTD processing instruction is found.,forbid_entities (default: True),
disallow XML with , declarations inside the DTD and raise
an , exception when an entity is declared.,forbid_external (default: True),
disallow any access to remote or local resources in external
entities or DTD and raising an ,
exception when a DTD or entity references an external resource.,DefusedXmlException, DTDForbidden, EntitiesForbidden,
ExternalReferenceForbidden, NotSupportedError,defuse_stdlib() (,), , is deprecated and will be removed in
a future release. Import from , instead.,parse(), iterparse(), fromstring(), XMLParser,parse(), iterparse(), fromstring(), XMLParser,create_parser(), DefusedExpatParser,parse(), parseString(), make_parser(),parse(), parseString(), DefusedExpatBuilder, DefusedExpatBuilderNS,parse(), parseString(),parse(), parseString(),The fix is implemented as monkey patch for the stdlib's xmlrpc package
(3.x) or xmlrpclib module (2.x). The function
, enables the fixes,
, removes the patch and
puts the code in its former state.,The monkey patch protects against XML related attacks as well as
decompression bombs and excessively large requests or responses. The
default setting is 30 MB for requests, responses and gzip decompression.
You can modify the default by changing the module variable
,. A value of
, disables the limit., The module is deprecated and will be removed in a future
release.,The module acts as an , how you could protect code that uses
lxml.etree. It implements a custom Element class that filters out Entity
instances, a custom parser factory and a thread local storage for parser
instances. It also has a check_docinfo() function which inspects a tree
for internal or external DTDs and entity declarations. In order to check
for entities lxml > 3.0 is required.,parse(), fromstring() RestrictedElement, GlobalParserTLS,
getDefaultParser(), check_docinfo(),The ,
(,)
comes with binary extensions and a , library instead of the standard
,. It's basically a
stand-alone version of the patches for Python's standard library C
extensions.,new definitions:,new XML_FeatureEnum members:,new XML_Error members:,new API functions:,XML_FEATURE_MAX_ENTITY_INDIRECTIONS,
Limit the amount of indirections that are allowed to occur during
the expansion of a nested entity. A counter starts when an entity
reference is encountered. It resets after the entity is fully
expanded. The limit protects the parser against exponential entity
expansion attacks (aka billion laughs attack). When the limit is
exceeded the parser stops and fails with
,. A
value of 0 disables the protection.,Supported range,
0 .. UINT_MAX,Default,
40,XML_FEATURE_MAX_ENTITY_EXPANSIONS,
Limit the total length of all entity expansions throughout the
entire document. The lengths of all entities are accumulated in a
parser variable. The setting protects against quadratic blowup
attacks (lots of expansions of a large entity declaration). When the
sum of all entities exceeds the limit, the parser stops and fails
with ,. A
value of 0 disables the protection.,Supported range,
0 .. UINT_MAX,Default,
8 MiB,XML_FEATURE_RESET_DTD,
Reset all DTD information after the <!DOCTYPE> block has been
parsed. When the flag is set (default: false) all DTD information
after the endDoctypeDeclHandler has been called. The flag can be set
inside the endDoctypeDeclHandler. Without DTD information any entity
reference in the document body leads to
,.,Supported range,
0, 1,Default,
0,(based on Brad Hill's ,),XML, XML parsers and processing libraries have more features and
possible issue that could lead to DoS vulnerabilities or security
exploits in applications. I have compiled an incomplete list of
theoretical issues that need further research and more attention. The
list is deliberately pessimistic and a bit paranoid, too. It contains
things that might go wrong under daffy circumstances.,XML parsers may use an algorithm with quadratic runtime O(n
,) to handle attributes and namespaces. If it uses hash
tables (dictionaries) to store attributes and namespaces the
implementation may be vulnerable to hash collision attacks, thus
reducing the performance to O(n ,) again. In either case an
attacker is able to forge a denial of service attack with an XML
document that contains thousands upon thousands of attributes in a
single node.,I haven't researched yet if expat, pyexpat or libxml2 are vulnerable.,The issue of decompression bombs (aka ,) apply to all XML
libraries that can parse compressed XML stream like gzipped HTTP streams
or LZMA-ed files. For an attacker it can reduce the amount of
transmitted data by three magnitudes or more. Gzip is able to compress 1
GiB zeros to roughly 1 MB, lzma is even better:,None of Python's standard XML libraries decompress streams except for
,. The module is vulnerable
<,> to decompression bombs.,lxml can load and process compressed data through libxml2 transparently.
libxml2 can handle even very large blobs of compressed data efficiently
without using too much memory. But it doesn't protect applications from
decompression bombs. A carefully written SAX or iterparse-like approach
can be safe.,'s like:,may impose more threats for XML processing. It depends if and how a
processor handles processing instructions. The issue of URL retrieval
with network or local file access apply to processing instructions, too., has more
features like ,. I haven't researched how these features may
be a security threat.,XPath statements may introduce DoS vulnerabilities. Code should never
execute queries from untrusted sources. An attacker may also be able to
create an XML document that makes certain XPath queries costly or
resource hungry.,XPath injeciton attacks pretty much work like SQL injection attacks.
Arguments to XPath queries must be quoted and validated properly,
especially when they are taken from the user. The page ,
list some ramifications of XPath injections.,Python's standard library doesn't have XPath support. Lxml supports
parameterized XPath queries which does proper quoting. You just have to
use its xpath() method correctly:, is
another way to load and include external files:,This feature should be disabled when XML files from an untrusted source
are processed. Some Python XML libraries and libxml2 support XInclude
but don't have an option to sandbox inclusion and limit it to allowed
directories.,A validating XML parser may download schema files from the information
in a , attribute.,You should keep in mind that XSLT is a Turing complete language. Never
process XSLT code from unknown or untrusted source! XSLT processors may
allow you to interact with external resources in ways you can't even
imagine. Some processors even support extensions that allow read/write
access to file system, access to JRE objects or scripting with Jython.,Example from ,
for Xalan-J:,CVE-2013-1664,
Unrestricted entity expansion induces DoS vulnerabilities in Python
XML libraries (XML bomb),CVE-2013-1665,
External entity expansion in Python XML libraries inflicts potential
security flaws and DoS vulnerabilities,Several other programming languages and frameworks are vulnerable as
well. A couple of them are affected by the fact that libxml2 up to 2.9.0
has no protection against quadratic blowup attacks. Most of them have
potential dangerous default settings for entity expansion and external
entities, too.,Perl's XML::Simple is vulnerable to quadratic entity expansion and
external entity expansion (both local and remote).,Ruby's REXML document parser is vulnerable to entity expansion attacks
(both quadratic and exponential) but it doesn't do external entity
expansion by default. In order to counteract entity expansion you have
to disable the feature:,libxml-ruby and hpricot don't expand entities in their default
configuration.,PHP's SimpleXML API is vulnerable to quadratic entity expansion and
loads entities from local and remote resources. The option
, disables network access but still allows local file
access. , seems to have no effect on entity expansion in
PHP 5.4.6.,Information in , suggest
that .NET is vulnerable with its default settings. The article contains
code snippets how to create a secure XML reader:,Untested. The documentation of Xerces and its ,
sounds like Xerces is also vulnerable to billion laugh attacks with its
default settings. It also does entity resolving when an
, is configured. I'm not yet sure about the
default setting here.,Java specialists suggest to have a custom builder factory:,Copyright (c) 2013-2017 by Christian Heimes <,>,Licensed to PSF under a Contributor Agreement.,See , for licensing details.,Brett Cannon (Python Core developer),
review and code cleanup,Antoine Pitrou (Python Core developer),
code review,Aaron Patterson, Ben Murphy and Michael Koziarski (Ruby community),
Many thanks to Aaron, Ben and Michael from the Ruby community for
their report and assistance.,Thierry Carrez (OpenStack),
Many thanks to Thierry for his report to the Python Security
Response Team on behalf of the OpenStack security team.,Carl Meyer (Django),
Many thanks to Carl for his report to PSRT on behalf of the Django
security team.,Daniel Veillard (libxml2),
Many thanks to Daniel for his insight and assistance with libxml2.,semantics GmbH (,),
Many thanks to my employer semantics for letting me work on the
issue during working hours as part of semantics's open source
initiative."
name,content
jarowinkler,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,maxbachmann/JaroWinkler,Name already in use,
 JaroWinkler
,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python library for fast approximate string matching using Jaro and Jaro-Winkler similarity
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
  ,
  ,
  ,
  ,
,The implementation is based on a novel approach to calculate the Jaro-Winkler similarity using bitparallelism. This is significantly faster than the original approach used in other libraries. The following benchmark shows the performance difference to jellyfish and python-Levenshtein.,
,
,You can install this library from , with pip:,JaroWinkler provides binary wheels for all common platforms.,For a source build (for example from a SDist packaged) you only require a C++14 compatible compiler. You can install directly from GitHub if you would like.,Any algorithms in JaroWinkler can not only be used with strings, but with any arbitary sequences of hashable objects:,So as long as two objects have the same hash they are treated as similar. You can provide a , method for your own object instances.,All algorithms provide a , parameter. This parameter can be used to filter out bad matches. Internally this allows JaroWinkler to select faster implementations in some places:,JaroWinkler can be used with RapidFuzz, which provides multiple methods to compute string metrics on collections of inputs. JaroWinkler implements the RapidFuzz C-API which allows RapidFuzz to call the functions without any of the usual overhead of python, which makes this even faster.,PRs are welcome!,Thank you ❤️,Copyright 2021 - present ,. , is free and open-source software licensed under the ,.,
      Python library for fast approximate string matching using Jaro and Jaro-Winkler similarity
    "
name,content
confection,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,explosion/confection,Name already in use,Confection: The sweetest config system for Python,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        , Confection: the sweetest config system for Python 
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , is a lightweight library that offers a , letting you conveniently describe arbitrary trees of objects.,Configuration is a huge challenge for machine-learning code because you may want
to expose almost any detail of any function as a hyperparameter. The setting you
want to expose might be arbitrarily far down in your call stack, so it might
need to pass all the way through the CLI or REST API, through any number of
intermediate functions, affecting the interface of everything along the way. And
then once those settings are added, they become hard to remove later. Default
values also become hard to change without breaking backwards compatibility.,To solve this problem, , offers a config system that lets you easily
describe arbitrary trees of objects. The objects can be created via function
calls you register using a simple decorator syntax. You can even version the
functions you create, allowing you to make improvements without breaking
backwards compatibility. The most similar config system we’re aware of is
,, which uses a similar syntax, and
also allows you to link the configuration system to functions in your code using
a decorator. ,'s config system is simpler and emphasizes a different
workflow via a subset of Gin’s functionality.,
,
,
,
,The configuration system parses a , file like,and resolves it to a ,:,The config is divided into sections, with the section name in square brackets –
for example, ,. Within the sections, config values can be assigned to
keys using ,. Values can also be referenced from other sections using the dot
notation and placeholders indicated by the dollar sign and curly braces. For
example, , will receive the value of use_vectors in the
training block. This is useful for settings that are shared across components.,The config format has three main differences from Python’s built-in
,:,There’s no pre-defined scheme you have to follow; how you set up the top-level
sections is up to you. At the end of it, you’ll receive a dictionary with the
values that you can use in your script – whether it’s complete initialized
functions, or just basic settings.,For instance, let’s say you want to define a new optimizer. You'd define its
arguments in , like so:,To load and parse this configuration using a , registry (install
, separately):,Under the hood, , will look up the , function
in the ""optimizers"" registry and then call it with the arguments ,
and ,. If the function has type annotations, it will also validate the
input. For instance, if , is annotated as a float and the config
defines a string, , will raise an error.,The Thinc documentation offers further information on the configuration system:,This class holds the model and training
, and can load and save the
INI-style configuration format from/to a string, file or bytes. The ,
class is a subclass of , and uses Python’s , under the hood.,Initialize a new , object with optional data.,Load the config from a string.,Load the config from a string.,Serialize the config to a byte string.,Load the config from a byte string.,Serialize the config to a file.,Load the config from a file.,Deep-copy the config.,Interpolate variables like , or , and
return a copy of the config with interpolated values. Can be used if a config is
loaded with ,, e.g. via ,.,Deep-merge two config objects, using the current config as the default. Only
merges sections and dictionaries and not other values like lists. Values that
are provided in the updates are overwritten in the base config, and any new
values or sections are added. If a config value is a variable like
, (e.g. if the config was loaded with ,, ,, even if the updates provide a different value. This
ensures that variable references aren’t destroyed by a merge., Note that blocks that refer to registered functions using the ,
syntax are only merged if they are referring to the same functions. Otherwise,
merging could easily produce invalid configs, since different functions can
take different arguments. If a block refers to a different function, it’s
overwritten.,
      , Confection: the sweetest config system for Python 
    "
name,content
pandocfilters,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jgm/pandocfilters,Name already in use,pandocfilters,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A python module for writing pandoc filters, with a collection of examples
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A python module for writing , filters,Pandoc filters
are pipes that read a JSON serialization of the Pandoc AST
from stdin, transform it in some way, and write it to stdout.
They can be used with pandoc (>= 1.12) either using pipes,or using the , (or ,) command-line option.,For more on pandoc filters, see the pandoc documentation under ,
and ,.,For an alternative library for writing pandoc filters, with
a more ""Pythonic"" design, see ,.,Pandoc 1.16 introduced link and image attributes to the existing
caption and target arguments, requiring a change in pandocfilters
that breaks backwards compatibility. Consequently, you should use:,Pandoc 1.17.3 (pandoc-types 1.17.*) introduced a new JSON format.
pandocfilters 1.4.0 should work with both the old and the new
format.,Run this inside the present directory:,Or install from PyPI:,The main functions , exports are,Walk a tree, applying an action to every object. Returns a modified
tree. An action is a function of the form
,, where:,The return of an action is either:,Like ,, but takes a single action as argument.,Generate a JSON-to-JSON filter from stdin to stdout,The filter:,The argument , is a list of functions of the form
,, as described in more detail
under ,.,This function calls ,, with the ,
argument provided by the first command-line argument, if present.
(Pandoc sets this by default when calling filters.),Walk through JSON structure and apply filters,This:,The , argument is a list of functions (see , for a
full description).,The argument , is a string encoded JSON object.,The argument , is a string describing the output format.,Returns a new JSON-formatted pandoc document.,Walks the tree x and returns concatenated string content, leaving out
all formatting.,Returns an attribute list, constructed from the dictionary attrs.,Most users will only need ,.  Here is a simple example
of its use:,The examples subdirectory in the source repository contains the
following filters. These filters should provide a useful starting point
for developing your own pandocfilters.,By default most filters use , to
create a directory , to save temporary
files. This directory doesn't get removed as it can be used as a cache so that
later pandoc runs don't have to recreate files if they already exist. The
directory is generated in the current directory.,If you prefer to have a clean directory after running pandoc filters, you
can set an environment variable , to any non-empty value such as 1
which forces the code to create a temporary directory that will be removed
by the end of execution.,
      A python module for writing pandoc filters, with a collection of examples
    "
name,content
ipytablewidgets,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,progressivis/ipytablewidgets,Name already in use,ipytablewidgets,lab,notebook,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Traitlets and widgets to efficiently data tables (e.g. Pandas DataFrame) using the jupyter notebook
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., End to end tests use , framework.,Traitlets and widgets to efficiently data tables (e.g. Pandas DataFrame) using the jupyter notebook,ipytablewidgets is a set of widgets and traitlets to reuse of large tables such as Pandas DataFrames
across different widgets, and different packages.,Using pip:,The first step requires the following three commands to be run (requires yarn and jupyterlab>=3):,The development of extensions for , and , requires , code to be modified in-place. For this reason, , and , extensions need to be configured this way:,The main widget for tables is the , class. It has a main trait: A
table. This table's main purpose is simply to be a standardized way of transmitting table
data from the kernel to the frontend, and to allow the data to be reused across
any number of other widgets, but with only a single sync across the network.,You can see , which is a more realistic example, currently used for end to end testing and ,.,Or, if you prefer to use the , traitlet directly:,Developers should consider using ipytablewidgets because:,The major parts of ipyablewidgets are:,
      Traitlets and widgets to efficiently data tables (e.g. Pandas DataFrame) using the jupyter notebook
    "
name,content
backports.csv,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,ryanhiebert/backports.csv,Name already in use,backports.csv: Backport of Python 3's csv module,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Backport of Python 3's csv module for Python 2
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,The API of the csv module in Python 2 is drastically different from
the csv module in Python 3. This is due, for the most part, to the
difference between str in Python 2 and Python 3.,The semantics of Python 3's version are more useful because they support
unicode natively, while Python 2's csv does not.,First make sure you're starting your file off right:,Then be careful with your files to handle the encoding.
If you're working with a binary file-like object,
, can be very helpful.
If you're dealing with a file, you can just use ,
instead of Python 2's , builtin, and it works
just like Python 3's builtin ,.,Note: It is safe to specify ,,
since the csv module does its own (universal) newline handling.,
      Backport of Python 3's csv module for Python 2
    "
name,content
jieba3k,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,
        ,
        ,
      ,Block or report fxsjy,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
            Prevent this user from interacting with your repositories and sending you notifications.
          Learn more about ,.
        ,
              You must be logged in to block users.
            ,
        Contact GitHub support about this user’s behavior.
        Learn more about ,.
      ,
        结巴中文分词
      ,
          ,

          ,
          ,
      ,
        GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN
      ,
          ,

          ,
          ,
      ,
        A simple high performance http server based on epoll
      ,
          ,

          ,
          ,
      ,
        Solution to build dedicated oracle
      ,
          ,

          ,
          ,
      ,
        A better message queue built by rust
      ,
          ,

          ,
          ,
      ,
    Seeing something unexpected? Take a look at the
    ,.
  "
name,content
bs4,"
        beautifulsoup4 4.12.2
      ,Quick start,Links,Note on Python 2 sunsetting,Supporting the project,Building the documentation,Running the unit tests,
          ,
          ,
        ,
        Released: ,
      ,Screen-scraping library,
    View statistics for this project via ,, or by using ,
  , MIT License, ,
    ,
    ,
    
    ,
    
    ,
    
    ,
    
    ,
    
  ,
    , Python >=3.6.0
  ,Beautiful Soup is a library that makes it easy to scrape information
from web pages. It sits atop an HTML or XML parser, providing Pythonic
idioms for iterating, searching, and modifying the parse tree.,To go beyond the basics, ,.,Beautiful Soup's support for Python 2 was discontinued on December 31,
2020: one year after the sunset date for Python 2 itself. From this
point onward, new Beautiful Soup development will exclusively target
Python 3. The final release of Beautiful Soup 4 to support Python 2
was 4.9.3.,If you use Beautiful Soup as part of your professional work, please consider a
,.
This will support many of the free software projects your organization
depends on, not just Beautiful Soup.,If you use Beautiful Soup for personal projects, the best way to say
thank you is to read
,, a zine I
wrote about what Beautiful Soup has taught me about software
development.,The bs4/doc/ directory contains full documentation in Sphinx
format. Run , in that directory to create HTML
documentation.,Beautiful Soup supports unit test discovery using Pytest:,
    View statistics for this project via ,, or by using ,
  , MIT License, ,
    ,
    ,
    
    ,
    
    ,
    
    ,
    
    ,
    
  ,
    , Python >=3.6.0
  ,
                  4.12.2
                  
                  
                ,
                  ,
                ,
                  4.12.1
                  
                  
                ,
                  ,
                ,
                  4.12.0
                  
                  
                ,
                  ,
                ,
                  4.11.2
                  
                  
                ,
                  ,
                ,
                  4.11.1
                  
                  
                ,
                  ,
                ,
                  4.11.0
                  
                  
                ,
                  ,
                ,
                  4.10.0
                  
                  
                ,
                  ,
                ,
                  4.9.3
                  
                  
                ,
                  ,
                ,
                  4.9.2
                  
                  
                ,
                  ,
                ,
                  4.9.1
                  
                  
                ,
                  ,
                ,
                  4.9.0
                  
                  
                ,
                  ,
                ,
                  4.8.2
                  
                  
                ,
                  ,
                ,
                  4.8.1
                  
                  
                ,
                  ,
                ,
                  4.8.0
                  
                  
                ,
                  ,
                ,
                  4.7.1
                  
                  
                ,
                  ,
                ,
                  4.7.0
                  
                  
                ,
                  ,
                ,
                  4.6.3
                  
                  
                ,
                  ,
                ,
                  4.6.2
                  
                  
                ,
                  ,
                ,
                  4.6.1
                  
                  
                ,
                  ,
                ,
                  4.6.0
                  
                  
                ,
                  ,
                ,
                  4.5.3
                  
                  
                ,
                  ,
                ,
                  4.5.2
                  
                  
                ,
                  ,
                ,
                  4.5.1
                  
                  
                ,
                  ,
                ,
                  4.5.0
                  
                  
                ,
                  ,
                ,
                  4.4.1
                  
                  
                ,
                  ,
                ,
                  4.4.0
                  
                  
                ,
                  ,
                ,
                  4.3.2
                  
                  
                ,
                  ,
                ,
                  4.3.1
                  
                  
                ,
                  ,
                ,
                  4.3.0
                  
                  
                ,
                  ,
                ,
                  4.2.1
                  
                  
                ,
                  ,
                ,
                  4.2.0
                  
                  
                ,
                  ,
                ,
                  4.1.3
                  
                  
                ,
                  ,
                ,
                  4.1.2
                  
                  
                ,
                  ,
                ,
                  4.1.1
                  
                  
                ,
                  ,
                ,
                  4.1.0
                  
                  
                ,
                  ,
                ,
                  4.0.5
                  
                  
                ,
                  ,
                ,
                  4.0.4
                  
                  
                ,
                  ,
                ,
                  4.0.3
                  
                  
                ,
                  ,
                ,
                  4.0.2
                  
                  
                ,
                  ,
                ,
                  4.0.1
                  
                  
                ,
                  ,
                ,Download the file for your platform. If you're not sure which to choose, learn more about ,.,
          Uploaded ,
          
          
          ,
          
          
        ,
          Uploaded ,
          
          
          ,
          
          
        ,Status:,
        ,
          Developed and maintained by the Python community, for the Python community.
          ,
          ,
        ,
          
""PyPI"", ""Python Package Index"", and the blocks logos are registered , of the ,.
,
        ,
          © 2023 ,
          ,
        ,Supported by"
name,content
cymem,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,explosion/cymem,Name already in use,cymem: A Cython Memory Helper,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        , Cython memory pool for RAII-style memory management
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,cymem provides two small memory-management helpers for Cython. They make it easy
to tie memory to a Python object's life-cycle, so that the memory is freed when
the object is garbage collected.,
,
,
,The most useful is ,, which acts as a thin wrapper around the calloc
function:,The , object saves the memory addresses internally, and frees them when the
object is garbage collected. Typically you'll attach the , to some cdef'd
class. This is particularly handy for deeply nested structs, which have
complicated initialization functions. Just pass the , object into the
initializer, and you don't have to worry about freeing your struct at all — all
of the calls to , will be automatically freed when the ,
expires.,Installation is via ,, and requires
,. Before installing, make sure that your ,,
, and , are up to date.,Let's say we want a sequence of sparse matrices. We need fast access, and a
Python list isn't performing well enough. So, we want a C-array or C++ vector,
which means we need the sparse matrix to be a C-level struct — it can't be a
Python class. We can write this easily enough in Cython:,We wrap the data structure in a Python ref-counted class at as low a level as we
can, given our performance constraints. This allows us to allocate and free the
memory in the , and , Cython special methods.,However, it's very easy to make mistakes when writing the , and
, functions, leading to memory leaks. cymem prevents you from
writing these deallocators at all. Instead, you write as follows:,All that the , class does is remember the addresses it gives out. When the
, object is garbage-collected, the , object will also be
garbage collected, which triggers a call to ,. The , then
frees all of its addresses. This saves you from walking back over your nested
data structures to free them, eliminating a common class of errors.,Sometimes external C libraries use private functions to allocate and free
objects, but we'd still like the laziness of the ,.,
      , Cython memory pool for RAII-style memory management
    "
name,content
oslo.utils,"Welcome to oslo.utils’s documentation!,Welcome to oslo.utils’s documentation!,The , utils library provides support for common utility type functions,
such as encoding, exception handling, string manipulation, and time handling.,Read also the ,.,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Docs.openstack.org is powered by
          ,.
        "
name,content
english-words,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,mwiens91/english-words-py,Name already in use,english-words-py,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Sets of English words to use in Python scripts/programs
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Returns sets of English words created by combining different words
lists together. Example usage: to get a set of English words from the
""web2"" word list, including only lower-case letters, you write the
following:,From the main package, import , as demonstrated
above. This function takes a number of arguments; the first is a list of
word list identifiers for the word lists to combine and the rest are
flags. These arguments are described here (in the following order):,Each word list is pre-processed to handle the above flags, so using any
combination of options will not cause the function to run slower.,Note that some care needs to be used when combining word lists. For
example, only proper nouns in the , word list are capitalized, but
most words in the , word list are capitalized.,To add a word list, say with identifier ,, put the word list (one word
per line), into a plain text file , in the ,
directory at the root of the repository. Then, to process the word list
(and all others in the directory) run the script
,.,Install this with pip with,This package is unfortunately rather large (~20MB), and will run into
scaling issues if more word lists or (especially) options are added.
When that bridge is crossed, word lists should possibly be chosen by the
user instead of simply including all of them; word lists could also be
preprocessed on the client side instead of being included in the
package.,
      Sets of English words to use in Python scripts/programs
    "
name,content
itemloaders,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,scrapy/itemloaders,Name already in use,itemloaders,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Library to populate items using XPath and CSS with a convenient API 
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a library that helps you collect data from HTML and XML sources.,It comes in handy to extract data from web pages, as it supports
data extraction using CSS and XPath Selectors.,It's specially useful when you need to standardize the data from many sources.
For example, it allows you to have all your casting and parsing rules in a
single place.,Here is an example to get you started:,For more information, check out the ,.,All contributions are welcome!,If you want to review some code, check open
,If you want to submit a code change,
      Library to populate items using XPath and CSS with a convenient API 
    "
name,content
configobj,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,DiffSK/configobj,Name already in use,configobj,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python 3+ compatible port of the configobj library
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,Python 3+ compatible port of the , library.,The Github CI/CD Pipeline runs tests on python versions:,You can find a full manual on how to use ConfigObj at ,.,This is a mature project that is not actively maintained at this time.,
      Python 3+ compatible port of the configobj library
    "
name,content
args,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,kennethreitz-archive/args,Name already in use,args,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Argument Parsing for Humans™
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Argument Parsing for Humans.,Here's an example application:,No arguments:,A few arguments:,A few expanded file arguments:,A few non-expanded file arguments:,A few mixed files/flags/arguments:,Installation is simple with pip:,
      Argument Parsing for Humans™
    "
name,content
murmurhash,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,explosion/murmurhash,Name already in use,Cython bindings for MurmurHash2,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        , Cython bindings for MurmurHash2
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
      , Cython bindings for MurmurHash2
    "
name,content
click-repl,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,click-contrib/click-repl,Name already in use,click-repl,Installation,Usage,Advanced Usage,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Subcommand REPL for click apps
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,
,Installation is done via pip:,In your , app:,In the shell:,You can use the internal , command to explain usage.,For more flexibility over how your REPL works you can use the , function
directly instead of ,. For example, in your app:,And then your custom , command will be available on your CLI, which
will start a REPL which has its history stored in
, and persist between sessions.,Any arguments that can be passed to the , , class
can be passed in the , argument and will be used when
instantiating your ,.,
      Subcommand REPL for click apps
    "
name,content
html5lib,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,html5lib/html5lib-python,Name already in use,html5lib,not,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Standards-compliant library for parsing and serializing HTML documents and fragments in Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,html5lib is a pure-python library for parsing HTML. It is designed to
conform to the WHATWG HTML specification, as is implemented by all major
web browsers.,Simple usage follows this pattern:,or:,By default, the , will be an , element instance.
Whenever possible, html5lib chooses the accelerated ,
implementation (i.e. , on Python 2.x).,Two other tree types are supported: , and
,. To use an alternative format, specify the name of
a treebuilder:,When using with , (Python 2), the charset from HTTP should be
pass into html5lib as follows:,When using with , (Python 3), the charset from HTTP
should be pass into html5lib as follows:,To have more control over the parser, create a parser object explicitly.
For instance, to make the parser raise exceptions on parse errors, use:,When you're instantiating parser objects explicitly, pass a treebuilder
class as the , keyword argument to use an alternative document
format:,More documentation is available at ,.,html5lib works on CPython 2.7+, CPython 3.5+ and PyPy. To install:,The goal is to support a (non-strict) superset of the versions that ,.,The following third-party libraries may be used for additional
functionality:,Please report any bugs on the ,.,Unit tests require the , and , libraries and can be
run using the , command in the root directory.,Test data are contained in a separate , repository and included
as a submodule, thus for git checkouts they must be initialized:,If you have all compatible Python implementations available on your
system, you can run tests on all of them using the , utility,
which can be found on PyPI.,Check out ,. Still
need help? Go to our ,.,You can also browse the archives of the ,.,
      Standards-compliant library for parsing and serializing HTML documents and fragments in Python
    "
name,content
en-core-web-sm,Explosion builds developer tools for
name,content
html5-parser,"html5-parser,html,transport_encoding=None,namespace_elements=False,treebuilder=u'lxml',fallback_encoding=None,keep_doctype=True,maybe_xhtml=False,return_root=True,line_number_attr=None,sanitize_names=True,stack_size=16384,fragment_context=None,0.4.10,0.4.10, ,A fast implementation of the , for Python. Parsing is done
in C using a variant of the ,. The gumbo parse tree is then
transformed into an , tree, also in C, yielding parse
times that can be , of the html5lib parse times. That is a
speedup of ,. This differs, for instance, from the gumbo python bindings,
where the initial parsing is done in C but the transformation into the final
tree is done in python.,On a Unix-y system, with a working C99 compiler, simply run:,It is important that lxml is installed with the , flag. This is
because without it, lxml uses a static copy of libxml2. For html5-parser to
work it must use the same libxml2 implementation as lxml. This is only possible
if libxml2 is loaded dynamically.,You can setup html5-parser to run from a source checkout as follows:,On Windows, installation is a little more involved. There is a 200 line script
that is used to install html5-parser and all its dependencies on the windows
continuous integration server. Using that script installation can be done by
running the following commands in a Visual Studio 2015 Command prompt:,This will install all dependencies and html5-parser in the ,
sub-directory. You will need to add , to , and
, to ,. Or copy the files
into your system python’s directories.,To use html5-parser in your code, after installing it simply do:,See the , function documentation for more details on
parsing. To learn how to use the parsed lxml tree in your program, see
the ,.,html5-parser has the ability to parse XHTML documents as well. It will
preserve namespace information even for namespaces not defined in the HTML 5
spec. You can ask it to treat the input html as possibly XHTML by using the
, parameter to the , function. For example:,becomes,This is useful when try to parse a XHTML document that is not well-formed and
so cannot be parsed by a regular XML parser.,The API of html5-parser is a single function, ,.,Parse the specified , and return the parsed representation.,The type of tree to return. Note that only the lxml treebuilder is fast, as all
other treebuilders are implemented in python, not C. Supported values are:,Before doing the actual comparison, let me say that html5lib is a great
project. It was a pioneer of HTML 5 parsing and I have used it myself for many
years. However, being written in pure python, it cannot help but be slow.,There is a benchmark script named , that
compares the parse times for parsing a large (~ 5.7MB) HTML document in
html5lib and html5-parser. The results on my system (using python 3) show a
speedup of ,. The output from the script on my system is:,There is further potential for speedup. Currently the gumbo subsystem uses
its own data structures to store parse results and these are converted to
libxml2 data structures in a second pass after parsing completes. By modifying gumbo
to use libxml2 data structures directly, there could be significant speed and
memory usage gains.,html5lib has truly horrible handling of namespaces. There is even a source-code
file in it named ,. Compare the result of parsing and pretty
printing the following simple HTML fragment (pretty printing is done via lxml in both
cases).,With ,:,With ,:,While both outputs are technically correct, the output produced via
html5-parser is much easier to read and much closer to what an actual human
would write. In particular, notice the unnecessary use of prefixes in
the html5lib output, as well as the ugly , anonymous prefix for the svg
namespace.,html5-parser also has the ability to optionally preserve namespace information
even for namespaces not defined in the HTML 5 standard. See the ,
section for more information.,The HTML parser is based on the , which has undergone a Google
security review and been tested on 2.5 billion pages from the Google cache. In
addition, html5-parser passes (almost) all the tests from the html5lib test
suite.,Finally, html5-parser is compiled with , and
the test suite, consisting of thousands of tests, is run using the address and
undefined behavior sanitizers. Continuous integration testing is done on three
major OSes and four different compilers.,
,
"
name,content
gprof2dot,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jrfonseca/gprof2dot,Name already in use,About ,Status,Example,Requirements,Download,Documentation,Links,gprof2dot,gprof2dot,gprof2dot,not,Trace,Load Symbols,Configure Symbol Paths,CPU sampling graph,Summary Table,Columns,Stack,Export Full Table,output.csv,total time %,self time %,total calls,total time %,calls,total time %,total time %,total time %,temperature-like,partial,essential,If,should,should,may,expects,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Converts profiling output to a dot graph.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This is a Python script to convert the output from many profilers into a ,.,It can:, currently fulfills my needs, and I have little or no time for its
maintenance.  So I'm afraid that any requested features are unlikely to be
implemented, and I might be slow processing issue reports or pull requests.,
,This is the result from the , in the , with the default settings:,On Debian/Ubuntu run:,On RedHat/Fedora run,If you're not familiar with xperf then read , first. Then do:,Start xperf as,Run your application.,Save the data.
`
xperf -d output.etl,Start the visualizer:,In , menu, select ,. , if necessary.,Select an area of interest on the ,, right-click, and select ,.,In the , menu, make sure the , column is enabled and visible.,Right click on a row, choose ,, and save to ,.,Then invoke gprof2dot as,Collect profile data as (also can be done from GUI):,Visualize profile data as:,See also ,.,See , for details.,A node in the output graph represents a function and has the following layout:,where:,An edge represents the calls between two functions and has the following layout:,Where:,Note that in recursive cycles, the , in the node is the same for the whole functions in the cycle, and there is no , figure in the edges inside the cycle, since such figure would make no sense.,The color of the nodes and edges varies according to the , value. In the default , color-map, functions where most time is spent (hot-spots) are marked as saturated red, and functions where little time is spent are marked as dark blue. Note that functions where negligible or no time is spent do not appear in the graph by default.,The flag , permits listing the function entries found in the , input.
This is intended as a tool to prepare for utilisations with the , (,)
or , (,) flags.,The selector argument is used with Unix/Bash globbing/pattern matching, in the same
fashion as performed by the , and , flags.,Entries are formatted '<pkg>:<linenum>:<function>'.,When selector argument starts with '%', a dump of all available information is
performed for selected entries,   after removal of selector's leading '%'. If
selector is ""+"" or ""*"", the full list of functions is printed.,By default , generates a , call graph, excluding nodes and edges with little or no impact in the total computation time. If you want the full call graph then set a zero threshold for nodes and edges via the , / ,  and , / , options, as:,The node labels can get very wide when profiling C++ code, due to inclusion of scope, function arguments, and template arguments in demangled C++ function names.,If you do not need function and template arguments information, then pass the , / , option to strip them.,If you want to keep all that information, or if the labels are still too wide, then you can pass the , / ,, to wrap the labels. Note that because , does not wrap labels automatically the label margins will not be perfectly aligned.,Likely, the total execution time is too short, so there is not enough precision in the profile to determine where time is being spent.,You can still force displaying the whole graph by setting a zero threshold for nodes and edges via the , / ,  and , / , options, as:,But to get meaningful results you will need to find a way to run the program for a longer time period (aggregate results from multiple runs).,You likely have an execution time too short, causing the round-off errors to be large.,See question above for ways to increase execution time.,Options which are , to produce suitable results are:, you're using gprof you will also need , option, but nowadays you can get much better results with other profiling tools, most of which require no special code instrumentation when compiling.,You want the code you are profiling to be as close as possible as the code that you will
be releasing. So you , include all options that you use in your release code, typically:,However many of the optimizations performed by gcc interfere with the accuracy/granularity of the profiling results.  You , pass these options to disable those particular optimizations:,If the granularity is still too low, you , pass these options to achieve finer granularity:,See the , for more information.,See the , for external resources, including complementary/alternative tools.,
      Converts profiling output to a dot graph.
    "
name,content
arrow,"Arrow: Better dates & times for Python,Release v1.2.3 (,) (,), is a Python library that offers a sensible and human-friendly approach to creating, manipulating, formatting and converting dates, times and timestamps. It implements and updates the datetime type, plugging gaps in functionality and providing an intelligent module API that supports many common creation scenarios. Simply put, it helps you work with dates and times with fewer imports and a lot less code.,Arrow is named after the , and is heavily inspired by , and ,.,Python’s standard library and some other low-level modules have near-complete date, time and timezone functionality, but don’t work very well from a usability perspective:,Too many modules: datetime, time, calendar, dateutil, pytz and more,Too many types: date, time, datetime, tzinfo, timedelta, relativedelta, etc.,Timezones and timestamp conversions are verbose and unpleasant,Timezone naivety is the norm,Gaps in functionality: ISO 8601 parsing, timespans, humanization,Fully-implemented, drop-in replacement for datetime,Support for Python 3.6+,Timezone-aware and UTC by default,Super-simple creation options for many common input scenarios, method with support for relative offsets, including weeks,Format and parse strings automatically,Wide support for the , standard,Timezone conversion,Support for ,, ,, and , tzinfo objects,Generates time spans, ranges, floors and ceilings for time frames ranging from microsecond to year,Humanize dates and times with a growing list of contributed locales,Extensible for your own Arrow-derived types,Full support for PEP 484-style type hints,To install Arrow, use , or ,:,
        © Copyright 2021, Chris Smith
      
        ,
      

    "
name,content
deform,"Deform,Topics,Demonstration Site,Community and links,Thanks,Index and Glossary, is a Python HTML form generation library.  It runs under Python
2.x, 3.x and PyPy.,Deform is a Python form library for generating HTML forms on the server side.
,,
,, , and a few other , are supported out of the box.,Deform integrates with the ,
and several other web frameworks. Deform comes with , and , styling. Under the hood, , are used for serialization and
validation. The , library
maps HTTP form submissions to nested structure.,Although Deform uses Chameleon templates internally, you can embed rendered
Deform forms into any template language.,Visit , to view an
application which demonstrates most of Deform's features.  The source code
for this application is also available in the ,.,The design of , is heavily influenced by the , form generation library.  Some
might even say it's a shameless rip-off; this would not be completely
inaccurate.  It differs from formish mostly in ways that make the
implementation (arguably) simpler and smaller.,Without these people, this software would not exist:"
name,content
Flask-WTF,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,wtforms/flask-wtf,Name already in use,Flask-WTF,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Simple integration of Flask and WTForms, including CSRF, file upload and Recaptcha integration.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Simple integration of Flask and WTForms, including CSRF, file upload,
and reCAPTCHA.,
      Simple integration of Flask and WTForms, including CSRF, file upload and Recaptcha integration.
    "
name,content
cachetools,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,tkem/cachetools,Name already in use,cachetools,cache,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Extensible memoizing collections and decorators
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This module provides various memoizing collections and decorators,
including variants of the Python Standard Library's ,
function decorator.,For the purpose of this module, a , is a , , of a
fixed maximum size.  When the cache is full, i.e. by adding another
item the cache would exceed its maximum size, the cache must choose
which item(s) to discard based on a suitable ,.,This module provides multiple cache classes based on different cache
algorithms, as well as decorators for easily memoizing function and
method calls.,cachetools is available from , and can be installed by running:,Typing stubs for this package are provided by , and can be
installed by running:,Copyright (c) 2014-2023 Thomas Kemmer.,Licensed under the ,.,
      Extensible memoizing collections and decorators
    "
name,content
nvidia-cuda-cupti-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
httpcore,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,encode/httpcore,Name already in use,HTTP Core,Sending requests,Do one thing, and do it well.,probably,really clear interface split,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A minimal HTTP client. ,
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,The HTTP Core package provides a minimal low-level HTTP client, which does
one thing only. Sending HTTP requests.,It does not provide any high level model abstractions over the API,
does not handle redirects, multipart uploads, building authentication headers,
transparent HTTP caching, URL parsing, session cookie handling,
content or charset decoding, handling JSON, environment based configuration
defaults, or any of that Jazz.,Some things HTTP Core does do:,Python 3.7+,For HTTP/1.1 only support, install with:,For HTTP/1.1 and HTTP/2 support, install with:,For SOCKS proxy support, install with:,Send an HTTP request:,The top-level , function is provided for convenience. In practice whenever you're working with , you'll want to use the connection pooling functionality that it provides.,Once you're ready to get going, ,.,You , don't want to be using HTTP Core directly. It might make sense if
you're writing something like a proxy service in Python, and you just want
something at the lowest possible level, but more typically you'll want to use
a higher level client library, such as ,.,The motivation for , is:,
      A minimal HTTP client. ,
    "
name,content
email-validator,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,JoshData/python-email-validator,Name already in use,email-validator: Validate Email Addresses,not,local,will,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A robust email syntax and deliverability validation library for Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A robust email address syntax and deliverability validation library for
Python 3.7+ by ,.,This library validates that a string is of the form ,
and optionally checks that the domain name is set up to receive email.
This is the sort of validation you would want when you are identifying
users by their email address like on a registration/login form (but not
necessarily for composing an email message, see below).,Key features:,This is an opinionated library. You should definitely also consider using
the less-opinionated , and
, if they are better for your
use case.,View the , for the version history of changes in the library. Occasionally this README is ahead of the latest published package --- see the CHANGELOG for details.,This package ,, so:,(You might need to use , depending on your local environment.),If you're validating a user's email address before creating a user
account in your application, you might do this:,This validates the address and gives you its normalized form. You should
, and always normalize before
checking if an address is in your database. When using this in a login form,
set , to , to avoid unnecessary DNS queries.,The module provides a function , which
takes an email address and:,When an email address is not valid, , raises either an
, if the form of the address is invalid or an
, if the domain name fails DNS checks. Both
exception classes are subclasses of ,, which in turn
is a subclass of ,.,But when an email address is valid, an object is returned containing
a normalized form of the email address (which you should use!) and
other information.,The validator doesn't, by default, permit obsoleted forms of email addresses
that no one uses anymore even though they are still valid and deliverable, since
they will probably give you grief if you're using email for login. (See
later in the document about how to allow some obsolete forms.),The validator optionally checks that the domain name in the email address has
a DNS MX record indicating that it can receive email. (Except a Null MX record.
If there is no MX record, a fallback A/AAAA-record is permitted, unless
a reject-all SPF record is present.) DNS is slow and sometimes unavailable or
unreliable, so consider whether these checks are useful for your use case and
turn them off if they aren't.
There is nothing to be gained by trying to actually contact an SMTP server, so
that's not done here. For privacy, security, and practicality reasons, servers
are good at not giving away whether an address is
deliverable or not: email addresses that appear to accept mail at first
can bounce mail after a delay, and bounced mail may indicate a temporary
failure of a good email address (sometimes an intentional failure, like
greylisting).,The , function also accepts the following keyword arguments
(defaults are as shown below):,: If true, DNS queries are made to check that the domain name in the email address (the part after the @-sign) can receive mail, as described above. Set to , to skip this DNS-based check. It is recommended to pass , when performing validation for login pages (but not account creation pages) since re-validation of a previously validated domain in your database by querying DNS at every login is probably undesirable. You can also set , to , to turn this off for all calls by default.,: Pass an instance of , to control the DNS resolver including setting a timeout and ,. The , function shown below is a helper function to construct a dns.resolver.Resolver with a ,. Reuse the same resolver instance across calls to , to make use of the cache.,: If ,, DNS-based deliverability checks are disabled and  , and , domain names are permitted (see below). You can also set , to , to turn it on for all calls by default.,: Set to , to prohibit internationalized addresses that would
require the
, extension. You can also set , to , to turn it off for all calls by default.,: Set to , to allow obscure and potentially problematic email addresses in which the part of the address before the @-sign contains spaces, @-signs, or other surprising characters when the local part is surrounded in quotes (so-called quoted-string local parts). In the object returned by ,, the normalized local part removes any unnecessary backslash-escaping and even removes the surrounding quotes if the address would be valid without them. You can also set , to , to turn this on for all calls by default.,: Set to , to allow bracketed IPv4 and ""IPv6:""-prefixd IPv6 addresses in the domain part of the email address. No deliverability checks are performed for these addresses. In the object returned by ,, the normalized domain will use the condensed IPv6 format, if applicable. The object's , attribute will hold the parsed , or , object if applicable. You can also set , to , to turn this on for all calls by default.,: Set to , to allow an empty local part (i.e.
,), e.g. for validating Postfix aliases.,When validating many email addresses or to control the timeout (the default is 15 seconds), create a caching , to reuse in each call. The , function returns one easily for you:,This library rejects email addresess that use the , ,, ,, ,, and some others by raising ,. This is to protect your system from abuse: You probably don't want a user to be able to cause an email to be sent to , (although they might be able to still do so via a malicious MX record). However, in your non-production test environments you may want to use , or , email addresses. There are three ways you can allow this:,It is tempting to use , in tests. They are , in this library's , list so you can, but shouldn't, use them. These domains are reserved to IANA for use in documentation so there is no risk of accidentally emailing someone at those domains. But beware that this library will nevertheless reject these domain names if DNS-based deliverability checks are not disabled because these domains do not resolve to domains that accept email. In tests, consider using your own domain name or , or , instead.,The email protocol SMTP and the domain name system DNS have historically
only allowed English (ASCII) characters in email addresses and domain names,
respectively. Each has adapted to internationalization in a separate
way, creating two separate aspects to email address
internationalization.,The first is ,, a.k.a IDNA 2008. The DNS
system has not been updated with Unicode support. Instead, internationalized
domain names are converted into a special IDNA ASCII "",""
form starting with ,. When an email address has non-ASCII
characters in its domain part, the domain part is replaced with its IDNA
ASCII equivalent form in the process of mail transmission. Your mail
submission library probably does this for you transparently. (,.) This library conforms to IDNA 2008
using the , module by Kim Davies.,The second sort of internationalization is internationalization in the
, part of the address (before the @-sign). In non-internationalized
email addresses, only English letters, numbers, and some punctuation
(,) are allowed. In internationalized email address
local parts, a wider range of Unicode characters are allowed.,A surprisingly large number of Unicode characters are not safe to display,
especially when the email address is concatenated with other text, so this
library tries to protect you by not permitting resvered, non-, private use,
formatting (which can be used to alter the display order of characters),
whitespace, and control characters, and combining characters
as the first character of the local part and the domain name (so that they
cannot combine with something outside of the email address string or with
the @-sign). See , and ,
for relevant prior work. (Other than whitespace, these are checks that
you should be applying to nearly all user inputs in a security-sensitive
context.),These character checks are performed after Unicode normalization (see below),
so you are only fully protected if you replace all user-provided email addresses
with the normalized email address string returned by this library. This does not
guard against the well known problem that many Unicode characters look alike
(or are identical), which can be used to fool humans reading displayed text.,Email addresses with these non-ASCII characters require that your mail
submission library and the mail servers along the route to the destination,
including your own outbound mail server, all support the
, extension.
Support for SMTPUTF8 varies. See the , parameter.,By default all internationalized forms are accepted by the validator.
But if you know ahead of time that SMTPUTF8 is not supported by your
mail submission stack, then you must filter out addresses that require
SMTPUTF8 using the , keyword argument (see above).
This will cause the validation function to raise a , if
delivery would require SMTPUTF8. That's just in those cases where
non-ASCII characters appear before the @-sign. If you do not set
,, you can also check the value of the ,
field in the returned object.,If your mail submission library doesn't support Unicode at all --- even
in the domain part of the address --- then immediately prior to mail
submission you must replace the email address with its ASCII-ized form.
This library gives you back the ASCII-ized form in the ,
field in the returned object, which you can get like this:,The local part is left alone (if it has internationalized characters
, will force validation to fail) and the domain
part is converted to ,.
(You probably should not do this at account creation time so you don't
change the user's login information without telling them.),The use of Unicode in email addresses introduced a normalization
problem. Different Unicode strings can look identical and have the same
semantic meaning to the user. The , field returned on successful
validation provides the correctly normalized form of the given email
address.,For example, the CJK fullwidth Latin letters are considered semantically
equivalent in domain names to their ASCII counterparts. This library
normalizes them to their ASCII counterparts:,Because an end-user might type their email address in different (but
equivalent) un-normalized forms at different times, you ought to
replace what they enter with the normalized form immediately prior to
going into your database (during account creation), querying your database
(during login), or sending outbound mail. Normalization may also change
the length of an email address, and this may affect whether it is valid
and acceptable by your SMTP provider.,The normalizations include lowercasing the domain part of the email
address (domain names are case-insensitive), , of the
whole address (which turns characters plus , into
precomposed characters where possible, replacement of ,
in the domain part, possibly other
, mappings on the domain part,
and conversion from Punycode to Unicode characters.,(See , and ,.),Normalization is also applied to quoted-string local parts and domain
literal IPv6 addresses if you have allowed them by the ,
and , options. In quoted-string local parts, unnecessary
backslash escaping is removed and even the surrounding quotes are removed if
they are unnecessary. For IPv6 domain literals, the IPv6 address is
normalized to condensed form. ,
also requires lowercase normalization for some specific mailbox names like ,.,For the email address ,, the returned object is:,For the fictitious but valid address ,, which has an
internationalized domain but ASCII local part, the returned object is:,Note that , and other fields provide a normalized form of the
email address, domain name, and (in other cases) local part (see earlier
discussion of normalization), which you should use in your database.,Calling , with the ASCII form of the above email address,
,, returns the exact same information (i.e., the
, field always will contain Unicode characters, not Punycode).,For the fictitious address ,, which has an
internationalized local part, the returned object is:,Now , is , and , is , because the local
part of the address is internationalized. The , and , fields
return the normalized form of the address.,When an email address passes validation, the fields in the returned object
are:,By design, this validator does not pass all email addresses that
strictly conform to the standards. Many email address forms are obsolete
or likely to cause trouble:,Tests can be run using,Tests run with mocked DNS responses. When adding or changing tests, temporarily turn on the , flag in , to re-build the database of mocked responses from live queries.,The package is distributed as a universal wheel and as a source package.,To release:,
      A robust email syntax and deliverability validation library for Python.
    "
name,content
leather,"leather 0.3.4,now,Leather is the Python charting library for those who need charts , and don’t care if they’re perfect.,Leather isn’t picky. It’s rough. It gets dirty. It looks sexy just hanging on the back of a chair. Leather doesn’t need your accessories. Leather is how Snake Plissken would make charts.,Get it?,Important links:,Documentation:    ,Repository:       ,Issues:           , - why you should use leather, - how to install for users and developers, - code + output examples of every feature of leather, - technical documentation for the leather API, - a record of every change made for each release, - the process for maintainers to publish new releases, - a copy of the MIT open source license covering leather,The following individuals have contributed code, documentation, or expertise to leather:"
name,content
blessed,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jquast/blessed,Name already in use,library,terminal,fun,easy,blessed,blessed,blessed,Blessed,Blessed,StringIO,Blessed,printable length,Blessed,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Blessed is an easy, practical library for making python terminal apps
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Blessed is an easy, practical , for making , apps, by providing an elegant,
well-documented interface to ,, , input, and screen position and ,
capabilities.,It's meant to be , and ,, to do basic terminal graphics and styling with Python using
,. , is the only class you need to import and the only object you should need for
Terminal capabilities.,Whether you want to improve CLI apps with colors, or make fullscreen applications or games,
, should help get you started quickly. Your users will love it because it works on Windows,
Mac, and Linux, and you will love it because it has plenty of documentation and examples!,Full documentation at ,, ,, ,, and ,, from our repository.,Exemplary 3rd-party examples which use ,,, is an extensible debugger UI toolkit written in Python, is ""graphical"" command line program for solving crossword puzzles in the terminal., builds an interactive heatmap of git history., is a library to quickly create terminal-based dashboards., is a console progress bar library that allows simultaneous output without redirection., is a clone of the (briefly popular) puzzle game, 2048., works with Windows, Mac, Linux, and BSD's, on Python 2.7, 3.5+., is more than just a Python wrapper around ,:, is a fork of ,, which does all of
the same above with the same API, as well as following ,:,With the built-in , module, this is how you would typically
print some underlined text at the bottom of the screen:,The same program with , is simply:,
      Blessed is an easy, practical library for making python terminal apps
    "
name,content
djangorestframework,"Django REST Framework,collaboratively funded project,Every single sign-up helps us make REST framework long-term financially sustainable.,Many thanks to all our ,, and in particular to our premium backers, ,, ,, ,, ,, ,, ,, ,, and ,.,
    ,

    ,

    ,
,
,Django REST framework is a powerful and flexible toolkit for building Web APIs.,Some reasons you might want to use REST framework:,REST framework is a ,. If you use
REST framework commercially we strongly encourage you to invest in its
continued development by ,.,REST framework requires the following:,We , and only officially support the latest patch release of
each Python and Django series.,The following packages are optional:,Install using ,, including any optional packages you want...,...or clone the project from github.,Add , to your , setting.,If you're intending to use the browsable API you'll probably also want to add REST framework's login and logout views.  Add the following to your root , file.,Note that the URL path can be whatever you want.,Let's take a look at a quick example of using REST framework to build a simple model-backed API.,We'll create a read-write API for accessing information on the users of our project.,Any global settings for a REST framework API are kept in a single configuration dictionary named ,.  Start off by adding the following to your , module:,Don't forget to make sure you've also added , to your ,.,We're ready to create our API now.
Here's our project's root , module:,You can now open the API in your browser at ,, and view your new 'users' API. If you use the login control in the top right corner you'll also be able to add, create and delete users from the system.,Can't wait to get started? The , is the fastest way to get up and running, and building APIs with REST framework.,See the , for information on how to clone
the repository, run the test suite and contribute changes back to REST
Framework.,For support please see the ,, try the  , channel on ,, or raise a  question on ,, making sure to include the , tag.,For priority support please sign up for a ,.,Security issues are handled under the supervision of the ,.,.,The project maintainers will then work with you to resolve any issues where required, prior to any public disclosure.,Copyright © 2011-present, ,.
All rights reserved.,Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:,Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.,Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.,Neither the name of the copyright holder nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.,THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.,Documentation built with ,.
    "
name,content
Chameleon,"Chameleon,Contents,Indices and Tables,Notes,page templates,Found a bug?,Need help?,page templates,path,template attribute language,macro expansion language,internationalization language,target
language,Chameleon is an HTML/XML template engine for ,.,It’s designed to generate the document output of a web application,
typically HTML markup or XML.,The language used is ,, originally a , invention ,, but available here as a
, that you can use in any
script or application running Python 2.7 and up, including 3.4+ and
,). It comes with a set of ,, too.,The template engine compiles templates into Python byte-code and is optimized
for speed. For a complex template language, the performance is
,., Please report issues to the ,., Post to the Pylons , or join the , channel on ,.,You can , the
package from the Python package index or install the latest release
using setuptools or the newer , (required for Python 3.x):,There are no required library dependencies on Python 2.7 and up
,.,The project is hosted in a ,. Code contributions are
welcome. The easiest way is to use the , interface.,The , language is used within your document structure
as special element attributes and text markup. Using a set of simple
language constructs, you control the document flow, element
repetition, text replacement and translation.,Note,If you’ve used page templates in a Zope environment previously, note that Chameleon uses Python as the default expression language (instead of , expressions).,The basic language (known as the , or TAL)
is simple enough to grasp from an example:,The , notation is short-hand for text insertion ,. The
Python-expression inside the braces is evaluated and the result
included in the output. By default, the string is escaped before
insertion. To avoid this, use the , prefix:,Note that if the expression result is an object that implements an
, method ,, this method will be called and the result
treated as “structure”. An example of such an object is the
, class that’s included as a utility:,The macro language (known as the , or METAL)
provides a means of filling in portions of a generic template.,On the left, the macro template; on the right, a template that loads
and uses the macro, filling in the “content” slot:,In the example, the expression type , is
used to retrieve a template from the file system using a path relative
to the calling template.,The METAL system works with TAL such that you can for instance fill in
a slot that appears in a , loop, or refer to variables
defined using ,.,The third language subset is the translation system (known as the
, or I18N):,Each translation message is marked up using , and
values can be mapped using ,. Attributes are marked for
translation using ,. The template engine generates
, translation strings from
the markup:,If you use a web framework such as ,, the
translation system is set up automatically and will negotiate on a , based on the HTTP request or other parameter. If not, then
you need to configure this manually.,This was just an introduction. There are a number of other basic
statements that you need to know in order to use the language. This is
all covered in the ,.,If you’re already familiar with the page template language, you can
skip ahead to the ,
section to learn how to use the template engine in your code.,To learn about integration with your favorite web framework see the
section on ,.,This software is made available under a BSD-like license.,
        © Copyright 2008-2017 by Malthe Borch and the Repoze Community
      
        ,
      

    "
name,content
argon2-cffi-bindings,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,hynek/argon2-cffi-bindings,Name already in use,Low-level Python CFFI Bindings for Argon2,argon2-cffi-bindings,argon2-cffi,argon2-cffi,argon2-cffi-bindings,argon2-cffi-bindings,argon2-cffi-bindings,argon2-cffi-bindings,argon2-cffi-bindings,cffi,argon2-cffi-bindings,BLAKE2,argon2-cffi-bindings,argon2-cffi-bindings,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Low-level Python CFFI Bindings for Argon2
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
, provides low-level , bindings to the official implementation of the , password hashing algorithm.,The currently vendored Argon2 commit ID is ,.,
If you want to hash passwords in an application, this package is , for you.
Have a look at , with its high-level abstractions!,These bindings have been extracted from , and it remains its main consumer.
However, they may be used by other packages that want to use the Argon2 library without dealing with C-related complexities., is available from ,.
The provided CFFI bindings are compiled in API mode.,Best effort is given to provide binary wheels for as many platforms as possible.,A copy of , is vendored and used by default, but can be disabled if , is installed using:,Usually the build process tries to guess whether or not it should use ,-optimized code (see , for details).
This can go wrong and is problematic for cross-compiling.,Therefore you can use the , environment variable to control the process:,However, if our heuristics fail you, we would welcome a bug report.,Since this package is intended to be an implementation detail, it uses a private module name to prevent your users from using it by accident.,Therefore you have to import the symbols from ,:,Please refer to , on how to use the , and , objects.,The list of symbols that are provided can be found in the ,., is written and maintained by ,.
It is released under the ,.,The development is kindly supported by ,.,The authors of Argon2 were very helpful to get the library to compile on ancient versions of Visual Studio for ancient versions of Python.,The documentation quotes frequently in verbatim from the Argon2 , to avoid mistakes by rephrasing.,The original Argon2 repo can be found at ,.,Except for the components listed below, the Argon2 code in this repository is copyright (c) 2015 Daniel Dinu, Dmitry Khovratovich (main authors), Jean-Philippe Aumasson and Samuel Neves, and under , license.,The string encoding routines in src/encoding.c are copyright (c) 2015 Thomas Pornin, and under , license.,The , code in , is copyright (c) Samuel Neves, 2013-2015, and under , license.,Available as part of the Tidelift Subscription.,The maintainers of , and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open-source packages you use to build your applications.
Save time, reduce risk, and improve code health, while paying the maintainers of the exact packages you use.
,
      Low-level Python CFFI Bindings for Argon2
    "
name,content
MouseInfo,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,asweigart/mouseinfo,Name already in use,MouseInfo,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        An application to display XY position and RGB color information for the pixel currently under the mouse. Works on Python 2 and 3.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,An application to display XY position and RGB color information for the pixel currently under the mouse. Works on Python 2 and 3. This is useful for GUI automation planning.,The full documentation is at ,To install with pip, run:,To run this application, enter the following into the terminal:,Or for Python 2, run:,Alternatively, to run it from the interactive shell or a Python program:,The Mouse Info application displays the current XY coordinates of the mouse cursor, as well as the RGB color information of the pixel directly under the cursor. This can be useful for planning out GUI automation tests where the mouse is controlled by a script (such as a Python script with PyAutoGUI) to click on the screen at specific coordinates.,The ""Copy"" buttons will copy this mouse information to the clipboard, while the ""Log"" buttons will add this mouse information to the text field in the application. The RGB color information is given as a comman-delimited, three-integer red, green, and blue values as decimals from 0 to 255. The hex values of the RGB value is also given.,For practical use, you should set the keyboard focus on these buttons by tabbing over them. This leaves you free to move the mouse into position and then press space or Enter to log the current mouse coordinates/RGB value.,The contents of the log text field can be saved by clicking ""Save Log"". This will automatically overwrite any file with the provided name. A screenshot can also be saved by clicking ""Save Screenshot"",If you'd like to contribute to MouseInfo, check out ,If you find this project helpful and would like to support its development, ,.,
      An application to display XY position and RGB color information for the pixel currently under the mouse. Works on Python 2 and 3.
    "
name,content
poyo,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,hackebrot/poyo,Name already in use,poyo,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A lightweight YAML Parser for Python. ,
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A lightweight YAML Parser for Python. , does not allow deserialization of arbitrary Python objects. Supported
types are ,, ,, ,, ,, , as well as , and
, values., Please note that poyo supports only a chosen subset of the YAML format
that is required to parse ,. poyo does not have support for serializing into YAML
and is not compatible with JSON.,poyo is available on , for Python versions 2.7 and newer and can
be installed with ,:,This package does not have any additional requirements. ,poyo comes with a , function, to load utf-8 encoded string
data into a Python dict.,poyo follows the recommendations for ,, which
means it does not configure logging itself. Its root logger is named ,
and the names of all its children loggers track the package/module hierarchy.
poyo logs to a , and solely on , level.,If your application configures logging and allows debug messages to be shown,
you will see logging when using poyo. The log messages indicate which parser
method is used for a given string as the parser deseralizes the config. You
can remove all logging from poyo in your application by setting the log level
of the , logger to a value higher than ,.,We created this project to work around installation issues with a
, version that depended on existing YAML parsers
for Python. For more information please check out this ,.,Would you like to contribute to ,? You're awesome! ,Please check out the , label for tasks,
that are good candidates for your first contribution to poyo. Your
contributions are greatly appreciated! Every little bit helps and credit will
always be given.,Everyone interacting in the poyo project's codebases, issue trackers, chat
rooms, and mailing lists is expected to follow the ,.,Join the poyo ,! 🌍🌏🌎,Distributed under the terms of the , license, poyo is free and open source
software.,
      A lightweight YAML Parser for Python. ,
    "
name,content
en-core-web-md,Explosion builds developer tools for
name,content
netifaces,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,al45tair/netifaces,Name already in use,netifaces 0.10.8,you can have more than one address of
the same type associated with each interface,Asking for ""the"" address of a particular interface doesn't make sense.,peer,may not,very,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Warning,netifaces needs a new maintainer.  al45tair is no longer able to maintain it
or make new releases due to work commitments.,It's been annoying me for some time that there's no easy way to get the
address(es) of the machine's network interfaces from Python.  There is
a good reason for this difficulty, which is that it is virtually impossible
to do so in a portable manner.  However, it seems to me that there should
be a package you can easy_install that will take care of working out the
details of doing so on the machine you're using, then you can get on with
writing Python code without concerning yourself with the nitty gritty of
system-dependent low-level networking APIs.,This package attempts to solve that problem.,First you need to install it, which you can do by typing:,,
as netifaces is written in C and installing this way will compile the extension.,Once that's done, you'll need to start Python and do something like the
following:,Then if you enter,you'll see the list of interface identifiers for your machine.,You can ask for the addresses of a particular interface by doing,Hmmmm.  That result looks a bit cryptic; let's break it apart and explain
what each piece means.  It returned a dictionary, so let's look there first:,Each of the numbers refers to a particular address family.  In this case, we
have three address families listed; on my system, 18 is , (which means
the link layer interface, e.g. Ethernet), 2 is , (normal Internet
addresses), and 30 is , (IPv6).,But wait!  Don't use these numbers in your code.  The numeric values here are
system dependent; fortunately, I thought of that when writing netifaces, so
the module declares a range of values that you might need.  e.g.,Again, on your system, the number may be different.,So, what we've established is that the dictionary that's returned has one
entry for each address family for which this interface has an address.  Let's
take a look at the , addresses now:,You might be wondering why this value is a list.  The reason is that it's
possible for an interface to have more than one address, even within the
same family.  I'll say that again: ,.,Right, so, we can see that this particular interface only has one address,
and, because it's a loopback interface, it's point-to-point and therefore
has a , address rather than a broadcast address.,Let's look at a more interesting interface.,This interface has two addresses (see, I told you...)  Both of them are
regular IPv4 addresses, although in one case the netmask has been changed
from its default.  The netmask , appear on your system if it's set
to the default for the address range.,Because this interface isn't point-to-point, it also has broadcast addresses.,Now, say we want, instead of the IP addresses, to get the MAC address; that
is, the hardware address of the Ethernet adapter running this interface.  We
can do,Note that this may not be available on platforms without getifaddrs(), unless
they happen to implement ,.  Note also that you just get the
address; it's unlikely that you'll see anything else with an , address.
Oh, and don't assume that all , addresses are Ethernet; you might, for
instance, be on a Mac, in which case:,No, that isn't an exceptionally long Ethernet MAC address---it's a FireWire
address.,As of version 0.10.0, you can also obtain a list of gateways on your
machine:,This dictionary is keyed on address family---in this case, ,---and
each entry is a list of gateways as , tuples.
Notice that here we have two separate gateways for IPv4 (,); some
operating systems support configurations like this and can either route packets
based on their source, or based on administratively configured routing tables.,For convenience, we also allow you to index the dictionary with the special
value ,, which returns a dictionary mapping address families to the
default gateway in each case.  Thus you can get the default IPv4 gateway with,Do note that there may be no default gateway for any given address family;
this is currently very common for IPv6 and much less common for IPv4 but it
can happen even for ,.,BTW, if you're trying to configure your machine to have multiple gateways for
the same address family, it's a very good idea to check the documentation for
your operating system , carefully, as some systems become extremely
confused or route packets in a non-obvious manner.,I'm very interested in hearing from anyone (on any platform) for whom the
, method doesn't produce the expected results.  It's quite
complicated extracting this information from the operating system (whichever
operating system we're talking about), and so I expect there's at least one
system out there where this just won't work.,It gets regular testing on OS X, Linux and Windows.  It has also been used
successfully on Solaris, and it's expected to work properly on other UNIX-like
systems as well.  If you are running something that is not supported, and
wish to contribute a patch, please use Github to send a pull request.,It's an MIT-style license. See ,.,Because someone released a fork of netifaces with the version 0.9.0.
Hopefully skipping the version number should remove any confusion.  In
addition starting with 0.10.0 Python 3 is now supported and other
features/bugfixes have been included as well.  See the CHANGELOG for a
more complete list of changes."
name,content
pluggy,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pytest-dev/pluggy,Name already in use,pluggy - A minimalist production ready plugin system,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A minimalist production ready plugin system
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , , , , ,This is the core framework used by the ,, ,, and , projects.,Please , to learn more!,Running this directly gets us:,
      A minimalist production ready plugin system
    "
name,content
oslo.i18n,"oslo.i18n – Oslo Internationalization Utilities,oslo.i18n – Oslo Internationalization Utilities,The oslo.i18n library contain utilities for working with
internationalization (i18n) features, especially translation for text
strings in an application or library.,Read also the ,.,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Docs.openstack.org is powered by
          ,.
        "
name,content
binaryornot,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,binaryornot/binaryornot,Name already in use,BinaryOrNot,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Ultra-lightweight pure Python package to check if a file is binary or text.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Ultra-lightweight pure Python package to guess whether a file is binary or text,
using a heuristic similar to Perl's pp_fttext and its analysis by @eliben.,It works, and people are using this package in various places. But it doesn't cover all edge cases yet.,The code could be improved. Pull requests welcome! As of now, it is based on these snippets, but that may change:,Has tests for these file types:,Has tests for numerous encodings.,You may be thinking, ""I can write this in 2 lines of code?!"",It's actually not that easy. Here's a great article about how Perl's
heuristic to guess file types works: ,And that's just where we started. Over time, we've found more edge cases and
our heuristic has gotten more complex.,Also, this package saves you from having to write and thoroughly test
your code with all sorts of weird file types and encodings, cross-platform.,Linux (Ubuntu 12.04 LTS Server Edition 64 bit):,Windows (Windows Server 2012 R2 (x64)):,This project was created by ,.,
      Ultra-lightweight pure Python package to check if a file is binary or text.
    "
name,content
asteval,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,newville/asteval,Name already in use,ASTEVAL,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        minimalistic evaluator of python expression using ast module
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,ASTEVAL is a safe(ish) evaluator of Python expressions and statements,
using Python's ast module.  The idea is to provide a simple, safe, and
robust miniature mathematical language that can handle user-input.  The
emphasis here is on mathematical expressions, and so many functions from
, are imported and used if available.,Many Python lanquage constructs are supported by default, These include
slicing, subscripting, list comprehension, conditionals (if-elif-else
blocks and if expressions), flow control (for loops, while loops, and
try-except-finally blocks). All data are python objects, and built-in data
structures (dictionaries, tuple, lists, numpy arrays, strings) are fully
supported by default.,Many of the standard builtin python functions are available, as are all
mathemetical functions from the math module.  If the numpy module is
installed, many of its functions will also be available.  Users can define
and run their own functions within the confines of the limitations of
asteval.,There are several absences and differences with Python, and asteval is by
no means an attempt to reproduce Python with its own ast module.  Some of
the most important differences and absences are:,In addition, accessing many internal methods and classes of objects is
forbidden in order to strengthen asteval against malicious user code.,
      minimalistic evaluator of python expression using ast module
    "
name,content
multi-rake,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,vgrabovets/multi_rake,Name already in use,Multilingual Rapid Automatic Keyword Extraction (RAKE) for Python,Default 3,Default 3,Default 1,Default None,Default None,Default 50,Default 2,Default 80,Default 3,Default 2,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Multilingual Rapid Automatic Keyword Extraction (RAKE) for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,If installation fails due to , error ,, than it can be installed with,English text, we don't specify explicitly language nor list of stopwords (built-in list is used).,Text written in Esperanto (article about ,).
There is no list of stopwords for this language, they will be generated from provided text., consists of three first paragraphs of introduction. , - all other text.,So, we are able to get decent result without explicit set of stopwords.,Initialize rake object, - word is selected to be part of keyword if its length is >= min_chars. , - maximum number of words in phrase considered to be a keyword. , - minimum number of occurences of a phrase to be considered a keyword. , - provide language code as string to use built-in set of stopwords. See list of available languages. If language is not specified algorithm will try to determine language with , and use corresponding set of built-in stopwords. , - provide own collection of stopwords (preferably as set, lowercased). Overrides , if it was specified. ,Keep , and , as , and stopwords will be generated from provided text., - threshold for probability of detected language in , (0-100). , - the same as , but will be used if language is unknown and stopwords are generated from provided text. Usually the best result is obtained when specifically crafted set of stopwords is used, in case of its absence and usage of generated stopwords resulting keywords may not be as pretty and it may be good idea, for example, to produce 2-word keywords for unknown languages and 3-word keywords for languages with predefined sets of stopwords. , - to generate stopwords we create distribution of every word in text by frequency. Words above this percentile (0 - 100) will be considered candidates to become stopwords. , - maximum character length of generated stopwords. , - minimum frequency of generated stopwords in the distribution. ,Apply rake object to text., - string containing text from which keywords should be generated., - string containing text which will be used for stopwords generation alongside ,. For example, you have article with introduction and several subsections. You know that for your purposes keywords from introduction will suffice, you don't know language of text nor you have list of stopwords. So stopwords can be generated from text itself and the more text you have, the better. Than you may specify ,.,RAKE algorithm works as described in Rose, S., Engel, D., Cramer, N., & Cowley, W. (2010). Automatic Keyword Extraction from Individual Documents. In M. W. Berry & J. Kogan (Eds.), Text Mining: Theory and Applications: John Wiley & Sons,This implementation is different from others by its multilingual support.
Basically you may provide text without knowing its language (it should be written with cyrillic or latin alphabets),
without explicit list of stopwords and get decent result.
Though the best result is achieved with thoroughly constructed list of stopwords.,What is happening under the hood:,We generate stopwords by creating frequency distribution of words in text and filtering them with parameters ,, ,, ,. We won't be able to generate them perfectly but it is rather easy to find articles and prepositions, because usually they consist of 3-4 characters and appear frequently. These stopwords, coupled with punctuation delimiters, enable us to get decent results for languages we don't understand.,During RAKE initialization only language code should be used.,Repository has configured linter, tests and coverage.,Create new virtual environment inside multi_rake folder in order to use it.,RAKE algorithm: Rose, S., Engel, D., Cramer, N., & Cowley, W. (2010). Automatic Keyword Extraction from Individual Documents. In M. W. Berry & J. Kogan (Eds.), Text Mining: Theory and Applications: John Wiley & Sons,As a basis RAKE implementation by , was used.,Stopwords: ,, ,
      Multilingual Rapid Automatic Keyword Extraction (RAKE) for Python
    "
name,content
h11,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-hyper/h11,Name already in use,h11,Whyyyyy?,else,Should I use it?,What are the features/limitations?,parser,parser wrapper,How do I try it?,License?,Code of conduct?,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A pure-Python, bring-your-own-I/O implementation of HTTP/1.1
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This is a little HTTP/1.1 library written from scratch in Python,
heavily inspired by ,.,It's a ""bring-your-own-I/O"" library; h11 contains no IO code
whatsoever. This means you can hook h11 up to your favorite network
API, and that could be anything you want: synchronous, threaded,
asynchronous, or your own implementation of , -- h11 won't judge you.
(Compare this to the current state of the art, where every time a , comes along then someone
gets to start over reimplementing the entire HTTP protocol from
scratch.) Cory Benfield made an ,, or if you like video
then here's his ,.,This also means that h11 is not immediately useful out of the box:
it's a toolkit for building programs that speak HTTP, not something
that could directly replace , or , or
whatever. But h11 makes it much easier to implement something like
, or ,.,At a high level, working with h11 goes like this:,For example, a client might instantiate and then send a
, object, then zero or more , objects for the
request body (e.g., if this is a POST), and then a
, to indicate the end of the message. Then the
server would then send back a ,, some ,, and
its own ,. If either side violates the protocol,
you'll get a , exception.,h11 is suitable for implementing both servers and clients, and has a
pleasantly symmetric API: the events you send as a client are exactly
the ones that you receive as a server and vice-versa.,It also has ,.,I wanted to play with HTTP in , and ,, which at the time didn't have any
HTTP libraries. So I thought, no big deal, Python has, like, a dozen
different implementations of HTTP, surely I can find one that's
reusable. I didn't find one, but I did find Cory's call-to-arms
blog-post. So I figured, well, fine, if I have to implement HTTP from
scratch, at least I can make sure no-one , has to ever again.,Maybe. You should be aware that it's a very young project. But, it's
feature complete and has an exhaustive test-suite and complete docs,
so the next step is for people to try using it and see how it goes
:-). If you do then please let us know -- if nothing else we'll want
to talk to you before making any incompatible changes!,Roughly speaking, it's trying to be a robust, complete, and non-hacky
implementation of the first ""chapter"" of the HTTP/1.1 spec: ,. That is, it mostly focuses on
implementing HTTP at the level of taking bytes on and off the wire,
and the headers related to that, and tries to be anal about spec
conformance. It doesn't know about higher-level concerns like URL
routing, conditional GETs, cross-origin cookie policies, or content
negotiation. But it does know how to take care of framing,
cross-version differences in keep-alive handling, and the ""obsolete
line folding"" rule, so you can focus your energies on the hard /
interesting parts for your application, and it tries to support the
full specification in the sense that any useful HTTP/1.1 conformant
application should be able to use h11.,It's pure Python, and has no dependencies outside of the standard
library.,It has a test suite with 100.0% coverage for both statements and
branches.,Currently it supports Python 3 (testing on 3.7-3.10) and PyPy 3.
The last Python 2-compatible version was h11 0.11.x.
(Originally it had a Cython wrapper for , and a beautiful nested state
machine implemented with , to postprocess the output. But
I had to take these out -- the new , needs fewer lines-of-code
than the old ,, is written in pure Python, uses no
exotic language syntax, and has more features. It's sad, really; that
old state machine was really slick. I just need a few sentences here
to mourn that.),I don't know how fast it is. I haven't benchmarked or profiled it yet,
so it's probably got a few pointless hot spots, and I've been trying
to err on the side of simplicity and robustness instead of
micro-optimization. But at the architectural level I tried hard to
avoid fundamentally bad decisions, e.g., I believe that all the
parsing algorithms remain linear-time even in the face of pathological
input like slowloris, and there are no byte-by-byte loops. (I also
believe that it maintains bounded memory usage in the face of
arbitrary/pathological input.),The whole library is ~800 lines-of-code. You can read and understand
the whole thing in less than an hour. Most of the energy invested in
this so far has been spent on trying to keep things simple by
minimizing special-cases and ad hoc state manipulation; even though it
is now quite small and simple, I'm still annoyed that I haven't
figured out how to make it even smaller and simpler. (Unfortunately,
HTTP does not lend itself to simplicity.),The API is ~feature complete and I don't expect the general outlines
to change much, but you can't judge an API's ergonomics until you
actually document and use it, so I'd expect some changes in the
details.,and go from there.,MIT,Contributors are requested to follow our , in
all project spaces.,
      A pure-Python, bring-your-own-I/O implementation of HTTP/1.1
    "
name,content
notes-mclds,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,miccaldas/notes,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Command line note taking app.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Command line note taking app. It allows for titles, tags, body of note and
that's it. Records are kept in a mysql database, so it was easy to implement
search, deletion and updating functionalities.
Oh! It has something I have not seen in any cli note apps. You can see all the
notes as in a list. It's much easier to search this way. Most of the time we
don't remember the title or the exact wording, but we are fairly sure that it
was the third last entry you did in the note app.,
      Command line note taking app.
    "
name,content
fissix,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,amyreese/fissix,Name already in use,fissix,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        backport of lib2to3, with enhancements
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Backport of latest lib2to3, with enhancements.,
,
,
, or ,, depending on the
operating system's Python policy.  On Debian ≥11 and derivatives such
as Ubuntu 21.04, ,.,fissix is licensed under the Python Software Foundation License Version 2.
I am providing code in this repository to you under an open source license.
Because this is my personal repository, the license you receive to my code
is from me and not from my employer.
See the , file for details.,
      backport of lib2to3, with enhancements
    "
name,content
pbr,"pbr - Python Build Reasonableness,pbr - Python Build Reasonableness,setuptools,pbr,setuptools,setuptools,pip,pbr,A library for managing , packaging needs in a consistent manner., reads and then filters the , data through a setup hook to
fill in default values and provide more sensible behaviors, and then feeds the
results in as the arguments to a call to , - so the heavy lifting of
handling Python packaging needs is still being done by ,.,Note that we don’t support the , aspects of ,: while
we depend on ,, for any , we recommend that
they be installed prior to running , - either by hand, or by
using an install tool such as ,., can and does do a bunch of things for you:,: Manage version number based on git revisions and tags,: Generate AUTHORS file from git log,: Generate ChangeLog from git log,: Generate a sensible manifest from git files and some standard
files,: Generate a release notes file using reno,: Store your dependencies in a pip requirements file,: Use your README file as a long_description,: Smartly find packages under your root package,: Generate autodoc stub files for your whole module,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Docs.openstack.org is powered by
          ,.
        "
name,content
networkx,"NetworkX is a Python package for the creation, manipulation, and
                study of the structure, dynamics, and functions of complex networks."
name,content
grab,
name,content
ipywidgets,"JupyterLab is the latest web-based interactive development environment for notebooks, code, and data. Its flexible interface allows users to configure and arrange workflows in data science, scientific computing, computational journalism, and machine learning. A modular design invites extensions to expand and enrich functionality.,The Jupyter Notebook is the original web application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience.,Jupyter supports over 40 programming languages, including Python, R, Julia, and Scala.,Notebooks can be shared with others using email, Dropbox, GitHub and the ,.,Your code can produce rich, interactive output: HTML, images, videos, LaTeX, and custom MIME types.,Leverage big data tools, such as Apache Spark, from Python, R, and Scala. Explore that same data with pandas, scikit-learn, ggplot2, and TensorFlow.,A multi-user version of the notebook designed for companies, classrooms and research labs,Manage users and authentication with PAM, OAuth or integrate with your own directory service system.,Deploy the Jupyter Notebook to thousands of users in your organization on centralized infrastructure on- or off-site.,Use Docker and Kubernetes to scale your deployment, isolate user processes, and simplify software installation.,Deploy the Notebook next to your data to provide unified software management and data access within your organization.,Voilà helps communicate insights by transforming notebooks into secure, stand-alone web applications that you can customize and share.,Project Jupyter promotes open standards that third-party developers can leverage to build customized applications. Think HTML and CSS for interactive computing on the web.,Jupyter Notebooks are an open document format based on JSON. They contain a complete record of the user's sessions and include code, narrative text, equations, and rich output.,The Notebook communicates with computational Kernels using the Interactive Computing Protocol, an open network protocol based on JSON data over ZMQ, and WebSockets.,Kernels are processes that run interactive code in a particular programming language and return output to the user. Kernels also respond to tab completion and introspection requests.,
              The Jupyter Trademark is registered with the U.S. Patent & Trademark Office. © 2023
          "
name,content
keyboard,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,boppreh/keyboard,Name already in use,keyboard,API,(aliases: ,),(aliases: ,, ,, ,),(aliases: ,),(aliases: ,, ,, ,),(aliases: ,, ,, ,),(aliases: ,),(aliases: ,),(aliases: ,),(aliases: ,),hotkey,pressed,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Hook and simulate global keyboard events on Windows and Linux.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Take full control of your keyboard with this small Python library. Hook global events, register hotkeys, simulate key presses and much more.,Install the ,:,or clone the repository (no installation required, source files are sufficient):,or , into your project folder.,Then check the , to see what features are available.,Use as library:,Use as standalone module:,Returns True if , is a scan code or name of a modifier key.,Returns a list of scan codes associated with this key (name or scan code).,Parses a user-provided hotkey into nested tuples representing the
parsed structure, with the bottom values being lists of scan codes.
Also accepts raw scan codes, which are then wrapped in the required
number of nestings.,Example:,Sends OS events that perform the given , hotkey.,Note: keys are released in the opposite order they were pressed.,Presses and holds down a hotkey (see ,).,Releases a hotkey (see ,).,Returns True if the key is pressed.,Calls the provided function in a new thread after waiting some time.
Useful for giving the system some time to process an event, without blocking
the current execution flow.,Installs a global listener on all available keyboards, invoking ,
each time a key is pressed or released.,The event passed to the callback is of type ,,
with the following attributes:,Returns the given callback for easier development.,Invokes , for every KEY_DOWN event. For details see ,.,Invokes , for every KEY_UP event. For details see ,.,Hooks key up and key down events for a single key. Returns the event handler
created. To remove a hooked key use , or
,.,Note: this function shares state with hotkeys, so ,
affects it as well.,Invokes , for KEY_DOWN event related to the given key. For details see ,.,Invokes , for KEY_UP event related to the given key. For details see ,.,Removes a previously added hook, either by callback or by the return value
of ,.,Removes all keyboard hooks in use, including hotkeys, abbreviations, word
listeners, ,ers and ,s.,Suppresses all key events of the given key, regardless of modifiers.,Whenever the key , is pressed or released, regardless of modifiers,
press or release the hotkey , instead.,Parses a user-provided hotkey. Differently from ,,
instead of each step being a list of the different scan codes for each key,
each step is a list of all possible combinations of those scan codes.,Invokes a callback every time a hotkey is pressed. The hotkey must
be in the format ,. This would trigger when the user holds
ctrl, shift and ""a"" at once, releases, and then presses ""s"". To represent
literal commas, pluses, and spaces, use their names ('comma', 'plus',
'space').,The event handler function is returned. To remove a hotkey call
, or ,.
before the hotkey state is reset.,Note: hotkeys are activated when the last key is ,, not released.
Note: the callback is executed in a separate thread, asynchronously. For an
example of how to use a callback synchronously, see ,.,Examples:,Removes a previously hooked hotkey. Must be called with the value returned
by ,.,Removes all keyboard hotkeys in use, including abbreviations, word listeners,
,ers and ,s.,Whenever the hotkey , is pressed, suppress it and send
, instead.,Example:,Builds a list of all currently pressed scan codes, releases them and returns
the list. Pairs well with , and ,.,Given a list of scan_codes ensures these keys, and only these keys, are
pressed. Pairs well with ,, alternative to ,.,Like ,, but only restores modifier keys.,Sends artificial keyboard events to the OS, simulating the typing of a given
text. Characters not available on the keyboard are typed as explicit unicode
characters using OS-specific functionality, such as alt+codepoint.,To ensure text integrity, all currently pressed keys are released before
the text is typed, and modifiers are restored afterwards.,Blocks the program execution until the given hotkey is pressed or,
if given no parameters, blocks forever.,Returns a string representation of hotkey from the given key names, or
the currently pressed keys if not given.  This function:,Example:,Blocks until a keyboard event happens, then returns that event.,Blocks until a keyboard event happens, then returns that event's name or,
if missing, its scan code.,Similar to ,, but blocks until the user presses and releases a
hotkey (or single key), then returns a string representing the hotkey
pressed.,Example:,Given a sequence of events, tries to deduce what strings were typed.
Strings are separated when a non-textual key is pressed (such as tab or
enter). Characters are converted to uppercase according to shift and
capslock status. If , is True, backspaces remove the last
character typed.,This function is a generator, so you can pass an infinite stream of events
and convert them to strings in real time.,Note this functions is merely an heuristic. Windows for example keeps per-
process keyboard state such as keyboard layout, and this information is not
available for our hooks.,Starts recording all keyboard events into a global variable, or the given
queue if any. Returns the queue of events and the hooked function.,Use , or , to stop.,Stops the global recording of events and returns a list of the events
captured.,Records all keyboard events from all keyboards until the user presses the
given hotkey. Then returns the list of events recorded, of type
,. Pairs well with
,.,Note: this is a blocking function.
Note: for more details on the keyboard hook and events see ,.,Plays a sequence of recorded events, maintaining the relative time
intervals. If speed_factor is <= 0 then the actions are replayed as fast
as the OS allows. Pairs well with ,.,Note: the current keyboard state is cleared at the beginning and restored at
the end of the function.,Invokes a callback every time a sequence of characters is typed (e.g. 'pet')
and followed by a trigger key (e.g. space). Modifiers (e.g. alt, ctrl,
shift) are ignored.,Returns the event handler created. To remove a word listener use
, or ,.,Note: all actions are performed on key down. Key up events are ignored.
Note: word matches are ,.,Removes a previously registered word listener. Accepts either the word used
during registration (exact string) or the event handler returned by the
, or , functions.,Registers a hotkey that replaces one typed text with another. For example,Replaces every ""tm"" followed by a space with a ™ symbol (and no space). The
replacement is done by sending backspace events.,For more details see ,.,Given a key name (e.g. ""LEFT CONTROL""), clean up the string and convert to
the canonical representation (e.g. ""left ctrl"") if one is known.,
      Hook and simulate global keyboard events on Windows and Linux.
    "
name,content
netaddr,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,netaddr/netaddr,Name already in use,netaddr,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A network address manipulation library for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A system-independent network address manipulation library for Python 2.7 and 3.5+.
(Python 2.7 and 3.5 support is deprecated).,Provides support for:,Layer 3 addresses,Layer 2 addresses,Starting with Python 3.3 there's an ,
module in the Python standard library which provides layer 3 address manipulation
capabilities overlapping ,.,Latest documentation ,Share and enjoy!,
      A network address manipulation library for Python
    "
name,content
outdated,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,alexmojaki/outdated,Name already in use,outdated,not,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Check if a version of a PyPI package is outdated
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , ,This is a mini-library which, given a package name and a version, checks if it's the latest version available on PyPI.,To install:,This will:,This will , check what version is currently installed, it will only use the given version. Library authors must make sure that the version in their , matches the version here.,The package name argument must be exactly the name used on PyPI, so that e.g. , is a valid URL.,Optional arguments:, is a boolean which is True if the given version is earlier than the latest version, which is the string ,.,Optional arguments:,This still makes the HTTP call with retries and caches the result on disk. It doesn't use a separate thread or emit any warnings (unless there is an exception specifically while using the cache, in which case the check will be done without the cache).,To disable all warnings from this library, set the environment variable , to any non-empty value.,To always raise exceptions instead of converting them to warnings (both in general in , and more specifically when there's a caching problem) set the environment variable ,.,The warnings are also categorised so that you can easily control them with standard ,. The classes are , and can be imported directly from the , module.,This library works by fetching a URL such as , - the time it takes to visit that link is essentially the speed of the library. This is much faster than the command , or any equivalent code.,
      Check if a version of a PyPI package is outdated
    "
name,content
agate-sql,"agate-sql 0.5.8,API,agate-sql adds SQL read/write support to ,.,Important links:,agate             ,Documentation:    ,Repository:       ,Issues:           ,To install:,For details on development or supported platforms see the ,.,Warning,You’ll need to have the correct , installed for whatever database you plan to access. For instance, in order to read/write tables in a Postgres database, you’ll also need to ,.,agate-sql uses a monkey patching pattern to add SQL support to all , instances.,Importing , attaches new methods to ,. For example, to import a table named , from a local postgresql database named , you will use ,:,To save this table back to the database:,The first argument to either function can be any valid ,. The second argument must be a database name. (Arbitrary SQL queries are not supported.),That’s all there is to it.,Create a new , from a given SQL table. Types will be
inferred from the database schema.,Monkey patched as class method ,., – An existing sqlalchemy connection or connection string., – The name of a table in the referenced database.,Create an agate table from the results of a SQL query. Note that column
data types will be inferred from the returned data, not the column types
declared in SQL (if any). This is more flexible than , but
could result in unexpected typing issues., – A SQL query to execute.,Write this table to the given SQL database.,Monkey patched as instance method ,., – An existing sqlalchemy connection or a connection string., – The name of the SQL table to create., – Drop any existing table with the same name before creating., – Create the table., – When creating the table, don’t fail if the table already exists., – Insert table data., – Add prefixes to the insert query., – Create table in the specified database schema., – Generate constraints such as , for table columns., – The names of the columns to include in a UNIQUE constraint., – Write rows in batches of this size. If not set, rows will be written at once., – The minimum length of text columns., – Multiply the maximum column length by this multiplier to accomodate larger values in later runs.,Generates a CREATE TABLE statement for this SQL table, but does not execute
it., – The name of the SQL table to create., – The dialect of SQL to use for the table statement., – Create table in the specified database schema., – Generate constraints such as , for table columns., – The names of the columns to include in a UNIQUE constraint.,Convert this agate table into an intermediate, in-memory sqlite table,
run a query against it, and then return the results as a new agate table.,Multiple queries may be separated with semicolons., – One SQL query, or multiple queries to be run consecutively separated
with semicolons., – The name to use for the table in the queries, defaults to ,.,The following individuals have contributed code to agate-sql:,Disallow SQLAlchemy 2.,Fix tests for Linux packages.,Add wheels distribution.,Fix test that fails in specific environments.,Set type to , for datetime (MS SQL).,Drop support for Python 2.7 (EOL 2020-01-01), 3.4 (2019-03-18), 3.5 (2020-09-13).,Add , and , options to , to control the length of text columns.,agate-sql is now tested against Python 3.7.,Drop support for Python 3.3 (end-of-life was September 29, 2017).,Dialect-specific:,Add support for CrateDB.,Set type to , for boolean (MS SQL).,Eliminate SQLite warning about Decimal numbers.,Add , option to , to write rows in batches.,Add , option to , to include in a UNIQUE constraint.,Dialect-specific:,Specify precision and scale for , (MS SQL, MySQL, Oracle).,Set length of , to , even if maximum length is , (MySQL).,Set type to , if maximum length is greater than 21,844 (MySQL).,Add , flag to ,.,Add , option to , to add expressions following the INSERT keyword, like OR IGNORE or OR REPLACE.,Use , instead of , for DateTime columns., columns are now generated with proper length constraints (unless explicilty disabled).,Tables can now be created from query results using ,.,Add support for running queries directly on tables with ,.,When creating tables, , constraints will be created by default.,SQL create statements can now be generated without being executed with ,Modified , so it no longer depends on Postgres.,It is no longer necessary to run , after importing agatesql.,Upgrade required agate to ,.,Add , flag to ,.,Removed Python 2.6 support.,Updated agate dependency to version 1.1.0.,Additional SQL types are now supported. (#4, #10),Add explicit patch function.,Initial version.,The MIT License,Copyright (c) 2017 Christopher Groskopf and contributors,Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:,The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.,THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE."
name,content
fancycompleter,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pdbpp/fancycompleter,Name already in use,fancycompleter: colorful Python TAB completion,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Friendly fork of (unmaintained) ,
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a module to improve your experience in Python by
adding TAB completion to the interactive prompt. It is an extension of
the stdlib's
, module.,Its best feature is that the completions are displayed in different
colors, depending on their type:,In the image above, strings are shown in green, functions in blue,
integers and boolean in yellows, , in gray, types and classes in
fuchsia. Everything else is plain white., is compatible with Python 3. However, by default colors
don't work on Python 3, see the section , for details.,First, install the module with , or ,:,Then, at the Python interactive prompt:,If you want to enable , automatically at startup, you can
add those two lines at the end of your
,
script.,If you do , have a , script, the
following command will create one for you in ,:,On Windows, , automatically sets the , environment
variable. On other systems, you need to add the proper command in
, or equivalent.,: depending on your particular system, , might need to
play dirty tricks in order to display colors, although everything should
""just work"". In particular, the call to , should be the last
line in the startup file, else the next lines might not be executed. See
section , for
details.,If you are using ,, you can stop reading now, as ,
will work out of the box.,If you are using , and you installed
, with , or ,, they automatically
installed , as a requirement, and you should also get colors out
of the box. If for some reason you don't want to use ,, you
should keep on reading.,By default, in CPython line input and TAB completion are handled by , (at least
on Linux). However, , explicitly strips escape sequences from
the completions, so completions with colors are not displayed correctly.,There are two ways to solve it:,By default, , tries to use , if it finds it. To
get colors you need a recent version, >= 0.8.2.,Starting from version 0.6.1, , works also on ,,
relying on ,. At the
moment of writing, the latest version of , is 2.1, which does
, support colored completions; here is the , which adds
support for them. To enable colors, you can install , from
, using the following
command:,If you are using ,, , does not work, and thus is not
installed. Your only option to get colors is to use a patched
,, as explained below.,This method is not really recommended, but if you really want, you can
use use a patched readline: you can find the patches in the ,
directory:,You can also try one of the following precompiled versions, which has
been tested on Ubuntu 10.10: remember to put them in a place where the
linker can find them, e.g. by setting ,:,Once it is installed, you should double-check that you can find it, e.g.
by running , on Python's , module:,Finally, you need to force , to use colors, since by
default, it uses colors only with ,: you can do it by placing a
custom config file in ,. An example config file
is
,
(remind that you need to put a dot in front of the filename!).,To customize the configuration of fancycompleter, you need to put a file
named , in your home directory. The file must
contain a class named , inheriting from , and
overridding the desired values.,The default and preferred way to get colors is to use ,. However,
there is no way to tell CPython to use , instead of the built-in
readline at the interactive prompt: this means that even if we install
our completer inside pyrepl's readline library, the interactive prompt
won't see it.,The issue is simply solved by avoiding to use the built-in prompt:
instead, we use a pure Python replacement based on
,.
This brings us also some niceties, such as the ability to do multi-line
editing of the history.,The console is automatically run by ,,
followed by ,: this way, if we execute it from the script in
,, the interpreter exits as soon as we finish the use the
prompt (e.g. by pressing CTRL-D, or by calling ,). This way, we
avoid to enter the built-in prompt and we get a behaviour which closely
resembles the default one. This is why in this configuration lines after
, might not be run.,Note that if we are using , instead of ,, the trick is
not needed and thus , will simply returns, letting the
built-in prompt to show up. The same is true if we are running PyPy, as
its built-in prompt is based on pyrepl anyway.,
      Friendly fork of (unmaintained) ,
    "
name,content
Jinja2,"Jinja,Jinja2 is a full-featured template engine for Python. It has full unicode
support, an optional integrated sandboxed execution environment,
widely used and BSD licensed.,Jinja2 is one of the most used template engines for Python. It is inspired by
Django's templating system but extends it with an expressive language
that gives template authors a more powerful set of tools. On top of that it
adds sandboxed execution and optional automatic escaping for
applications where security is important.,It is internally based on Unicode and runs on a wide range of Python
versions from 2.5 to current versions including Python 3.,
          ,
        
        , ,
        , ,
        , ,
      "
name,content
Protego,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,scrapy/protego,Name already in use,Protego,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A pure-Python robots.txt parser with support for modern conventions. 
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Protego is a pure-Python , parser with support for modern
conventions.,To install Protego, simply use pip:,Using Protego with ,:,The following table compares Protego to the most popular , parsers
implemented in Python or featuring Python bindings:,Class ,:,
      A pure-Python robots.txt parser with support for modern conventions. 
    "
name,content
ffmpeg-python,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,kkroening/ffmpeg-python,Name already in use,ffmpeg-python: Python bindings for FFmpeg,Audio/video pipeline,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python bindings for FFmpeg - with complex filtering support
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,There are tons of Python FFmpeg wrappers out there but they seem to lack complex filter support.  , works well for simple as well as complex signal graphs.,Flip a video horizontally:,Or if you prefer a fluent interface:,FFmpeg is extremely powerful, but its command-line interface gets really complicated rather quickly - especially when working with signal graphs and doing anything more than trivial.,Take for example a signal graph that looks like this:,The corresponding command-line arguments are pretty gnarly:,Maybe this looks great to you, but if you're not an FFmpeg command-line expert, it probably looks alien.,If you're like me and find Python to be powerful and readable, it's easier with ,:, takes care of running , with the command-line arguments that correspond to the above filter diagram, in familiar Python terms.,Real-world signal graphs can get a heck of a lot more complex, but , handles arbitrarily large (directed-acyclic) signal graphs.,The latest version of , can be acquired via a typical pip install:,Or the source can be cloned and installed from locally:,: , makes no attempt to download/install FFmpeg, as , is merely a pure-Python wrapper - whereas FFmpeg installation is platform-dependent/environment-specific, and is thus the responsibility of the user, as described below.,Before using ,, FFmpeg must be installed and accessible via the , environment variable.,There are a variety of ways to install FFmpeg, such as the ,, or using your package manager of choice (e.g. , on Debian/Ubuntu, , on OS X, etc.).,Regardless of how FFmpeg is installed, you can check if your environment path is set correctly by running the , command from the terminal, in which case the version information should appear, as in the following example (truncated for brevity):,: The actual version information displayed here may vary from one system to another; but if a message such as , appears instead of the version information, FFmpeg is not properly installed.,When in doubt, take a look at the , to see if there's something that's close to whatever you're trying to do.,Here are a few:,See the , for additional examples.,Don't see the filter you're looking for?  While , includes shorthand notation for some of the most commonly used filters (such as ,), all filters can be referenced via the , operator:,Or fluently:,Arguments with special names such as , (variable bitrate), , (constant bitrate), etc. can be specified as a keyword-args dictionary as follows:,Filters that take multiple input streams can be used by passing the input streams as an array to ,:,Filters that produce multiple outputs can be used with ,:,(In this particular case, , is the equivalent shorthand, but the general approach works for other multi-output filters),Expressions to be interpreted by ffmpeg can be included as string parameters and reference any special ffmpeg variable names:,When in doubt, refer to the ,, ,, and/or the ,.,Make sure you ran , and , , (wrong) or , (also wrong).,Some ffmpeg filters drop audio streams, and care must be taken to preserve the audio in the final output.  The , and , operators can be used to reference the audio/video portions of a stream so that they can be processed separately and then re-combined later in the pipeline.,This dilemma is intrinsic to ffmpeg, and ffmpeg-python tries to stay out of the way while users may refer to the official ffmpeg documentation as to why certain filters drop audio.,As usual, take a look at the , (, in particular).,You can run , before , to retrieve the command line arguments that will be passed to ,. You can also run , that also includes the , executable as the first argument.,Take a look at each of the links in the , section at the end of this README.  If you look everywhere and can't find what you're looking for and have a question that may be relevant to other users, you may open an issue asking how to do it, while providing a thorough explanation of what you're trying to do and what you've tried so far.,Issues not directly related to , or issues asking others to write your code for you or how to do the work of solving a complex signal processing problem for you that's not relevant to other users will be closed.,That said, we hope to continue improving our documentation and provide a community of support for people using , to do cool and exciting things.,One of the best things you can do to help make , better is to answer , in the issue tracker.  The questions that are answered will be tagged and incorporated into the documentation, examples, and other learning resources.,If you notice things that could be better in the documentation or overall development experience, please say so in the ,.  And of course, feel free to report any bugs or submit feature requests.,Pull requests are welcome as well, but it wouldn't hurt to touch base in the issue tracker or hop on the , first.,Anyone who fixes any of the , or implements , is a hero, but changes should include passing tests.,
      Python bindings for FFmpeg - with complex filtering support
    "
name,content
BTrees,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,zopefoundation/BTrees,Name already in use,:  scalable persistent components,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This package contains a set of persistent object containers built around
a modified BTree data structure.  The trees are optimized for use inside
ZODB's ""optimistic concurrency"" paradigm, and include explicit resolution
of conflicts detected by that mechanism.,Please see , for
further information."
name,content
isoduration,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,bolsote/isoduration,Name already in use,isoduration: Operations with ISO 8601 durations.,Limitations,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Operations with ISO 8601 durations
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,ISO 8601 is most commonly known as a way to exchange datetimes in textual format. A
lesser known aspect of the standard is the representation of durations. They have a
shape similar to this:,This string represents a duration of 3 years, 6 months, 4 days, 12 hours, 30 minutes,
and 5 seconds.,The state of the art of ISO 8601 duration handling in Python is more or less limited to
what's offered by ,. What we are trying to
achieve here is to address the shortcomings of , (as described in their own
, section), and a few of
our own annoyances with their interface, such as the lack of uniformity in their
handling of types, and the use of regular expressions for parsing.,This package revolves around the , type.,Given a ISO duration string we can produce such a type by using the ,
function:,The , and , portions of the parsed duration are just regular
,, so their members can
be accessed in a non-surprising way.,Besides just parsing them, a number of additional operations are available:,These steps, in this order, should land you in a development environment:,Adapt to your own likings and/or needs.,Testing is driven by ,. The output of , and a
careful read of , should get you there.,Some years have 366 days. If it's not always the same, then it's not the same., cannot represent certain durations, such as those involving years or months.
Since it cannot represent all possible durations without dangerous arithmetic, then it
must not be the right type.,Because this wonderful representation is not unique.,Probably because the standard made me to.,Probably because the standard doesn't allow me to.,I'm confused.,You shouldn't do what people on the Internet tell you to do.,Yes.,
      Operations with ISO 8601 durations
    "
name,content
pickleshare,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pickleshare/pickleshare,Name already in use,all,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        File system based database that uses python pickles
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,PickleShare - a small 'shelve' like datastore with concurrency support,Like shelve, a PickleShareDB object acts like a normal dictionary. Unlike shelve,
many processes can access the database simultaneously. Changing a value in
database is immediately visible to other processes accessing the same database.,Concurrency is possible because the values are stored in separate files. Hence
the ""database"" is a directory where , files are governed by PickleShare.,Both python2 and python3 are supported.,Example usage:,This module is certainly not ZODB, but can be used for low-load
(non-mission-critical) situations where tiny code size trumps the
advanced features of a ""real"" object database.,Installation guide:,Or, if installing from source,
      File system based database that uses python pickles
    "
name,content
django-notifs,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,danidee10/django-notifs,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Modular Notifications (InApp, Email, SMS, CustomBackend etc) for Django
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,django-notifs is a modular notifications app for Django that basically allows you to notify users about events that occur in your application E.g,It also allows you to deliver these notifications to any destination you want to with custom delivery channels.,It also supports asynchronous notification with several pluggable delivery backends (e.g Celery, RQ etc),A tutorial on how to build a ,The Repository for the chat app (Chatire) is also available on ,
      Modular Notifications (InApp, Email, SMS, CustomBackend etc) for Django
    "
name,content
django-jsonfield-backport,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,laymonage/django-jsonfield-backport,Name already in use,django-jsonfield-backport,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Backport of the cross-DB JSONField model and form fields from Django 3.1.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Backport of the cross-DB , model and form fields from Django 3.1.,Most features of the JSONField model and form fields from Django 3.1 are
supported.,Due to limited access to Django's APIs, some features are not supported.,This package is fully compatible with the JSONField from Django 3.1. That
means you just need to change your imports and edit your migrations when you
finally upgrade to Django 3.1. If you leave them as they are, this package
will use the built-in JSONField and system warnings will be raised.,This package supports and is tested against the latest patch versions of:,All database backends are tested with the latest versions of their drivers.
SQLite is also tested on GitHub Actions' latest macOS and Windows virtual
environments.,Use , or your preferred dependency management tool to install the package.,Add , to , in your settings.,To use the model and form fields, import , from
, and ,,
respectively.,Model field example:,Form field example:,, ,, and , classes are also
available from ,.,Since this package is a backport, the official Django 3.1 docs for
, and , are mostly compatible with this
package.,As of the creation of this package, JSONField implementations exist in multiple
packages on PyPI:,Along with other unmaintained packages such as ,,
,, ,, ,,
,, ,, ,,
,, and ,.,Up until the new JSONField in Django 3.1, there had been no implementation of
JSONField that supports all the database backends supported by Django with more
or less , as the , JSONField
provides., does not backport new features to previous feature
releases. However, the current LTS release is 2.2 which is still supported until
April 2022. The next LTS release is Django 3.2 in April 2021 that happens to be
the end of extended support for Django 3.1.,Some projects only use LTS releases of Django. There are also incompatibilities
between Django 3.0 and 3.1. Therefore, using Django 3.1 may not be an option for
some people at the moment.,Since JSONField seems to be in popular demand and that it works well as a
standalone package, I decided to create a backport.,Besides, I'm the ,. ¯\_(ツ)_/¯,This package is licensed under the ,.,
      Backport of the cross-DB JSONField model and form fields from Django 3.1.
    "
name,content
Automat,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,glyph/automat,Name already in use,Automat,input,body,output,states,users,inputs,outputs,not have to check themselves,better,we can't add any
implementation code to the input method,all,return,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Self-service finite-state machines for the programmer on the go.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,Automat is a library for concise, idiomatic Python expression of finite-state
automata (particularly deterministic finite-state transducers).,Read more here, or on ,, or watch the following videos for an overview and presentation,Overview and presentation by , at the first talk of the first Pyninsula meetup, on February 21st, 2017:,
,Presentation by , at PyCon Australia, on August 6th 2017:,
,Sometimes you have to create an object whose behavior varies with its state,
but still wishes to present a consistent interface to its callers.,For example, let's say you're writing the software for a coffee machine.  It
has a lid that can be opened or closed, a chamber for water, a chamber for
coffee beans, and a button for ""brew"".,There are a number of possible states for the coffee machine.  It might or
might not have water.  It might or might not have beans.  The lid might be open
or closed.  The ""brew"" button should only actually attempt to brew coffee in
one of these configurations, and the ""open lid"" button should only work if the
coffee is not, in fact, brewing.,With diligence and attention to detail, you can implement this correctly using
a collection of attributes on an object; ,, ,,
, and so on.  However, you have to keep all these attributes
consistent.  As the coffee maker becomes more complex - perhaps you add an
additional chamber for flavorings so you can make hazelnut coffee, for
example - you have to keep adding more and more checks and more and more
reasoning about which combinations of states are allowed.,Rather than adding tedious 'if' checks to every single method to make sure that
each of these flags are exactly what you expect, you can use a state machine to
ensure that if your code runs at all, it will be run with all the required
values initialized, because they have to be called in the order you declare
them.,You can read about state machines and their advantages for Python programmers
in more detail ,.,There are
,.
So it behooves me to say why yet another one would be a good idea.,Automat is designed around this principle: while organizing your code around
state machines is a good idea, your callers don't, and shouldn't have to, care
that you've done so.  In Python, the ""input"" to a stateful system is a method
call; the ""output"" may be a method call, if you need to invoke a side effect,
or a return value, if you are just performing a computation in memory.  Most
other state-machine libraries require you to explicitly create an input object,
provide that object to a generic ""input"" method, and then receive results,
sometimes in terms of that library's interfaces and sometimes in terms of
classes you define yourself.,For example, a snippet of the coffee-machine example above might be implemented
as follows in naive Python:,With Automat, you'd create a class with a , attribute:,and then you would break the above logic into two pieces - the ,
,, declared like so:,It wouldn't do any good to declare a method , on this, however, because
input methods don't actually execute their bodies when called; doing actual
work is the ,'s job:,As well as a couple of , - and for simplicity's sake let's say that the
only two states are , and ,:, is the , state because , starts without beans
in it.,(And another input to put some beans in:),Finally, you hook everything together with the , method of the functions
decorated with ,:,To , of this coffee machine class though, it still looks like a POPO
(Plain Old Python Object):,All of the , are provided by calling them like methods, all of the
, are automatically invoked when they are produced according to the
outputs specified to , and all of the states are simply opaque tokens -
although the fact that they're defined as methods like inputs and outputs
allows you to put docstrings on them easily to document them.,Don't do that.,One major reason for having a state machine is that you want the callers of the
state machine to just provide the appropriate input to the machine at the
appropriate time, and , what state the machine is
in.  So if you are tempted to write some code like this:,Instead, just make your calling code do this:,and then change your state machine to look like this:,so that the responsibility for knowing which state the state machine is in
remains within the state machine itself.,Quite often you want to be able to pass parameters to your methods, as well as
inspecting their results.  For example, when you brew the coffee, you might
expect a cup of coffee to result, and you would like to see what kind of coffee
it is.  And if you were to put delicious hand-roasted small-batch artisanal
beans into the machine, you would expect a , cup of coffee than if you
were to use mass-produced beans.  You would do this in plain old Python by
adding a parameter, so that's how you do it in Automat as well.,However, one important difference here is that ,.  Inputs are purely a declaration of
the interface; the behavior must all come from outputs.  Therefore, the change
in the state of the coffee machine must be represented as an output.  We can
add an output method like this:,and then connect it to the , by changing the transition from
, to , like so:,Now, when you call:,the machine will remember the beans for later.,So how do we get the beans back out again?  One of our outputs needs to have a
return value.  It would make sense if our , method returned the cup
of coffee that it made, so we should add an output.  So, in addition to heating
the heating element, let's add a return value that describes the coffee.  First
a new output:,Note that we don't need to check first whether , exists or not,
because we can only reach this output method if the state machine says we've
gone through a set of states that sets this attribute.,Now, we need to hook up , to the process of brewing, so change
the brewing transition to:,Now, we can call it:,Except... wait a second, what's that , doing there?,Since every input can produce multiple outputs, in automat, the default return
value from every input invocation is a ,.  In this case, we have both
, and , outputs, so we're seeing
both of their return values.  However, this can be customized, with the
, argument to ,; the , is a callable which takes an
iterable of all the outputs' return values and ""collects"" a single return value
to return to the caller of the state machine.,In this case, we only care about the last output, so we can adjust the call to
, like this:,And now, we'll get just the return value we want:,There are APIs for serializing the state machine.,First, you have to decide on a persistent representation of each state, via the
, argument to the , decorator.,Let's take this very simple ""light switch"" state machine, which can be on or
off, and flipped to reverse its state:,In this case, we've chosen a serialized representation for each state via the
, argument.  The on state is represented by the string ,, and
the off state is represented by the string ,.,Now, let's just add an input that lets us tell if the switch is on or not.,To save the state, we have the , method.  A
method decorated with , gets an extra argument injected at the
beginning of its argument list: the serialized identifier for the state.  In
this case, either , or ,.  Since state machine output methods can
also affect other state on the object, a serializer method is expected to
return , relevant state for serialization.,For our simple light switch, such a method might look like this:,Serializers can be public methods, and they can return whatever you like.  If
necessary, you can have different serializers - just multiple methods decorated
with , - for different formats; return one data-structure
for JSON, one for XML, one for a database row, and so on.,When it comes time to unserialize, though, you generally want a private method,
because an unserializer has to take a not-fully-initialized instance and
populate it with state.  It is expected to , the serialized machine
state token that was passed to the serializer, but it can take whatever
arguments you like.  Of course, in order to return that, it probably has to
take it somewhere in its arguments, so it will generally take whatever a paired
serializer has returned as an argument.,So our unserializer would look like this:,Generally you will want a classmethod deserialization constructor which you
write yourself to call this, so that you know how to create an instance of your
own object, like so:,Saving and loading our , along with its state-machine state can now
be accomplished as follows:,More comprehensive (tested, working) examples are present in ,.,Go forth and machine all the state!,
      Self-service finite-state machines for the programmer on the go.
    "
name,content
appdirs,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,ActiveState/appdirs,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A small Python module for determining appropriate platform-specific dirs, e.g. a ""user data dir"".
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Note: This project has been officially deprecated. You may want to check out , which is a more active fork of appdirs. Thanks to everyone who has used appdirs. Shout out to ActiveState for the time they gave their employees to work on this over the years.,What directory should your app use for storing user data? If running on macOS, you
should use:,If on Windows (at least English Win XP) that should be:,or possibly:,for , but that is another story.,On Linux (and other Unices) the dir, according to the ,, is:,This kind of thing is what the , module is for. , will
help you choose an appropriate:,and also:,On macOS:,On Windows 7:,On Linux:,If you have multiple versions of your app in use that you want to be
able to run side-by-side, then you may want version-isolation for these
dirs:,
      A small Python module for determining appropriate platform-specific dirs, e.g. a ""user data dir"".
    "
name,content
parso,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,davidhalter/parso,Name already in use,parso - A Python Parser,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A Python Parser
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Parso is a Python parser that supports error recovery and round-trip parsing
for different Python versions (in multiple Python versions). Parso is also able
to list multiple syntax errors in your python file.,Parso has been battle-tested by ,. It was pulled out of jedi to be useful
for other projects as well.,Parso consists of a small API to parse Python and analyse the syntax tree.,A simple example:,To list multiple issues:,
      A Python Parser
    "
name,content
nbclassic,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jupyter/nbclassic,Name already in use,The Classic Jupyter Notebook as a Jupyter Server Extension,Read the full ,!,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Jupyter Notebook as a Jupyter Server extension
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,The Jupyter Notebook is ,, but it
will also break backwards compatibility with many classic Jupyter Notebook
extensions and customizations.,NbClassic provides a backwards compatible Jupyter Notebook interface that
you can , with the latest versions: That way, you can
fearlessly upgrade without worrying about your classic extensions and
customizations breaking.,Because NbClassic provides the classic interface on top of the new , backend, it can coexist with other frontends like JupyterLab and
Notebook 7 in the same installation. NbClassic preserves the custom classic
notebook experience under a new set of URL endpoints, under the namespace
,.,Install from PyPI:,This will automatically enable the NbClassic Jupyter Server extension in Jupyter Server.,Launch directly:,Alternatively, you can run Jupyter Server:,
      Jupyter Notebook as a Jupyter Server extension
    "
name,content
nspektr,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jaraco/nspektr,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,nspektr is a distribution package dependency inspector.,It combines functionality from , and ,
to provide routines to resolve and validate dependencies for a package
or entry point.,Highlights:"
name,content
cattrs,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-attrs/cattrs,Name already in use,cattrs,cattrs,attrs,attrs,cattrs,cattrs,cattrs,attrs,cattrs,attrs,attrs,attrs,attrs,attrs,cattrs,cattrs,cattrs,cattrs,cattrs,cattrs,cattrs,cattrs,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Complex custom class converters for attrs.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
, is an open source Python library for structuring and unstructuring
data. , works best with , classes, dataclasses and the usual
Python collections, but other kinds of classes are supported by manually
registering converters.,Python has a rich set of powerful, easy to use, built-in data types like
dictionaries, lists and tuples. These data types are also the lingua franca
of most data serialization libraries, for formats like json, msgpack, cbor,
yaml or toml.,Data types like this, and mappings like , s in particular, represent
unstructured data. Your data is, in all likelihood, structured: not all
combinations of field names or values are valid inputs to your programs. In
Python, structured data is better represented with classes and enumerations.
, is an excellent library for declaratively describing the structure of
your data, and validating it.,When you're handed unstructured data (by your network, file system, database...),
, helps to convert this data into structured data. When you have to
convert your structured data into data types other libraries can handle,
, turns your classes and enumerations into dictionaries, integers and
strings.,Here's a simple taste. The list containing a float, an int and a string
gets converted into a tuple of three ints., works well with , classes out of the box.,Here's a much more complex example, involving , classes with type
metadata.,Consider unstructured data a low-level representation that needs to be converted
to structured data to be handled, and use ,. When you're done,
, the data to its unstructured form and pass it along to another
library or module. Use ,
to add type metadata to attributes, so , will know how to structure and
destructure them.,Converts structured data into unstructured data, recursively:,Converts unstructured data into structured data, recursively, according to
your specification given as a type. The following types are supported:,.,, ,, , (converts to a list)., (both variants, , and ,).,, , (converts to a set)., (converts to a frozenset).,, ,, , (converts to a dict).,., classes with simple attributes and the usual ,.,All , classes and dataclasses with the usual ,, if their complex attributes have type metadata., s of supported , classes, given that all of the classes have a unique field., s of anything, given that you provide a disambiguation function for it.,Custom converters for any type can be registered using ,., comes with preconfigured converters for a number of serialization libraries, including json, msgpack, cbor2, bson, yaml and toml.
For details, see the ,., is based on a few fundamental design decisions.,A foolish consistency is the hobgoblin of little minds so these decisions can and are sometimes broken, but they have proven to be a good foundation.,Major credits to Hynek Schlawack for creating , and its predecessor, ,., is tested with ,, by David R. MacIver., is benchmarked using , and ,.,This package was created with , and the , project template.,
      Complex custom class converters for attrs.
    "
name,content
Django,"
      ,Django,Meet Django,Stay in the loop,Django Links,Django makes it easier to build better web apps more quickly and with less code.,latest release: 4.2.3,The web framework for perfectionists with deadlines.,
    ,
  ,
    ,
  ,
      Django is a high-level Python web framework that encourages rapid development and clean, pragmatic design.
      Built by experienced developers, it takes care of much of the hassle of web development, so you can focus
      on writing your app without needing to reinvent the wheel. It’s free and open source.
    ,Django was designed to help developers take applications from concept to completion as quickly as possible.,Django takes security seriously and helps developers avoid many common security mistakes.,Some of the busiest sites on the web leverage Django’s ability to quickly and flexibly scale.,Subscribe to one of our mailing lists to stay up to date with everything in the Django community:,Get help with Django and follow announcements.,
      You can also subscribe by sending an email to
      , and following the
      instructions that will be sent to you.
    ,Contribute to the development of Django itself.,
      Before asking a question about how to contribute, read
      ,. Many frequently asked questions are answered there.
    ,
      You can also subscribe by sending an email to
      , and following the
      instructions that will be sent to you.
    ,
  We have a few other specialized lists (announce, i18n, ...). You can
  find more information about them in our
  ,.
,The Django Software Foundation’s biggest fundraising event of the year is here!,Django 4.2.3, 4.1.10, and 3.2.20 fix one security issue.,© 2005-2023
        , and individual contributors. Django is a
        , of the Django Software Foundation.
      "
name,content
plaster-pastedeploy,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Pylons/plaster_pastedeploy,Name already in use,plaster_pastedeploy,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A PasteDeploy binding to the plaster configuration loader.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a , plugin that provides a ,
that can parse ini files according to the standard set by ,. It
supports the , plaster protocol, implementing the
, interface.,Applications should use , to load settings from named
sections in a configuration source (usually a file).,Most applications will want to use
, to get this loader. It then
exposes ,, ,, , and
,.,Any , options are forwarded as defaults to the loader.
Some examples are below:,
      A PasteDeploy binding to the plaster configuration loader.
    "
name,content
pooch,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,fatiando/pooch,Name already in use,Does your Python package include sample datasets?
Are you shipping them with the code?
Are they getting too big?,registry,cache,Are you a scientist or researcher? Pooch can help you too!,If you're using Pooch, send us a pull request adding your project to the list.,This disclaimer was adapted from the,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A friend to fetch your data files
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
, •
, •
, •
,
,
Part of the , project
,
,
,
,
,
,
, is here to help! It will manage a data , by downloading your
data files from a server only when needed and storing them locally in a data
, (a folder on your computer).,Here are Pooch's main features:,For a , for analysis:,For , including sample data in their projects:,🗨️ ,
Find out more about how to reach us at
,.,👩🏾‍💻 ,
Please read our
,
to see how you can help and give feedback.,🧑🏾‍🤝‍🧑🏼 ,
This project is released with a
,.
By participating in this project you agree to abide by its terms.,
We want your help. , There may be a little voice inside your
head that is telling you that you're not ready, that you aren't skilled
enough to contribute. We assure you that the little voice in your head is
wrong. Most importantly, ,.,
,.,This is free software: you can redistribute it and/or modify it under the terms
of the ,. A copy of this license is provided in
,.,
      A friend to fetch your data files
    "
name,content
oslo.config,"oslo.config,oslo.config,An OpenStack library for parsing configuration options from the command
line and configuration files.,Read also the ,.,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Docs.openstack.org is powered by
          ,.
        "
name,content
joblib,"Joblib: running Python functions as pipeline jobs,joblib.dump,joblib.load,Joblib is a set of tools to provide ,. In particular:,transparent disk-caching of functions and lazy re-evaluation
(memoize pattern),easy simple parallel computing,Joblib is optimized to be , and , on large
data in particular and has specific optimizations for , arrays. It is
,.,The vision is to provide tools to easily achieve better performance and
reproducibility when working with long running jobs.,: code is often rerun again and
again, for instance when prototyping computational-heavy jobs (as in
scientific development), but hand-crafted solutions to alleviate this
issue are error-prone and often lead to unreproducible results.,: efficiently persisting
arbitrary objects containing large data is hard. Using
joblib’s caching mechanism avoids hand-written persistence and
implicitly links the file on disk to the execution context of
the original Python object. As a result, joblib’s persistence is
good for resuming an application status or computational job, eg
after a crash.,Joblib addresses these problems while , (no framework, no new paradigms)., a memoize or
make-like functionality for Python functions that works well for
arbitrary Python objects, including very large numpy arrays. Separate
persistence and flow-execution logic from domain logic or algorithmic
code by writing the operations as a set of steps with well-defined
inputs and  outputs: Python functions. Joblib can save their
computation to disk and rerun it only if necessary:, to make it easy to write readable
parallel code and debug it quickly:,: a replacement for pickle to work
efficiently on Python objects containing large data (
, & , ).,([location, backend, mmap_mode, ...]),A context object for caching a function's return value each time it is called with the same input arguments.,([n_jobs, backend, return_as, ...]),Helper class for readable parallel mapping.,([backend, n_jobs, verbose, ...]),Set the default backend or configuration for ,.,(value, filename[, compress, protocol, ...]),Persist an arbitrary Python object into one file.,(filename[, mmap_mode]),Reconstruct a Python object from a file persisted with joblib.dump.,(obj[, hash_name, coerce_mmap]),Quick calculation of a hash to identify uniquely Python objects containing numpy arrays.,(compressor_name, compressor),Register a new compressor.,
  ,
"
name,content
print-schema,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,suryashekharc/print_schema,Name already in use,print_schema,display the structure,New:,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Print the schema of Python objects
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Ever had a complex Python object and wanted to easily see its structure?, makes it super easy to , of complex dictionaries, JSONs, lists, etc
It differs from pprint in that this displays the structure rather than the object itself., Use , to display a 2D array (list of lists) in the matrix form.,You can download this package from pip:,New in version 1.1,This project is licensed under the MIT License - see the , file for details,This project started when I started looking for a native Python equivalent of PySpark/Scala's printSchema() and couldn't find any :),Much thanks to my favorite after-hours colleague Puneet Jindal for all the help.,
      Print the schema of Python objects
    "
name,content
charset-normalizer,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Ousret/charset_normalizer,Name already in use,Charset Detection, for Everyone ,restrictive,restrictive,** : They are clearly using specific code for a specific encoding even if covering most of used one,Just print out normalized text,Upgrade your code without effort,Noise :,Coherence :,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Truly universal encoding detector in pure Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
  ,
  ,
  ,
  ,
,A library that helps you read text from an unknown charset encoding., Motivated by ,,
I'm trying to resolve the issue by taking a new approach.
All IANA character set names for which the Python core library provides codecs are supported.,
  >>>>> , <<<<<
,This project offers you an alternative to ,, also known as ,.,
,
,
Did you got there because of the logs? See ,This package offer better performance than its counterpart Chardet. Here are some numbers.,Chardet's performance on larger file (1MB+) are very poor. Expect huge difference on large payload.,Stats are generated using 400+ files using default parameters. More details on used files, see GHA workflows.
And yes, these results might change at any time. The dataset can be updated to include more files.
The actual delays heavily depends on your CPU capabilities. The factors should remain the same.
Keep in mind that the stats are generous and that Chardet accuracy vs our is measured using Chardet initial capability
(eg. Supported Encoding) Challenge-them if you want.,Using pip:,This package comes with a CLI.,🎉 Since version 1.4.0 the CLI produce easily usable stdout result in JSON format.,The above code will behave the same as ,. We ensure that we offer the best (reasonable) BC result possible.,See the docs for advanced usage : ,When I started using Chardet, I noticed that it was not suited to my expectations, and I wanted to propose a
reliable alternative using a completely different method. Also! I never back down on a good challenge!,I , about the , encoding, because , can
produce ,
What I want is to get readable text, the best I can.,In a way, , How cool is that ? ,Don't confuse package , with charset-normalizer or chardet. ftfy goal is to repair unicode string whereas charset-normalizer to convert raw file in unknown encoding to unicode.,, what is noise/mess and coherence according to , I opened hundred of text files, ,, with the wrong encoding table. ,, then
, some ground rules about , when , a mess.
I know that my interpretation of what is noise is probably incomplete, feel free to contribute in order to
improve or rewrite it., For each language there is on earth, we have computed ranked letter appearance occurrences (the best we can). So I thought
that intel is worth something here. So I use those records against decoded text to check if I can detect intelligent design.,Upgrade your Python interpreter as soon as possible.,Contributions, issues and feature requests are very much welcome.,
Feel free to check , if you want to contribute.,Copyright © ,.,
This project is , licensed.,Characters frequencies used in this project © 2012 ,Professional support for charset-normalizer is available as part of the ,. Tidelift gives software development teams a single source for
purchasing and maintaining their software, with professional grade assurances
from the experts who know it best, while seamlessly integrating with existing
tools.,
      Truly universal encoding detector in pure Python
    "
name,content
jedi,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,davidhalter/jedi,Name already in use,Jedi - an awesome autocompletion, static analysis and refactoring library for Python,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Awesome autocompletion, static analysis and refactoring library for python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Jedi is a static analysis tool for Python that is typically used in
IDEs/editors plugins. Jedi has a focus on autocompletion and goto
functionality. Other features include refactoring, code search and finding
references.,Jedi has a simple API to work with. There is a reference implementation as a
,. Autocompletion in your
REPL is also possible, IPython uses it natively and for the CPython REPL you
can install it. Jedi is well tested and bugs should be rare.,Jedi can currently be used with the following editors/projects:,and many more!,There are a few language servers that use Jedi:,Here are some pictures taken from ,:,Completion for almost anything:,Documentation:,Get the latest version from ,
(master branch should always be kind of stable/working).,Docs are available at ,. Pull requests with enhancements
and/or fixes are awesome and most welcome. Jedi uses ,.,If you want to stay , with releases, please , to this
mailing list: ,. To subscribe you can
simply send an empty email to ,.,You can file issues and questions in the issue tracker
<,>. Alternatively you can also ask on
, with
the label ,.,.,Jedi's features are listed here:
,.,You can run Jedi on Python 3.6+ but it should also
understand code that is older than those versions. Additionally you should be
able to use ,
very well.,Tips on how to use Jedi efficiently can be found ,.,You can find a comprehensive documentation for the
,.,There are the following commands:,The returned objects are very powerful and are really all you might need.,Jedi is a dependency of IPython. Autocompletion in IPython with Jedi is
therefore possible without additional configuration.,Here is an , how REPL completion
can look like.
For the , shell you can enable tab completion in a ,.,For a lot of forms of static analysis, you can try to use
,. It will return a list of names that you can
then filter and work with. There is also a way to list the syntax errors in a
file: ,.,Jedi supports the following refactorings:,There is support for module search with ,, and project
search for ,. The way to search is either by providing a
name like , or by using dotted syntax like ,. Additionally you
can provide the API type like ,. There are also the
functions , and ,.,There's a pretty good and extensive ,.,The test suite uses ,:,If you want to test only a specific Python version (e.g. Python 3.8), it is as
easy as:,For more detailed information visit the ,.,Thanks a lot to all the
,!,
      Awesome autocompletion, static analysis and refactoring library for python
    "
name,content
pangocffi,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,leifgehrmann/pangocffi,Name already in use,pangocffi,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        CFFI-based pango bindings for Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,pangocffi is a ,-based set of Python bindings for ,.,pangocffi on its own is not that useful, since it depends on a PangoFontMap
being declared against the PangoContext.
PangoFontMap instances can easily be retrieved from libraries such as
PangoCairo, PangoXft, PangoFT2, and PangoWin32 (See gnome's documentation
, for a list of rendering engines).,See , for bindings that allow you to render pango objects with
cairo.,The bindings are currently not fully implemented. Feel free to make a pull
request to contribute!,See , for information on how to install the necessary libraries.,See , for additional information on all the objects.,If you would like to contribute to this project, either by leaving feedback or
submitting a pull request, please read ','.,
      CFFI-based pango bindings for Python.
    "
name,content
mistune,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,lepture/mistune,Name already in use,Mistune v3,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A fast yet powerful Python Markdown parser with renderers and plugins.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A fast yet powerful Python Markdown parser with renderers and plugins.,
,Looking for old Mistune? Switch branch to:,You can ask me to create a custom mistune plugin or directive for your needs with GitHub sponsor
,.,To install mistune:,Convert Markdown to HTML with ease:,If you found security bugs, please do not send a public issue or patch.
You can send me email at ,. Attachment with patch is welcome.
My PGP Key fingerprint is:,Or, you can use the ,.
Tidelift will coordinate the fix and disclosure.,Here is the benchmark score on my computer. Check the , script.,Mistune is licensed under BSD. Please see LICENSE for licensing details.,
      A fast yet powerful Python Markdown parser with renderers and plugins.
    "
name,content
nvidia-cusolver-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
hyperlink,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-hyper/hyperlink,Name already in use,Hyperlink,Cool URLs that don't change.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        , Immutable, Pythonic, correct URLs.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Hyperlink provides a pure-Python implementation of immutable
URLs. Based on , and ,, the Hyperlink URL
makes working with both URIs and IRIs easy.,Hyperlink is tested against Python 2.7, 3.4, 3.5, 3.6, 3.7, 3.8, and PyPy.,Full documentation is available on ,.,Hyperlink is a pure-Python package and requires nothing but
Python. The easiest way to install is with pip:,Then, hyperlink away!,See the full API docs on ,.,Hyperlink would not have been possible without the help of
, and many other
community members, especially considering that it started as an
extract from the Twisted networking library. Thanks to them,
Hyperlink's URL has been production-grade for well over a decade.,Still, should you encounter any issues, do file an issue, or submit a
pull request.,
      , Immutable, Pythonic, correct URLs.
    "
name,content
html2text,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Alir3z4/html2text,Name already in use,html2text,Originally written by Aaron Swartz. This code is distributed under the GPLv3.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Convert HTML to Markdown-formatted text.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,
,html2text is a Python script that converts a page of HTML into clean, easy-to-read plain ASCII text. Better yet, that ASCII also happens to be valid Markdown (a text-to-HTML format).,Usage: ,For a complete list of options see the ,Or you can use it from within ,:,Or with some configuration options:, is available on pypi
,To see the coverage results:,then open the , file in your browser.,Documentation lives ,
      Convert HTML to Markdown-formatted text.
    "
name,content
argcomplete,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,kislyuk/argcomplete,Name already in use,argcomplete - Bash/zsh tab completion for argparse,Tab complete all the things!,parser,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python and tab completion, better together.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Argcomplete provides easy, extensible command line tab completion of arguments for your Python application.,It makes two assumptions:,Argcomplete is particularly useful if your program has lots of options or subparsers, and if your program can
dynamically suggest completions for your argument/option values (for example, if the user is browsing resources over
the network).,See , below for details about the second step.,Refresh your shell environment (start a new shell).,Add the , marker and a call to , to your Python application as
follows:,Register your Python application with your shell's completion framework by running ,:,Quotes are significant; the registration will fail without them. See , below for a way to enable
argcomplete generally without registering each application individually.,This method is the entry point to the module. It must be called , ArgumentParser construction is complete, but
, the , method is called. The method looks for an environment variable that the
completion hook shellcode sets, and if it's there, collects completions, prints them to the output stream (fd 8 by
default), and exits. Otherwise, it returns to the caller immediately.,Side effects,Argcomplete gets completions by running your program. It intercepts the execution flow at the moment
, is called. After sending completions, it exits using , (,
by default). This means if your program has any side effects that happen before , is called, those
side effects will happen every time the user presses , (although anything your program prints to stdout or
stderr will be suppressed). For this reason it's best to construct the argument parser and call
, as early as possible in your execution flow.,Performance,If the program takes a long time to get to the point where , is called, the tab completion
process will feel sluggish, and the user may lose confidence in it. So it's also important to minimize the startup time
of the program up to that point (for example, by deferring initialization or importing of large modules until after
parsing options).,You can specify custom completion functions for your options and arguments. Two styles are supported: callable and
readline-style. Callable completers are simpler. They are called with the following keyword arguments:,Completers can return their completions as an iterable of strings or a mapping (dict) of strings to their
descriptions (zsh will display the descriptions as context help alongside completions). An example completer for names
of environment variables might look like this:,To specify a completer for an argument or option, set the , attribute of its associated action. An easy
way to do this at definition time is:,If you specify the , keyword for an argparse option or argument (and don't specify a completer), it will be
used for completions.,A completer that is initialized with a set of all possible choices of values for its action might look like this:,The following two ways to specify a static set of choices are equivalent for completion purposes:,Note that if you use the , option, argparse will show
all these choices in the , output by default. To prevent this, set
, (like ,).,The following , uses
, and , to query GitHub for publicly known members of an
organization and complete their names, then prints the member description:, like this:,If you have a useful completer to add to the ,, send a pull request!,The , module defines a completer protocol in ,. Readline-style completers are also supported by
argcomplete, so you can use the same completer object both in an interactive readline-powered shell and on the command
line. For example, you can use the readline-style completer provided by , to get introspective completions like
you would get in the IPython shell:, can also be used to plug in an argparse parser as a readline completer.,Normal stdout/stderr output is suspended when argcomplete runs. Sometimes, though, when the user presses ,, it's
appropriate to print information about why completions generation failed. To do this, use ,:,By default, argcomplete validates your completions by checking if they start with the prefix given to the completer. You
can override this validation check by supplying the , keyword to ,:,In global completion mode, you don't have to register each argcomplete-capable executable separately. Instead, the shell
will look for the string , in the first 1024 bytes of any executable that it's running
completion for, and if it's found, follow the rest of the argcomplete protocol as described above.,Additionally, completion is activated for scripts run as , and ,. If you're using
multiple Python versions on the same system, the version being used to run the script must have argcomplete installed.,Bash version compatibility,When using bash, global completion requires bash support for ,, which was introduced in bash 4.2. Since
Mac OS ships with an outdated version of Bash (3.2), you can either use zsh or install a newer version of bash using
, (, - you will also need to add , to
,, and run , to change your shell). You can check the version of the running copy of bash with
,.,Note,If you use setuptools/distribute , or , directives to package your module,
argcomplete will follow the wrapper scripts to their destination and look for , in the
destination code.,If you choose not to use global completion, or ship a completion module that depends on argcomplete, you must register
your script explicitly using ,. Standard completion module
registration rules apply: namely, the script name is passed directly to ,, meaning it is only tab completed
when invoked exactly as it was registered. In the above example, , must be on the path, and the user
must be attempting to complete it by that name. The above line alone would , allow you to complete
,, or ,.,The script , installs the global completion script
,
into an appropriate location on your system for both bash and zsh. The specific location depends on your platform and
whether you installed argcomplete system-wide using , or locally (into your user's home directory).,Argcomplete supports zsh. On top of plain completions like in bash, zsh allows you to see argparse help strings as
completion descriptions. All shellcode included with argcomplete is compatible with both bash and zsh, so the same
completer commands , and ,
work for zsh as well.,Argcomplete requires Python 3.7+.,Argcomplete maintainers provide support only for the bash and zsh shells on Linux and MacOS. For resources related to
other shells and platforms, including fish, tcsh, xonsh, powershell, and Windows, please see the
, directory.,If global completion is not completing your script, bash may have registered a default completion function:,You can fix this by restarting your shell, or by running ,.,Set the , variable in your shell to enable verbose debug output every time argcomplete runs. This will
disrupt the command line composition state of your terminal, but make it possible to see the internal state of the
completer if it encounters problems.,Inspired and informed by the , module by Martin Blais.,Please report bugs, issues, feature requests, etc. on ,.,Copyright 2012-2023, Andrey Kislyuk and argcomplete contributors. Licensed under the terms of the
,. Distribution of the LICENSE and NOTICE
files with source copies of this package and derivative works is , as specified by the Apache License.,
      Python and tab completion, better together.
    "
name,content
APScheduler,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,agronholm/apscheduler,Name already in use,triggers,combining triggers,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Task scheduling library for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Warning,The v4.0 series is provided as a , and may change in a
backwards incompatible fashion without any migration pathway, so do NOT use this
release in production!,Advanced Python Scheduler (APScheduler) is a task scheduler and task queue system for
Python. It can be used solely as a job queuing system if you have no need for task
scheduling. It scales both up and down, and is suitable for both trivial, single-process
use cases as well as large deployments spanning multiple nodes. Multiple schedulers and
workers can be deployed to use a shared data store to provide both a degree of high
availability and horizontal scaling.,APScheduler comes in both synchronous and asynchronous flavors, making it a good fit for
both traditional, thread-based applications, and asynchronous (asyncio or ,)
applications. Documentation and examples are provided for integrating with either ,
or , compatible web applications.,Support is provided for persistent storage of schedules and jobs. This means that they
can be shared among multiple scheduler/worker instances and will survive process and
node restarts.,The built-in persistent data store back-ends are:,The built-in event brokers (needed in scenarios with multiple schedulers and/or
workers):,The built-in scheduling mechanisms (,) are:,Different scheduling mechanisms can even be combined with so-called ,
(see the , for details).,You can also implement your custom scheduling logic by building your own trigger class.
These will be treated no differently than the built-in ones.,Other notable features include:,Documentation can be found
,.,The source can be browsed at ,.,A , is provided by
GitHub.,If you have problems or other questions, you can either:,
      Task scheduling library for Python
    "
name,content
itemadapter,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,scrapy/itemadapter,Name already in use,itemadapter,class ,class method ,class method ,class method ,method ,method ,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Common interface for data container classes
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,The , class is a wrapper for data container objects, providing a
common interface to handle objects of different types in an uniform manner,
regardless of their underlying implementation.,Currently supported types are:,Additionally, interaction with arbitrary types is supported, by implementing
a pre-defined interface (see ,)., is available on ,, it can be installed with ,:, is distributed under a , license.,The following is a simple example using a , object.
Consider the following type definition:,An , object can be treated much like a dictionary:,The wrapped object is modified in-place:,The , class provides the , method, which converts
nested items recursively. Consider the following example:,Note that just passing an adapter object to the , built-in also works,
but it doesn't traverse the object recursively converting nested items:,The following adapters are included by default:,This is the main entrypoint for the package. Tipically, user code
wraps an item using this class, and proceeds to handle it with the provided interface.
, implements the
,
interface, providing a ,-like API to manipulate data for the object it wraps
(which is modified in-place).,Stores the currently registered adapter classes.,The order in which the adapters are registered is important. When an , object is
created for a specific item, the registered adapters are traversed in order and the first
adapter class to return , for the , class method is used for all subsequent
operations. The default order is the one defined in the
, section.,The default implementation uses a
,
to support efficient addition/deletion of adapters classes to both ends, but if you are
deriving a subclass (see the section on ,
for additional information), any other iterable (e.g. ,, ,) will work.,Return , if any of the registed adapters can handle the item
(i.e. if any of them returns , for its , method with
, as argument), , otherwise.,Return , if any of the registered adapters can handle the item class
(i.e. if any of them returns , for its , method with
, as argument), , otherwise.,Return a ,
object, which is a read-only mapping with metadata about the given field. If the item class does not
support field metadata, or there is no metadata for the given field, an empty object is returned.,The returned value is taken from the following sources, depending on the item type:,Return a list with the names of all the fields defined for the item class.
If an item class doesn't support defining fields upfront, None is returned.,Return metadata for the given field, if available. Unless overriden in a custom adapter class, by default
this method calls the adapter's , method, passing the wrapped item's class.,Return a ,
with the names of all the defined fields for the item.,Return a , object with the contents of the adapter. This works slightly different than
calling ,, because it's applied recursively to nested items (if there are any).,Return , if the given object belongs to (at least) one of the supported types,
, otherwise. This is an alias, using the ,
class method is encouraged for better performance.,Alias for ,, ,, ,, and , objects allow the definition of
arbitrary field metadata. This can be accessed through a
,
object, which can be retrieved from an item instance with
,, or from an item class
with the ,
method (or its alias ,).
The source of the data depends on the underlying type (see the docs for
,).,This package allows to handle arbitrary item classes, by implementing an adapter interface:,Abstract Base Class for adapters. An adapter that handles a specific type of item must
inherit from this class and implement the abstract methods defined on it. ,
inherits from ,,
so all methods from the , interface must be implemented as well.,Return , if the adapter can handle the given item class, , otherwise. Abstract (mandatory).,Return , if the adapter can handle the given item, , otherwise.
The default implementation calls ,.,Return metadata for the given item class and field name, if available.
By default, this method returns an empty , object. Please supply your
own method definition if you want to handle field metadata based on custom logic.
See the , for additional information.,Return metadata for the given field name, if available. It's usually not necessary to
override this method, since the , base class
provides a default implementation that calls ,
with the wrapped item's class as argument.
See the , for additional information.,:,Return a ,
of the item's field names. By default, this method returns the result of calling , on
the current adapter, i.e., its return value depends on the implementation of the methods from the
, interface (more specifically, it depends on the return value of ,).,You might want to override this method if you want a way to get all fields for an item, whether or not
they are populated. For instance, Scrapy uses this method to define column names when exporting items to CSV.,Add your custom adapter class to the ,
class attribute in order to handle custom item classes:,If you need to have different handlers and/or priorities for different cases
you can subclass the , class and set the ,
attribute as needed:,See the ,
      Common interface for data container classes
    "
name,content
jsonpointer,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,stefankoegl/python-json-pointer,Name already in use,python-json-pointer,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Resolve JSON Pointers in Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,Library to resolve JSON Pointers according to
,See source code for examples,
      Resolve JSON Pointers in Python
    "
name,content
persistent,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,zopefoundation/persistent,Name already in use,:  automatic persistence for Python objects,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        automatic persistence for Python objects
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This package contains a generic persistence implementation for Python. It
forms the core protocol for making objects interact ""transparently"" with
a database such as the ZODB.,Please see the Sphinx documentation (,) for further
information, or view the documentation at Read The Docs, for either
the latest (,) or stable
release (,).,Note,Use of this standalone , release is not recommended or
supported with ZODB < 3.11.  ZODB 3.10 and earlier bundle their own
version of  the , package.,
      automatic persistence for Python objects
    "
name,content
h2,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-hyper/h2,Name already in use,h2: HTTP/2 Protocol Stack,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        HTTP/2 State-Machine based protocol implementation
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This repository contains a pure-Python implementation of a HTTP/2 protocol
stack. It's written from the ground up to be embeddable in whatever program you
choose to use, ensuring that you can speak HTTP/2 regardless of your
programming paradigm.,You use it like this:,This repository does not provide a parsing layer, a network layer, or any rules
about concurrency. Instead, it's a purely in-memory solution, defined in terms
of data actions and HTTP/2 frames. This is one building block of a full Python
HTTP implementation.,To install it, just run:,Documentation is available at , ., welcomes contributions from anyone! Unlike many other projects we
are happy to accept cosmetic contributions and small contributions, in addition
to large feature requests and changes.,Before you contribute (either by opening an issue or filing a pull request),
please ,., is made available under the MIT License. For more details, see the
, file in the repository., was authored by Cory Benfield and is maintained
by the members of ,.,
      HTTP/2 State-Machine based protocol implementation
    "
name,content
btrfsutil,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,kdave/btrfs-progs,Name already in use,
Btrfs-progs,btrfs-progs: subpart, ...,why,how,what,how,usecase,Author:,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Development of userspace BTRFS tools
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Userspace utilities to manage btrfs filesystems.
License: GPLv2.,Btrfs is a copy on write (COW) filesystem for Linux aimed at implementing
advanced features while focusing on fault tolerance, repair and easy
administration.,This repository hosts following utilities and also documentation:,See , for build instructions, , for
testing information and , for CI information.,The major version releases are time-based and follow the cycle of the linux
kernel releases. The cycle usually takes 2 months. A minor version releases may
happen in the meantime if there are bug fixes or minor useful improvements
queued.,The release tags are signed with a GPG key ID ,,
release tarballs are hosted at ,.
See file , or ,.,There are several ways, each has its own specifics and audience that can give
feedback or work on a fix. The following list is sorted in the order of
preference:,The development takes place in the mailing list (,)
or at github (issues, pull requests). Changes should be split to logical parts
if possible, documentation may be included in the same patch as to code or
separately.,The development model of btrfs-progs shares a lot with the kernel model. The,Source code coding style and preferences follow the
,.
You can find the editor settings in , and use the
, plugin to let your editor use that,
or update your editor settings manually.,The testing documentation can be found in , and
continuous integration/container images in ,.,Documentation fixes or updates do not need much explanation so sticking to the
code rules in the previous section is not necessary. GitHub pull requests are
OK, patches could be sent to me directly and not required to be also in the
mailinglist. Pointing out typos via IRC also works, although might get
accidentally lost in the noise.,Documentation sources are written in
, and built by sphinx.,Build dependencies are listed in ,. Implementation of checksum/hash
functions is provided by copies of the respective sources to avoid adding
dependencies that would make deployments in rescue or limited environments
harder. The implementations are portable and there are optimized versions for
some architectures.  Optionally it's possible to use libgcrypt, libsodium or
libkcapi implementations.,Some other code is borrowed from kernel, eg. the raid5 tables or data structure
implementation (list, rb-tree).,
      Development of userspace BTRFS tools
    "
name,content
passwordgenerator,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,gabfl/password-generator-py,Name already in use,password-generator-py,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Passwords easy for humans, hard for computers
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,A lot of people with security in mind will use random characters as passwords like ,.
, because it's complicated. But the password above is as difficult as , for a machine to brute force even though it's a lot easier for a user to remember.,This program attempts to create passwords truly difficult for a computer to brute force and easier to remember for a user.,Here are a few passwords that can be generated:,
      Passwords easy for humans, hard for computers
    "
name,content
mrtoolstheme,"
pyl_mrtoolstheme
,

,Sphinx HTML theme, based on the Nord theme."
name,content
jmespath,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jmespath/jmespath.py,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        JMESPath is a query language for JSON.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,JMESPath (pronounced ""james path"") allows you to declaratively specify how to
extract elements from a JSON document.,For example, given this document:,The jmespath expression , will return ""baz"".,JMESPath also supports:,Referencing elements in a list.  Given the data:,The expression: , will return ""one"".
You can also reference all the items in a list using the ,
syntax:,The expression: , will return [""one"", ""two""].
Negative indexing is also supported (-1 refers to the last element
in the list).  Given the data above, the expression
, will return ""two"".,The , can also be used for hash types:,The expression: , will return [""one"", ""two""].,You can install JMESPath from pypi with:,The , library has two functions
that operate on python data structures.  You can use ,
and give it the jmespath expression and the data:,Similar to the , module, you can use the , function
to compile the JMESPath expression and use this parsed expression
to perform repeated searches:,This is useful if you're going to use the same jmespath expression to
search multiple documents.  This avoids having to reparse the
JMESPath expression each time you search a new document.,You can provide an instance of , to control how
a JMESPath expression is evaluated.  The most common scenario for
using an , instance is if you want to have ordered output
of your dict keys.  To do this you can use either of these options:,The JMESPath language has numerous
,, but it is
also possible to add your own custom functions.  Keep in mind that
custom function support in jmespath.py is experimental and the API may
change based on feedback.,
You can submit proposals
,.,To create custom functions:,Below are a few examples:,Again, if you come up with useful functions that you think make
sense in the JMESPath language (and make sense to implement in all
JMESPath libraries, not just python), please let us know at
,.,If you'd like to learn more about the JMESPath language, you can check out
the ,.  Also check
out the , for
examples of more complex jmespath queries.,The grammar is specified using ABNF, as described in
,.
You can find the most up to date
,.,You can read the full
,.,In addition to the unit tests for the jmespath modules,
there is a , directory that contains
.json files with test cases.  This allows other implementations
to verify they are producing the correct output.  Each json
file is grouped by feature.,Join us on our ,
if you want to chat or if you have any questions.,
      JMESPath is a query language for JSON.
    "
name,content
async-generator,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-trio/async_generator,Name already in use,easy,right,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Making it easy to write async iterators in Python 3.5
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Python 3.6 added ,. (What's an async
generator? ,.) Python 3.7 adds some more
tools to make them usable, like ,.,This library gives you all that back to Python 3.5.,For example, this code only works in Python 3.6+:,But this code does the same thing, and works on Python 3.5+:,Or in Python 3.7, you can write:,This is the same, but back to 3.5:,(And if you're on 3.6, you can use , with
native generators.), is a new async concurrency
library for Python that's obsessed with usability and correctness – we
want to make it , to get things ,. The ,
library is maintained by the Trio project as part of that mission, and
because Trio uses , internally.,You can use , with any async library. It works great
with ,, or Twisted, or whatever you like. (But we think Trio
is pretty sweet.),
      Making it easy to write async iterators in Python 3.5
    "
name,content
nanoid,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,puyuan/py-nanoid,Name already in use,Nano ID,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python Nanoid
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A tiny, secure, URL-friendly, unique string ID generator for Python.,The main module uses URL-friendly symbols (A-Za-z0-9_-) and returns an ID with 21 characters (to have a collision probability similar to UUID v4).,Symbols , are not encoded in the URL. If used at the end of a link they could be identified as a punctuation symbol.,If you want to reduce ID length (and increase collisions probability), you can pass the length as an argument.,Don’t forget to check the safety of your ID length in ID ,.,If you want to change the ID's alphabet or length you can use the internal generate module.,Non-secure API is also available:,
      Python Nanoid
    "
name,content
fluidity-sm,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,nsi-iff/fluidity,Name already in use,Fluidity,from_,to,action,from_,to,event,action,guard,action,action,guard,guard,fluidity-sm,fluidity,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        State machine implementation for Python objects
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,State machine implementation for Python objects.,A very simple example taken from specs:,For demonstrating more advanced capabilities, a ""slightly more complex example"" from ,, the Ruby's most popular state machine implementation, is reproduced below, using Fluidity:,A Fluidity state machine must have one initial state and at least two states.,A state may have enter and exit callbacks, for running some code on state enter
and exit, respectively. These params can be method names (as strings),
callables, or lists of method names or callables.,Transitions lead the machine from a state to another. Transitions must have
,, ,, and , parameters. , is one or more (as list) states
from which the transition can be started. , is the state to which the
transition will lead the machine. , is the method that have to be called
to launch the transition. This method is automatically created by the Fluidity
engine.,A transition can have optional , and , parameters. , is a
method (or callable) that will be called when transition is launched. If
parameters are passed to the event method, they are passed to the ,
method, if it accepts these parameters. , is a method (or callable) that
is called to allow or deny the transition, depending on the result of its
execution. Both ""action"" and , can be lists.,The same event can be in multiple transitions, going to different states, having
their respective guards as selectors. For the transitions having the same event,
only one guard should return a true value at a time.,States and transitions are defined in a class-wide mode. However, one can define
states and transitions for individual objects. For example, having ""door"" as a
state machine:,These additions only affect the target object.,Just run:,: the Pypi package is called ,, not ,.,Just run:,for install all test dependencies (,
and ,, at the moment) and
run the tests. Fluidity itself has no dependencies.,
      State machine implementation for Python objects
    "
name,content
poe-api,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,ading2210/poe-api,Name already in use,Python Poe API,Table of contents generated with ,.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A reverse engineered Python API wrapper for Quora's Poe, which provides free access to ChatGPT, GPT-4, and Claude.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This is a reverse engineered API wrapper for Quora's Poe, which allows you free access to OpenAI's ChatGPT and GPT-4, as well as Anthropic's Claude.,You can install this library by running the following command:,This library depends on ,, which does not have prebuilt binaries available for Python 3.11. Pip will attempt to compile it, but will fail if , is not installed.,On Linux, you can install it via the instructions listed here: ,On Windows and MacOS, , should be included with your existing Python installation.,Examples can be found in the , directory. To run these examples, pass in your token as a command-line argument.,Log into , on any desktop web browser, then open your browser's developer tools (also known as ""inspect"") and look for the value of the , cookie in the following menus:,Note that excessive usage of this library may lead to your account getting banned. It is recommended that you set your own rate limits, and that you use an alt account that you don't value. See , for more details. If your requests are infrequent, the risk for a ban is very low.,To use this library, simply import , and create a , instance. The Client class accepts the following arguments:,Regular Example:,Proxied Example:,Note that the following examples assume , is the name of your , instance. If the token is invalid, a RuntimeError will be raised.,The client downloads all of the available bots upon initialization and stores them within ,. A dictionary that maps bot codenames to their display names can be found at ,. If you want to refresh these values, you can call ,. This function takes the following arguments:,Note that, on free accounts, Claude+ (a2_2) has a limit of 3 messages per day and GPT-4 (beaver) has a limit of 1 message per day. Claude-instant-100k (c2_100k) is completely inaccessible for free accounts. For all the other chatbots, there seems to be a rate limit of 10 messages per minute.,To get a list of 3rd party bots, use ,, which accepts the following arguments:,The function will return a dict containing a list of bots and the cursor for the next page:,To get a specific third party bot, you can use ,, which accept's the bot's codename as its only argument.,Since display names are the same as the codenames for custom bots, you can simply pass the bot's display name into , to send it a message.,You can create a new bot using the , function, which accepts the following arguments:,Use these arguments if you want the new bot to use your own API (as detailed ,):,A full example of how to create and edit bots is located at ,.,You can edit a custom bot using the , function, which accepts the following arguments:,Bot API related arguments:,A full example of how to create and edit bots is located at ,.,You can use the , function to send a message to a chatbot, which accepts the following arguments:,The function is a generator which returns the most recent version of the generated message whenever it is updated.,Streamed Example:,Non-Streamed Example:,You can also send multiple messages in parallel using , and receive their responses separately, as demonstrated in ,. Note that if you send messages too fast, the server will give an error, but the request will eventually succeed.,If you want to clear the the context of a conversation without sending a message, you can use ,. The only argument is the codename of the bot whose context will be cleared.,The function returns the message which represents the chat break.,To download past messages in a conversation, use the , function, which accepts the following arguments:,Note that if you don't specify a cursor, the client will have to perform an extra request to determine what the latest cursor is.,The returned messages are ordered from oldest to newest.,To delete messages, use the , function, which accepts a single argument. You can pass a single message ID into it to delete a single message, or you can pass a list of message IDs to delete multiple messages at once.,To purge an entire conversation, or just the last few messages, you can use the , function. This function accepts the following arguments:,To purge every conversation in your account, use the , function. This function doesn't need any arguments.,To get the number of messages remaining in the quota for a conversation, use the , function. This function accepts the following arguments:,The function will return the number of messages remaining, or , if the bot does not have a quota.,If you want to show debug messages, simply call ,.,If you want to change the headers that are spoofed, set , after importing the library.,To use your browser's own headers, visit ,, and copy-paste its contents.,The following headers will be ignored and overwritten:,Previously, this was done through ,, but that variable is now completely ignored.,You'd also want to change , to match the user-agent that you have set. See the , for some sample values. Keep in mind that spoofing Chrome/Firefox versions >= 110 may be detectable.,If you want to change the device ID that is being spoofed, you can use the ,, which accepts the following arguments:,The device IDs are saved to , on Unix-like systems, and , on Windows.,Additionally, the , function or , can be used to retrieve the saved device ID.,This program is licensed under the ,. Most code, with the exception of the GraphQL queries, has been written by me, ,.,Reverse engineering the , header has been done by , in ,.,The , function was written by , in ,.,Detection avoidance and fetching the third party bots has been done by , in ,.,Most of the GraphQL queries are taken from ,, which is licensed under the ISC License.,
      A reverse engineered Python API wrapper for Quora's Poe, which provides free access to ChatGPT, GPT-4, and Claude.
    "
name,content
gunicorn,"Gunicorn 'Green Unicorn' is a Python WSGI HTTP Server for UNIX. It's a pre-fork worker model. The Gunicorn server is broadly compatible with various web frameworks, simply implemented, light on server resources, and fairly speedy.,Installation,Deployment,Project Management,IRC,Issue Tracking,Security Issues,Documentation,Read the quickstart guide to get started using Gunicorn.,Learn how to deploy the Gunicorn server.,Get in touch with the community.,Read the documentation to learn more about Gunicorn.,
          Here's a quick rundown on how to get started with Gunicorn. For more details read the ,.
        ,
          Gunicorn is a WSGI HTTP server. It is best to use Gunicorn behind an HTTP proxy server. We strongly advise you to use ,.
        ,Here's an example to help you get started with using nginx:,Nginx is set up as reverse proxy server to a Gunicorn server running on localhost port 8000.,Read the full documentation at , uses ,. GitHub issues are used for 3 different purposes:,Project maintenance guidelines are available on the ,The Gunicorn channel is on the , IRC
          network. You can chat with the community on the ,.,Bug reports, enhancement requests and tasks generally go in the ,.,The security mailing list is a place to report security issues. Only
        developers are subscribed to it. To post a message to the list use the
        address ,You can read more comprehensive documentation at ,.,The contents are:"
name,content
imageio-ffmpeg,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,imageio/imageio-ffmpeg,Name already in use,imageio-ffmpeg,much,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        FFMPEG wrapper for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,FFMPEG wrapper for Python,The purpose of this project is to provide a simple and reliable ffmpeg
wrapper for working with video files. It implements two simple generator
functions for reading and writing data from/to ffmpeg, which reliably
terminate the ffmpeg process when done. It also takes care of publishing
platform-specific wheels that include the binary ffmpeg executables.,This library is used as the basis for the
,
,,
but it can also be used by itself. Imageio provides a higher level API,
and adds support for e.g. cameras and seeking.,This library works with any version of Python 3.5+ (including Pypy).
There are no further dependencies. The wheels on Pypi include the ffmpeg
executable for all common platforms (Windows 7+, Linux kernel 2.6.32+,
OSX 10.9+). Install using:,(On Linux you may want to first ,, since pip 19 is needed to detect the , wheels.),If you're using a Conda environment: the conda package does not include
the ffmpeg executable, but instead depends on the , package from
,. Install using:,If you don't want to install the included ffmpeg, you can use pip with
, or conda with ,. Then use the
, environment variable if needed.,The , library provides low level functionality to read
and write video data, using Python generators:,(Also see the API section further down.),This library calls ffmpeg in a subprocess, and video frames are
communicated over pipes. This is certainly not the fastest way to
use ffmpeg, but it makes it possible to wrap ffmpeg with pure Python,
making distribution and installation , easier. And probably
the code itself too. In contrast, ,
wraps ffmpeg at the C level.,Note that because of how , works, , and
, only accept file names, and not file (like) objects.,Available as part of the Tidelift Subscription,The maintainers of imageio-ffmpeg and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. ,To report a security vulnerability, please use the
,.
Tidelift will coordinate the fix and disclosure.,The library can be configured at runtime by setting the following environment
variables:,Dev deps:,We use invoke:,
      FFMPEG wrapper for Python
    "
name,content
certifi,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,certifi/python-certifi,Name already in use,Certifi: Python SSL Certificates,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        (Python Distribution) A carefully curated collection of Root Certificates for validating the trustworthiness of SSL certificates while verifying the identity of TLS hosts.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Certifi provides Mozilla's carefully curated collection of Root Certificates for
validating the trustworthiness of SSL certificates while verifying the identity
of TLS hosts. It has been extracted from the , project., is available on PyPI. Simply install it with ,:,To reference the installed certificate authority (CA) bundle, you can use the
built-in function:,Or from the command line:,Enjoy!,Certifi does not support any addition/removal or other modification of the
CA trust store content. This project is intended to provide a reliable and
highly portable root of trust to python deployments. Look to upstream projects
for methods to use alternate trust.,
      (Python Distribution) A carefully curated collection of Root Certificates for validating the trustworthiness of SSL certificates while verifying the identity of TLS hosts.
    "
name,content
incremental,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,twisted/incremental,Name already in use,Incremental,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A library for versioning your Python projects.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,

,

,Incremental is a small library that versions your Python projects.,API documentation can be found ,.,Add this to your ,'s , call, removing any other versioning arguments:,Install Incremental to your local environment with ,.
Then run ,.
It will create a file in your package named , and look like this:,Then, so users of your project can find your version, in your root package's , add:,Subsequent installations of your project will then use Incremental for versioning., is a class that represents a version of a given project.
It is made up of the following elements (which are given during instantiation):,You can extract a PEP-440 compatible version string by using the , method, which returns a , containing the full version. This is the version you should provide to users, or publicly use. An example output would be ,, ,, or ,.,Calling , with a , will give a Python-source-code representation of it, and calling , with a , will provide a string similar to ,.,Incremental includes a tool to automate updating your Incremental-using project's version called ,.
It updates the , file and automatically updates some uses of Incremental versions from an indeterminate version to the current one.
It requires , from PyPI., will perform updates on that package.
The commands that can be given after that will determine what the next version is.,If you give no arguments, it will strip the release candidate number, making it a ""full release"".,Incremental supports ""indeterminate"" versions, as a stand-in for the next ""full"" version. This can be used when the version which will be displayed to the end-user is unknown (for example ""introduced in"" or ""deprecated in""). Incremental supports the following indeterminate versions:,When you run ,, these will be updated to real versions (assuming the target final version is 17.1.0):,Once the final version is made, it will become:,
      A library for versioning your Python projects.
    "
name,content
bottle,"Bottle: Python Web Framework,NOT,Bottle is a fast, simple and lightweight , micro web-framework for ,. It is distributed as a single file module and has no dependencies other than the ,.,Example: “Hello World” in a bottle,Run this script or paste it into a Python console, then point your browser to ,. That’s it.,Download and Install,Install the latest stable release with , or download , (unstable) into your project directory. There are no hard , dependencies other than the Python standard library. Bottle supports ,.,Support for Python 2.5 and 2.6 was dropped with this release.,Start here if you want to learn how to use the bottle framework for web development. If you have any questions not answered here, feel free to ask the ,.,A collection of articles, guides and HOWTOs.,These chapters are intended for developers interested in the bottle development and release workflow.,Code and documentation are available according to the MIT License:,The Bottle logo however is , covered by that license. It is allowed to
use the logo as a link to the bottle homepage or in direct context with
the unmodified library. In all other cases please ask first.,Footnotes,
   Bottle is a fast, simple and lightweight WSGI micro web-framework for Python.
,Install Bottle with , or download the source package at ,., This is a preview for ,, which is
    not released yet. Switch to the latest ,?,Download this documentation as , or , for offline use."
name,content
cached-property,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pydanny/cached-property,Name already in use,cached-property,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A decorator for caching properties in classes.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,A decorator for caching properties in classes.,Let's define a class with an expensive property. Every time you stay there the
price goes up by $50!,Now run it:,Let's convert the boardwalk property into a ,.,Now when we run it the price stays at $550.,Why doesn't the value of , change? Because it's a ,!,Results of cached functions can be invalidated by outside forces. Let's demonstrate how to force the cache to invalidate:,What if a whole bunch of people want to stay at Boardwalk all at once? This means using threads, which
unfortunately causes problems with the standard ,. In this case, switch to using the
,:,Now use it:,The cached property can be async, in which case you have to use await
as usual to get the value. Because of the caching, the value is only
computed once and then cached:,Now use it:,Note that this does not work with threading either, most asyncio
objects are not thread-safe. And if you run separate event loops in
each thread, the cached version will most likely have the wrong event
loop. To summarize, either use cooperative multitasking (event loop)
or threading, but not both at the same time.,Sometimes you want the price of things to reset after a time. Use the ,
versions of , and ,.,Now use it:, The , tools do not reliably allow the clearing of the cache. This
is why they are broken out into seperate tools. See ,.,
      A decorator for caching properties in classes.
    "
name,content
livereload,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,lepture/python-livereload,Name already in use,LiveReload,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        livereload server in python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Reload webpages on changes, without hitting refresh in your browser.,LiveReload is for web developers who know Python. It is available on ,.,.,To report a security vulnerability, please use the ,.
Tidelift will coordinate the fix and disclosure.,
      livereload server in python
    "
name,content
littleutils,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,alexmojaki/littleutils,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Small personal collection of python utility functions, partly just for fun.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
      Small personal collection of python utility functions, partly just for fun.
    "
name,content
pep517,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pypa/pyproject-hooks,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A low-level library for calling build-backends in `pyproject.toml`-based project
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This is a low-level library for calling build-backends in ,-based project. It provides the basic functionality to help write tooling that generates distribution files from Python projects.,If you want a tool that builds Python packages, you'll want to use , instead. This is an underlying piece for pip, build and other ""build frontends"" use to call ""build backends"" within them.,You can read more in the ,.,
      A low-level library for calling build-backends in `pyproject.toml`-based project
    "
name,content
flake8,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,PyCQA/flake8,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        flake8 is a python tool that glues together pycodestyle, pyflakes, mccabe, and third-party plugins to check the style and quality of some python code.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Flake8 is a wrapper around these tools:,Flake8 runs all the tools by launching the single , command.
It displays the warnings in a per-file, merged output.,It also adds a few features:,files that contain this line are skipped:,lines that contain a , comment at the end will not issue warnings.,you can ignore specific errors on a line with ,, e.g.,
,. Multiple codes can be given, separated by comma. The , token is case insensitive, the colon before the list of codes is required otherwise the part after , is ignored,Git and Mercurial hooks,extendable through , and , entry
points,See our , for how to install
and get started with Flake8.,Flake8 maintains an , in its
documentation.,If you have questions you'd like to ask the developers, or feedback you'd like
to provide, feel free to use the mailing list: ,We would love to hear from you. Additionally, if you have a feature you'd like
to suggest, the mailing list would be the best place for it.,Flake8 was created by Tarek Ziadé and is currently maintained by , and ,
      flake8 is a python tool that glues together pycodestyle, pyflakes, mccabe, and third-party plugins to check the style and quality of some python code.
    "
name,content
procrastinate,"Procrastinate: PostgreSQL-based Task Queue for Python,Note to my future self: add a quick note here on why this project is named,Procrastinate is an open-source Python 3.7+ distributed task processing
library, leveraging PostgreSQL to store task definitions, manage locks and
dispatch tasks. It can be used within both sync and async code.,In other words, from your main code, you call specific functions (tasks) in a
special way and instead of being run on the spot, they’re scheduled to
be run elsewhere, now or in the future.,Here’s an example:,The worker will run the job, which will create a text file
named , with the result of the sum , (that’s ,).,Similarly, from the command line:,Lastly, you can use Procrastinate asynchronously too:,There are quite a few interesting features that Procrastinate adds to the mix.
You can head to the Quickstart section for a general tour or
to the How-To sections for specific features. The Discussion
section should hopefully answer your questions. Otherwise,
feel free to open an ,.,The project is still quite early-stage and will probably evolve.,
“,”.,Python/PostgreSQL task processing library,
,
,
,
"
name,content
lxml,"lxml - XML and HTML with Python,Introduction,Support the project,Documentation,Download,Mailing list,Bug tracker,License,Old Versions,Project income report,Legal Notice for Donations,lxml is the most feature-rich
and easy-to-use library
for processing XML and HTML
in the Python language.,The lxml XML toolkit is a Pythonic binding for the C libraries
, and ,.  It is unique in that it combines the speed and
XML feature completeness of these libraries with the simplicity of a
native Python API, mostly compatible but superior to the well-known
, API.  The latest release works with all CPython versions
from 2.7 to 3.9.  See the , for more information about
background and goals of the lxml project.  Some common questions are
answered in the ,.,lxml has been downloaded from the ,
millions of times and is also available directly in many package
distributions, e.g. for Linux or macOS.,Most people who use lxml do so because they like using it.
You can show us that you like it by blogging about your experience
with it and linking to the project website.,If you are using lxml for your work and feel like giving a bit of
your own benefit back to support the project, consider sending us
money through GitHub Sponsors, Tidelift or PayPal that we can use
to buy us free time for the maintenance of this great library, to
fix bugs in the software, review and integrate code contributions,
to improve its features and documentation, or to just take a deep
breath and have a cup of tea every once in a while.
Please read the Legal Notice below, at the bottom of this page.
Thank you for your support.,Support lxml through ,via a ,or via PayPal:,Please ,
for other ways to support the lxml project,
as well as commercial consulting, customisations and trainings on lxml and
fast Python XML processing.,Note that we are not accepting donations in crypto currencies.
Much of the development and hosting for lxml is done in a carbon-neutral way
or with compensated and very low emissions.
Crypto currencies do not fit into that ambition., and ,
support the lxml project with their build and CI servers.
Jetbrains supports the lxml project by donating free licenses of their
,.
Another supporter of the lxml project is
,.,The HTML documentation from this web site is part of
the normal ,.,lxml.etree follows the , API as much as possible, building
it on top of the native libxml2 tree.  If you are new to ElementTree,
start with the ,.  See also the
ElementTree , overview and the ,
page comparing lxml to the original , and ,
implementations.,Right after the , and the
, documentation, the next place to look is the , documentation.  It describes how lxml extends the
ElementTree API to expose libxml2 and libxslt specific XML
functionality, such as ,, ,, ,, ,, and
, (including ,).
Python code can be called from XPath expressions and XSLT
stylesheets through the use of ,.  lxml
also offers a ,, that works with the SAX support in
the standard library.,There is a separate module , that implements a data-binding
API on top of lxml.etree.  See the , FAQ entry for a
comparison.,In addition to the ElementTree API, lxml also features a sophisticated
API for ,.  This is a simple way to write
arbitrary XML driven APIs on top of lxml.  lxml.etree also has a
, that can be used to efficiently extend lxml.etree in
external C modules, including fast custom element class support.,The best way to download lxml is to visit , (PyPI).  It has the source
that compiles on various platforms.  The source distribution is signed
with ,.,The latest version is ,, released 2022-12-13
(,).  ,
are listed below.,Please take a look at the
, !,This complete website (including the generated API documentation) is
part of the source distribution, so if you want to download the
documentation for offline use, take the source archive and copy the
, directory out of the source tree.,The latest ,
are available from Github.  It's also possible to check out
the latest development version of lxml from Github directly, using a command
like this:,You can browse the , and its history through
the web.  Please read ,
first.  The , of the developer version are also
accessible.  You can check there if a bug you found has been fixed
or a feature you want has been implemented in the latest trunk version.,Questions? Suggestions? Code to contribute? We have a ,.,You can also , for past questions and discussions.,lxml uses the ,.  If you are sure you found a
bug in lxml, please file a bug report there.  If you are not sure
whether some unexpected behaviour of lxml is a bug or not, please
check the documentation and ask on the , first.  Do not
forget to ,!,The lxml library is shipped under a ,. libxml2 and libxslt2
itself are shipped under the ,. There should therefore be no
obstacle to using lxml in your codebase.,See the websites of lxml
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,,
,lxml has ,
per month on PyPI.,Any donation that you make to the lxml project is voluntary and
is not a fee for any services, goods, or advantages.  By making
a donation to the lxml project, you acknowledge that we have the
right to use the money you donate in any lawful way and for any
lawful purpose we see fit and we are not obligated to disclose
the way and purpose to any party unless required by applicable
law.  Although lxml is free software, to the best of our knowledge
the lxml project does not have any tax exempt status.  The lxml
project is neither a registered non-profit corporation nor a
registered charity in any country.  Your donation may or may not
be tax-deductible; please consult your tax advisor in this matter.
We will not publish or disclose your name and/or e-mail address
without your consent, unless required by applicable law.  Your
donation is non-refundable."
name,content
langdetect,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,Mimino666/langdetect,Name already in use,langdetect,Installation,Languages,Basic usage,How to add new language?,Original project,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Port of Google's language-detection library to Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Port of Nakatani Shuyo's , library (version from 03/03/2014) to Python.,Supported Python versions 2.7, 3.4+., supports 55 languages out of the box (,):,To detect the language of the text:,To find out the probabilities for the top languages:,Language detection algorithm is non-deterministic, which means that if you try to run it on a text which is either too short or too ambiguous, you might get different results everytime you run it.,To enforce consistent results, call following code before the first language detection:,You need to create a new language profile. The easiest way to do it is to use the , tool, which can generate language profiles from Wikipedia abstract database files or plain text.,Wikipedia abstract database files can be retrieved from ""Wikipedia Downloads"" (,). They form '(language code)wiki-(version)-abstract.xml' (e.g. 'enwiki-20101004-abstract.xml' ).,usage: ,Remark: The database filename in Chinese is like 'zhwiki-(version)-abstract-zh-cn.xml' or zhwiki-(version)-abstract-zh-tw.xml', so that it must be modified 'zh-cnwiki-(version)-abstract.xml' or 'zh-twwiki-(version)-abstract.xml'.,To generate language profile from a plain text, use the genprofile-text command.,usage: ,For more details see ,.,This library is a direct port of Google's , library from Java to Python. All the classes and methods are unchanged, so for more information see the project's website or wiki.,Presentation of the language detection algorithm: ,.,
      Port of Google's language-detection library to Python.
    "
name,content
cur-tools,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pabloniklas/cur_tools,Name already in use,cur_tools,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        This projects aims to provide differents TUI elements in Python.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,By Pablo Niklas, , , ,The idea behind this library is to provide DOS like interface using curses.,A simple information window.,Window to browse a text.,It creates a horizontal menu bar.,with submenus,MIT,
      This projects aims to provide differents TUI elements in Python.
    "
name,content
aiomysql,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,aio-libs/aiomysql,Name already in use,aiomysql,aiomysql,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        aiomysql is a library for accessing a MySQL database from the asyncio
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a ""driver"" for accessing a MySQL database
from the , (PEP-3156/tulip) framework. It depends on and reuses most
parts of , . , tries to be like awesome , library and
preserve same api, look and feel.,Internally , is copy of PyMySQL, underlying io calls switched
to async, basically , and , added in
proper places)). sqlalchemy support ported from ,., based on , , and provides same api, you just need
to use  , or , instead of calling
, for every method.,Properties are unchanged, so , is correct as well as
,.,Sqlalchemy support has been ported from , so api should be very familiar
for , user.:,
      aiomysql is a library for accessing a MySQL database from the asyncio
    "
name,content
colorlog,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,borntyping/python-colorlog,Name already in use,Log formatting with colors!,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A colored formatter for the python logging module
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,Add colours to the output of Python's , module.,colorlog currently requires Python 3.6 or higher. Older versions (below 5.x.x)
support Python 2.6 and above., is included as a required dependency and initialised when using
colorlog on Windows.,This library is almost a decade old and supported a wide set of Python versions
for most of its life, which has made it a difficult library to add new features
to. colorlog 6 may break backwards compatibility so that newer features
can be added more easily, but may still not accept all changes or feature
requests. colorlog 4 might accept essential bugfixes but should not be
considered actively maintained and will not accept any major changes or new
features.,Install from PyPI with:,Several Linux distributions provide official packages (,, ,,
,, , and ,), and others have user provided packages
(,, ,, ,).,The , class takes several arguments:,Color escape codes can be selected based on the log records level, by adding
parameters to the format string:,Multiple escape codes can be used at once by joining them with commas when
configuring the color for a log level (but can't be used directly in the format
string). For example, , would use the escape codes for black
text on a white background.,The following escape codes are made available for use in the format string:,The available color names are ,, ,, ,, ,, ,,
,, , and ,.,The following code creates a , for use in a logging setup,
using the default values for each argument.,Secondary log colors are a way to have more than one color that is selected
based on the log level. Each key in , adds an attribute
that can be used in format strings (, becomes ,), and
has a corresponding value that is identical in format to the ,
argument.,The following example highlights the level name using the default log colors,
and highlights the message in red for , and , level log messages.,A full example dictionary can be found in ,.,An instance of ColoredFormatter created with those arguments will then be used
by any handlers that are configured to use the , formatter.,A full example configuration can be found in ,.,ColoredFormatter will work with custom log levels added with
,:,Tests similar to the above examples are found in ,.,colorlog is in maintenance mode. I try and ensure bugfixes are published,
but compatibility with Python 2.6+ and Python 3+ makes this a difficult
codebase to add features to. Any changes that might break backwards
compatibility for existing users will not be considered.,There are some more modern libraries for improving Python logging you may
find useful.,GitHub provides ,.,Some early adopters included ,, ,, and ,.,Copyright (c) 2012-2021 Sam Clements ,Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the ""Software""), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:,The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.,THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.,
      A colored formatter for the python logging module
    "
name,content
matplotlib-inline,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,ipython/matplotlib-inline,Name already in use,Matplotlib Inline Back-end for IPython and Jupyter,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Inline Matplotlib backend for Jupyter
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This package provides support for matplotlib to display figures directly inline in the Jupyter notebook and related clients, as shown below.,With conda:,With pip:,Note that in current versions of JupyterLab and Jupyter Notebook, the explicit use of the , directive is not needed anymore, though other third-party clients may still require it.,This will produce a figure immediately below:,Licensed under the terms of the BSD 3-Clause License, by the IPython Development Team (see , file).,
      Inline Matplotlib backend for Jupyter
    "
name,content
feedfinder2,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,dfm/feedfinder2,Name already in use,Feedfinder2,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A Python library for finding feed links on websites.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This is a Python library for finding links feeds on a website. It is based on
, - originally
written by , and
subsequently maintained by , until his untimely death.,Feedfinder2 offers a single public function: ,. You would use it
as follows:,Now, , is the list: ,. There is some attempt made to rank feeds from
best candidate to worst but... well... you never know.,Feedfinder2 is licensed under the MIT license (see LICENSE).,
      A Python library for finding feed links on websites.
    "
name,content
mccabe,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,PyCQA/mccabe,Name already in use,McCabe complexity checker,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        McCabe complexity checker for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Ned's script to check McCabe complexity.,This module provides a plugin for ,, the Python code checker.,You can install, upgrade, or uninstall , with these commands:,The complexity checker can be used directly:,When both , and , are installed, the plugin is
available in ,:,By default the plugin is disabled.  Use the , switch to
enable it.  It will emit a warning if the McCabe complexity of a function is
higher than the provided value:,This feature is quite useful for detecting over-complex code.  According to McCabe,
anything that goes beyond 10 is too complex.,Flake8 has many features that mccabe does not provide. Flake8 allows users to
ignore violations reported by plugins with ,. Read more about this in
,.
To silence violations reported by ,, place your , on
the function definition line, where the error is reported for (possibly a
decorator).,
      McCabe complexity checker for Python
    "
name,content
amqp,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,celery/py-amqp,Name already in use,Python AMQP 0.9.1 client library,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        amqplib fork
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , , , ,This is a fork of , which was originally written by Barry Pederson.
It is maintained by the , project, and used by , as a pure python
alternative when , is not available.,This library should be API compatible with ,.,Supports draining events from multiple channels (,),Support for timeouts,Channels are restored after channel error, instead of having to close the
connection.,Support for heartbeats,Support for ,Adds , that tries to detect
whether the connection can still be used.,Adds , and ,,
a list of recoverable errors.,Exposes the underlying socket as ,.,Adds , to keep track of consumer tags
that set the no_ack flag.,Slightly better at error recovery,Simple producer publishing messages to , queue using default exchange:,Producer publishing to , exchange with publisher confirms enabled and using virtual_host ,:,Consumer with acknowledgments enabled:,Consumer with acknowledgments disabled:,This library has , support of speedups. Speedups are implemented using Cython. To enable speedups, , environment variable must be set during building/installation.
Currently speedups can be installed:,Differences between AMQP 0.8 and 0.9.1,AMQP 0.9.1 Quick Reference,RabbitMQ Extensions,For more information about AMQP, visit,For other Python client libraries see:,The maintainers of py-amqp and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. [Learn more.](,),
      amqplib fork
    "
name,content
et-xmlfile,"
et_xmlfile
,

,
,A low-memory way of creating XML files.,This is an implementation of lxml's xmlfile module for the standard library's ElementTree."
name,content
mechanize,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-mechanize/mechanize,Name already in use,mechanize - Automate interaction with HTTP web servers,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        The official source code for the python-mechanize project
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., ,Contents,Stateful programmatic web browsing in Python,To install for normal usage:,To install for development:,To install manually, simply add the mechanize sub-directory somewhere on your
PYTHONPATH.,See ,python-mechanize was the creation of John J. Lee. Maintenance was taken over by
Kovid Goyal in 2017.,Much of the code was originally derived from the work of the following people:,Also:,Thanks also to the many people who have contributed bug reports and
patches.,
      The official source code for the python-mechanize project
    "
name,content
jusText,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,miso-belica/jusText,Name already in use,jusText,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Heuristic based boilerplate removal tool
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Program jusText is a tool for removing boilerplate content, such as navigation
links, headers, and footers from HTML pages. It is
, to preserve
mainly text containing full sentences and it is therefore well suited for
creating linguistic resources such as Web corpora. You can
,.,This is a fork of original (currently unmaintained) code of , hosted
on Google Code.,Adaptations of the algorithm to other languages:,Some libraries using jusText:,Some currently (Jan 2020) maintained alternatives:,Make sure you have , 2.7+/3.5+ and ,
(,,
,) installed.
Run simply:,Run tests via,This software has been developed at the , of
, with a financial support from , and
, It also relates to , of Jan Pomikálek.,
      Heuristic based boilerplate removal tool
    "
name,content
gitdb,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,gitpython-developers/gitdb,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        IO of git-style object databases
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,GitDB allows you to access bare git repositories for reading and writing. It aims at allowing full access to loose objects as well as packs with performance and scalability in mind. It operates exclusively on streams, allowing to handle large objects with a small memory footprint.,From ,If you want to go up to 20% faster, you can install gitdb-speedups with:,The source is available in a git repository at gitorious and github:,Once the clone is complete, please be sure to initialize the submodules using,Run the tests with,The library is considered mature, and not under active development. It's primary (known) use is in git-python.,New BSD License,
      IO of git-style object databases
    "
name,content
clint,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,kennethreitz-archive/clint,Name already in use,Clint: Python Command-line Interface Tools,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python Command-line Application Tools
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a module filled with a set of awesome tools for developing
commandline applications., ommand
, ine
, terface
, ools
.,Clint is awesome. Crazy awesome. It supports colors, but detects if the session is a TTY, so doesn't render the colors if you're piping stuff around. Automagically.,Awesome nest-able indentation context manager. Example: (,). It supports custom email-style quotes. Of course, it supports color too, if and when needed.,It has an awesome Column printer with optional auto-expanding columns. It detects how wide your current console is and adjusts accordingly. It wraps your words properly to fit the column size. With or without colors mixed in. All with a single function call.,The world's easiest to use implicit argument system w/ chaining methods for filtering. Seriously.,Run the various executables in , to get a good feel for what Clint offers.,You'll never want to not use it.,I want to indent my console text.,I want to quote my console text (like email).,I want to color my console text.,I want to get data piped to stdin.,I want to get the first commandline argument passed in.,I want to store a configuration file.,I want to force color output even if stdout is not a TTY:,I want to ask for input.,To install clint, simply:,Or, if you absolutely must:,But, you really shouldn't do that.,ISC License.,If you'd like to contribute, simply fork ,, commit your changes
to the , branch (or branch off of it), and send a pull request. Make
sure you add yourself to ,.,
      Python Command-line Application Tools
    "
name,content
prometheus-client,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,prometheus/client_python,Name already in use,Prometheus Python Client,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Prometheus instrumentation library for Python applications
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,The official Python client for ,.,: Install the client:,: Paste the following into a Python interpreter:,: Visit , to view the metrics.,From one easy to use decorator you get:,Prometheus's , function allows calculation of both requests per second,
and latency over time from this data.,In addition if you're on Linux the , metrics expose CPU, memory and
other information about the process for free!,This package can be found on
,.,Four types of metric are offered: Counter, Gauge, Summary and Histogram.
See the documentation on ,
and ,
on how to use them.,Counters go up, and reset when the process restarts.,If there is a suffix of , on the metric name, it will be removed. When
exposing the time series for counter, a , suffix will be added. This is
for compatibility between OpenMetrics and the Prometheus text format, as OpenMetrics
requires the , suffix.,There are utilities to count exceptions raised:,Gauges can go up and down.,There are utilities for common use cases:,A Gauge can also take its value from a callback:,Summaries track the size and number of events.,There are utilities for timing code:,The Python client doesn't store or expose quantile information at this time.,Histograms track the size and number of events in buckets.
This allows for aggregatable calculation of quantiles.,The default buckets are intended to cover a typical web/rpc request from milliseconds to seconds.
They can be overridden by passing , keyword argument to ,.,There are utilities for timing code:,Info tracks key-value information, usually about a whole target.,Enum tracks which of a set of states something is currently in.,All metrics can have labels, allowing grouping of related time series.,See the best practices on ,
and ,.,Taking a counter as an example:,Labels can also be passed as keyword-arguments:,Metrics with labels are not initialized when declared, because the client can't
know what values the label can have. It is recommended to initialize the label
values by calling the , method alone:,Exemplars can be added to counter and histogram metrics. Exemplars can be
specified by passing a dict of label value pairs to be exposed as the exemplar.
For example with a counter:,And with a histogram:,By default counters, histograms, and summaries export an additional series
suffixed with , and a value of the unix timestamp for when the metric
was created. If this information is not helpful, it can be disabled by setting
the environment variable ,.,The Python client automatically exports metrics about process CPU usage, RAM,
file descriptors and start time. These all have the prefix ,, and
are only currently available on Linux.,The namespace and pid constructor arguments allows for exporting metrics about
other processes, for example:,The client also automatically exports some metadata about Python. If using Jython,
metadata about the JVM in use is also included. This information is available as
labels on the , metric. The value of the metric is 1, since it is the
labels that carry information.,By default the collected ,, ,, and , collector metrics are exported.
If this information is not helpful, it can be disabled using the following:,There are several options for exporting metrics.,Metrics are usually exposed over HTTP, to be read by the Prometheus server.,The easiest way to do this is via ,, which will start a HTTP
server in a daemon thread on the given port:,Visit , to view the metrics.,To add Prometheus exposition to an existing HTTP server, see the , class
which provides a ,. It also serves as a simple example of how
to write a custom endpoint.,To use prometheus with ,, there is , which exposes metrics as a twisted resource.,To use Prometheus with ,, there is
, which creates a WSGI application.,Such an application can be useful when integrating Prometheus metrics with WSGI
apps.,The method , can be used to serve the metrics through the
WSGI reference implementation in a new thread.,By default, the WSGI application will respect , headers used by Prometheus
and compress the response if such a header is present. This behaviour can be disabled by passing
, when creating the app, like this:,To use Prometheus with ,, there is
, which creates an ASGI application.,Such an application can be useful when integrating Prometheus metrics with ASGI
apps.,By default, the WSGI application will respect , headers used by Prometheus
and compress the response if such a header is present. This behaviour can be disabled by passing
, when creating the app, like this:,To use Prometheus with , we need to serve metrics through a Prometheus WSGI application. This can be achieved using ,. Below is a working example.,Save the snippet below in a , file,Run the example web application like this,Visit , to see the metrics,To use Prometheus with , and , we need to serve metrics through a Prometheus ASGI application.,Save the snippet below in a , file,For Multiprocessing support, use this modified code snippet. Full multiprocessing instructions are provided ,.,Run the example web application like this,Visit , to see the metrics,The ,
allows machine-level statistics to be exported out via the Node exporter.,This is useful for monitoring cronjobs, or for writing cronjobs to expose metrics
about a machine system that the Node exporter does not support or would not make sense
to perform at every scrape (for example, anything involving subprocesses).,A separate registry is used, as the default registry may contain other metrics
such as those from the Process Collector.,The ,
allows ephemeral and batch jobs to expose their metrics to Prometheus.,A separate registry is used, as the default registry may contain other metrics
such as those from the Process Collector.,Pushgateway functions take a grouping key. , replaces metrics
with the same grouping key, , only replaces metrics with the
same name and grouping key and , deletes metrics with the
given job and grouping key. See the
,
for more information., returns a grouping key with the instance label set
to the host's IP address.,If the push gateway you are connecting to is protected with HTTP Basic Auth,
you can use a special handler to set the Authorization header.,TLS Auth is also supported when using the push gateway with a special handler.,It is also possible to expose metrics to systems other than Prometheus.
This allows you to take advantage of Prometheus instrumentation even
if you are not quite ready to fully transition to Prometheus yet.,Metrics are pushed over TCP in the Graphite plaintext format.,Graphite , are also supported.,Sometimes it is not possible to directly instrument code, as it is not
in your control. This requires you to proxy metrics from other systems.,To do so you need to create a custom collector, for example:,, , and , work similarly.,A collector may implement a , method which returns metrics in the same
format as , (though you don't have to include the samples). This is
used to predetermine the names of time series a , exposes and
thus to detect collisions and duplicate registrations.,Usually custom collectors do not have to implement ,. If , is
not implemented and the CollectorRegistry was created with ,
(which is the case for the default registry) then , will be called at
registration time instead of ,. If this could cause problems, either
implement a proper ,, or if that's not practical have ,
return an empty list.,Prometheus client libraries presume a threaded model, where metrics are shared
across workers. This doesn't work so well for languages such as Python where
it's common to have processes rather than threads to handle large workloads.,To handle this the client library can be put in multiprocess mode.
This comes with a number of limitations:,There's several steps to getting this working:,:,The , environment variable must be set to a directory
that the client library can use for metrics. This directory must be wiped
between process/Gunicorn runs (before startup is recommended).,This environment variable should be set from a start-up shell script,
and not directly from Python (otherwise it may not propagate to child processes).,:,The application must initialize a new ,, and store the
multi-process collector inside. It is a best practice to create this registry
inside the context of a request to avoid metrics registering themselves to a
collector used by a ,. If a registry with metrics
registered is used by a , duplicate metrics may be
exported, one for multiprocess, and one for the process serving the request.,:,The , configuration file needs to include the following function:,:,When ,s are used in multiprocess applications,
you must decide how to handle the metrics reported by each process.
Gauges have several modes they can run in, which can be selected with the , parameter.,Prepend 'live' to the beginning of the mode to return the same result but only considering living processes
(e.g., 'liveall, 'livesum', 'livemax', 'livemin').,The Python client supports parsing the Prometheus text format.
This is intended for advanced use cases where you have servers
exposing Prometheus metrics and need to get them into some other
system.,
      Prometheus instrumentation library for Python applications
    "
name,content
moviepy,"User Guide,Contribute !,MoviePy is a Python module for video editing, which can be used for basic operations (like cuts, concatenations, title insertions), video compositing (a.k.a. non-linear editing), video processing, or to create advanced effects. It can read and write the most common video formats, including GIF.,Here it is in action (run in an IPython Notebook):,MoviePy is an open source software originally written by , and released under the MIT licence. It works on Windows, Mac, and Linux, with Python 2 or Python 3. The code is hosted on ,, where you can push improvements, report bugs and ask for help. There is also a MoviePy forum on , and a mailing list on , .,
        © Copyright 2017, Zulko

    "
name,content
hiredis,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,redis/hiredis-py,Name already in use,hiredis-py,class,with,with,with,with,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python wrapper for hiredis
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,Python extension that wraps protocol parsing code in ,.
It primarily speeds up parsing of multi bulk replies.,hiredis-py is available on ,, and can be installed via:,Building this repository requires a recursive checkout of submodules, and building hiredis. The following example shows how to clone, compile, and run tests. Please note - you will need the gcc installed.,hiredis-py requires ,.,Make sure Python development headers are available when installing hiredis-py.
On Ubuntu/Debian systems, install them with ,.,The , module contains the , class. This class is responsible for
parsing replies from the stream of data that is read from a Redis connection.
It does not contain functionality to handle I/O.,The , class has two methods that are used when parsing replies from a
stream of data. , takes a string argument that is appended to the
internal buffer. , reads this buffer and returns a reply when the
buffer contains a full reply. If a single call to , contains multiple
replies, , should be called multiple times to extract all replies.,Example:,When the buffer does not contain a full reply, , returns ,.
This means extra data is needed and , should be called again before calling
, again. Alternatively you could provide custom sentinel object via parameter,
which is useful for RESP3 protocol where native boolean types are supported:,Example:, is able to decode bulk data to any encoding Python supports.
To do so, specify the encoding you want to use for decoding replies when
initializing it:,Decoding of bulk data will be attempted using the specified encoding and
error handler. If the error handler is , (the default), a
, is raised when data cannot be dedcoded. This is identical
to Python's default behavior. Other valid values to , include
,, ,, and ,. More information on the
behavior of these error handlers can be found
,.,When the specified encoding cannot be found, a , will be raised
when calling , for the first reply with bulk data.,When a protocol error occurs (because of multiple threads using the same
socket, or some other condition that causes a corrupt stream), the error
, is raised. Because the buffer is read in a lazy
fashion, it will only be raised when , is called and the first reply in
the buffer contains an error. There is no way to recover from a faulty protocol
state, so when this happens, the I/O code feeding data to , should
probably reconnect.,Redis can reply with error replies (,). For these replies, the custom
error class , is returned, ,.,When other error types should be used (so existing code doesn't have to change
its , clauses), , can be initialized with the , and
, keywords. These keywords should contain a , that is a
subclass of ,. When not provided, , will use the default
error types.,The repository contains a benchmarking script in the , directory,
which uses , to have non-blocking I/O and redis-py
to handle connections. These benchmarks are done with a patched version of
redis-py that uses hiredis-py when it is available.,All benchmarks are done with 10 concurrent connections.,List entries in the following tests are 5 bytes.,Throughput improvement for simple SET/GET is minimal, but the larger multi bulk replies
get, the larger the performance improvement is.,This code is released under the BSD license, after the license of hiredis.,
      Python wrapper for hiredis
    "
name,content
alabaster,"Alabaster: a Sphinx theme,A light, configurable Sphinx theme,
,
,
Professionally-supported Alabaster is available with the
,.
,Alabaster is a visually (c)lean, responsive, configurable theme for the , documentation system. It is Python 3.6+ compatible.,It began as a third-party theme, and is still maintained separately, but as of
Sphinx 1.3, Alabaster is an install-time dependency of Sphinx and is selected
as the default theme.,Live examples of this theme can be seen on ,, ,,
, and ,.,For more documentation, please see ,.,Easy ability to install/use as a Python package (tip o’ the hat to , for
showing the way);,Style tweaks compared to the source themes, such as better code-block
alignment, Github button placement, page source link moved to footer,
improved (optional) related-items sidebar item, and many more;,Many customization hooks, including toggle of various sidebar & footer
components; header/link/etc color control; etc;,Improved documentation for all customizations (pre-existing & new).,Alabaster is a modified (with permission) version of , , (it’s the one used
in his , project). Kenneth’s
theme was itself originally based on Armin Ronacher’s , theme. Many thanks to both for their hard work., contains a lot of
general exposition & thoughts as I developed Alabaster, specifically with a
mind towards using it on two nearly identical ‘sister’ sites (single-version
www ‘info’ site & versioned API docs site).,Alabaster includes/requires a tiny Sphinx extension on top of the theme
itself; this is just so we can inject dynamic metadata (like Alabaster’s own
version number) into template contexts. It doesn’t add any additional
directives or the like, at least not yet."
name,content
parsel,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,scrapy/parsel,Name already in use,Parsel,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Parsel lets you extract data from XML/HTML documents using XPath or CSS selectors
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Parsel is a BSD-licensed , library to extract data from ,, ,, and
, documents.,It supports:,Find the Parsel online documentation at ,.,Example (,):,
      Parsel lets you extract data from XML/HTML documents using XPath or CSS selectors
    "
name,content
opencv-python,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,opencv/opencv-python,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Automated CI toolchain to produce precompiled opencv-python, opencv-python-headless, opencv-contrib-python and opencv-contrib-python-headless packages.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Pre-built CPU-only OpenCV packages for Python.,Check the manual build section if you wish to compile the bindings from source to enable additional modules such as CUDA.,If you have previous/other manually installed (= not installed via ,) version of OpenCV installed (e.g. cv2 module in the root of Python's site-packages), remove it before installation to avoid conflicts.,Make sure that your , version is up-to-date (19.3 is the minimum supported version): ,. Check version with ,. For example Linux distributions ship usually with very old , versions which cause a lot of unexpected problems especially with the , format.,Select the correct package for your environment:,There are four different packages (see options 1, 2, 3 and 4 below) and you should ,. Do not install multiple different packages in the same environment. There is no plugin architecture: all the packages use the same namespace (,). If you installed multiple different packages in the same environment, uninstall them all with , and reinstall only one package., Packages for standard desktop environments (Windows, macOS, almost any GNU/Linux distribution), Packages for server (headless) environments (such as Docker, cloud environments etc.), no GUI library dependencies,These packages are smaller than the two other packages above because they do not contain any GUI functionality (not compiled with Qt / other GUI components). This means that the packages avoid a heavy dependency chain to X11 libraries and you will have for example smaller Docker images as a result. You should always use these packages if you do not use , et al. or you are using some other package (such as PyQt) than OpenCV to create your GUI.,Import the package:,All packages contain Haar cascade files. , can be used as a shortcut to the data folder. For example:,Read ,Before opening a new issue, read the FAQ below and have a look at the other issues which are already open.,A: No, the packages are special wheel binary packages and they already contain statically built OpenCV binaries.,Since , version 4.3.0.*, , wheels were replaced by , wheels. If your pip is too old, it will try to use the new source distribution introduced in 4.3.0.38 to manually build OpenCV because it does not know how to install , wheels. However, source build will also fail because of too old , because it does not understand build dependencies in ,. To use the new , pre-built wheels (or to build from source), your , version must be >= 19.3. Please upgrade , with ,.,A: If the import fails on Windows, make sure you have , installed. If you are using older Windows version than Windows 10 and latest system updates are not installed, , might be also required.,Windows N and KN editions do not include Media Feature Pack which is required by OpenCV. If you are using Windows N or KN edition, please install also ,.,If you have Windows Server 2012+, media DLLs are probably missing too; please install the Feature called ""Media Foundation"" in the Server Manager. Beware, some posts advise to install ""Windows Server Essentials Media Pack"", but this one requires the ""Windows Server Essentials Experience"" role, and this role will deeply affect your Windows Server configuration (by enforcing active directory integration etc.); so just installing the ""Media Foundation"" should be a safer choice.,If the above does not help, check if you are using Anaconda. Old Anaconda versions have a bug which causes the error, see , for a manual fix.,If you still encounter the error after you have checked all the previous solutions, download , and open the , (located usually at ,) file with it to debug missing DLL issues.,A: Make sure you have removed old manual installations of OpenCV Python bindings (cv2.so or cv2.pyd in site-packages).,A: The repository contains only OpenCV-Python package build scripts, but not OpenCV itself. Python bindings for OpenCV are developed in official OpenCV repository and it's the best place to report issues. Also please check , and , before file new bugs.,A: Non-free algorithms such as SURF are not included in these packages because they are patented / non-free and therefore cannot be distributed as built binaries. Note that SIFT is included in the builds due to patent expiration since OpenCV versions 4.3.0 and 3.4.10. See this issue for more info: ,A: It's easier for users to understand , than , and it makes it easier to find the package with search engines. , (old interface in old OpenCV versions was named as ,) is the name that OpenCV developers chose when they created the binding generators. This is kept as the import name to be consistent with different kind of tutorials around the internet. Changing the import name or behaviour would be also confusing to experienced users who are accustomed to the ,.,
,
,The aim of this repository is to provide means to package each new , for the most used Python versions and platforms.,The project is structured like a normal Python package with a standard , file.
The build process for a single entry in the build matrices is as follows (see for example , file):,In Linux and MacOS build: get OpenCV's optional C dependencies that we compile against,Checkout repository and submodules,Find OpenCV version from the sources,Build OpenCV,Rearrange OpenCV's build result, add our custom files and generate wheel,Linux and macOS wheels are transformed with auditwheel and delocate, correspondingly,Install the generated wheel,Test that Python can import the library and run some sanity checks,Use twine to upload the generated wheel to PyPI (only in release builds),Steps 1--4 are handled by ,.,The build can be customized with environment variables. In addition to any variables that OpenCV's build accepts, we recognize:,See the next section for more info about manual builds outside the CI environment.,If some dependency is not enabled in the pre-built wheels, you can also run the build locally to create a custom wheel.,In order to build , in an unoptimized debug build, you need to side-step the normal process a bit.,If you would like the build produce all compiler commands, then the following combination of flags and environment variables has been tested to work on Linux:,See this issue for more discussion: ,Since OpenCV version 4.3.0, also source distributions are provided in PyPI. This means that if your system is not compatible with any of the wheels in PyPI, , will attempt to build OpenCV from sources. If you need a OpenCV version which is not available in PyPI as a source distribution, please follow the manual build guidance above instead of this one.,You can also force , to build the wheels from the source distribution. Some examples:,If you need contrib modules or headless version, just change the package name (step 4 in the previous section is not needed). However, any additional CMake flags can be provided via environment variables as described in step 3 of the manual build section. If none are provided, OpenCV's CMake scripts will attempt to find and enable any suitable dependencies. Headless distributions have hard coded CMake flags which disable all possible GUI dependencies.,On slow systems such as Raspberry Pi the full build may take several hours. On a 8-core Ryzen 7 3700X the build takes about 6 minutes.,Opencv-python package (scripts in this repository) is available under MIT license.,OpenCV itself is available under , license.,Third party package licenses are at ,.,All wheels ship with , licensed under the ,.,Non-headless Linux wheels ship with , licensed under the ,.,The packages include also other binaries. Full list of licenses can be found from ,., script searches for the version information from OpenCV sources and appends also a revision number specific to this repository to the version string. It saves the version information to , file under , in addition to some other flags.,A release is made and uploaded to PyPI when a new tag is pushed to master branch. These tags differentiate packages (this repo might have modifications but OpenCV version stays same) and should be incremented sequentially. In practice, release version numbers look like this:, e.g. ,The master branch follows OpenCV master branch releases. 3.4 branch follows OpenCV 3.4 bugfix releases.,Every commit to the master branch of this repo will be built. Possible build artifacts use local version identifiers:, e.g. ,These artifacts can't be and will not be uploaded to PyPI.,Linux wheels are built using ,. These wheels should work out of the box for most of the distros (which use GNU C standard library) out there since they are built against an old version of glibc.,The default , images have been extended with some OpenCV dependencies. See , for more info.,Python 3.x compatible pre-built wheels are provided for the officially supported Python versions (not in EOL):,Starting from 4.2.0 and 3.4.9 builds the macOS Travis build environment was updated to XCode 9.4. The change effectively dropped support for older than 10.13 macOS versions.,Starting from 4.3.0 and 3.4.10 builds the Linux build environment was updated from , to ,. This dropped support for old Linux distributions.,Starting from version 4.7.0 the Mac OS GitHub Actions build environment was update to version 11. Mac OS 10.x support depricated. See ,
      Automated CI toolchain to produce precompiled opencv-python, opencv-python-headless, opencv-contrib-python and opencv-contrib-python-headless packages.
    "
name,content
feedparser,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,kurtmckee/feedparser,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Parse feeds in Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,feedparser - Parse Atom and RSS feeds in Python.,feedparser is open source. See the LICENSE file for more information.,feedparser can be installed by running pip:,The feedparser documentation is available on the web at:,It is also included in its source format, ReST, in the , directory.
To build the documentation you'll need the Sphinx package, which is available at:,You can then build HTML pages using a command similar to:,This will produce HTML documentation in the , directory.,Feedparser has an extensive test suite, powered by Tox. To run it, type this:,
      Parse feeds in Python
    "
name,content
Deprecated,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,tantale/deprecated,Name already in use,Deprecated Decorator,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python , decorator to deprecate old python classes, functions or methods.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Python , decorator to deprecate old python classes, functions or methods.,
,
,
,
,
,To use this, decorate your deprecated function with , decorator:,You can also decorate a class or a method:,You can give a ""reason"" message to help the developer to choose another function/class:,The authors of this library are:
,, and
,.,The original code was made in , by
,,
,, and
,.,
      Python , decorator to deprecate old python classes, functions or methods.
    "
name,content
oslo.serialization,"Welcome to oslo.serialization’s documentation!,Welcome to oslo.serialization’s documentation!,The , serialization library provides support for representing objects
in transmittable and storable formats, such as JSON and MessagePack.,Read also the ,.,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Docs.openstack.org is powered by
          ,.
        "
name,content
oauthlib,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,oauthlib/oauthlib,Name already in use,OAuthLib - Python Framework for OAuth1 & OAuth2,A generic, spec-compliant, thorough implementation of the OAuth request-signing
logic for Python 3.6+.,OAuthLib is in active development, with the core of both OAuth1 and OAuth2
completed, for providers as well as clients.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A generic, spec-compliant, thorough implementation of the OAuth request-signing logic
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,OAuth often seems complicated and difficult-to-implement. There are several
prominent libraries for handling OAuth requests, but they all suffer from one or
both of the following:,OAuthLib is a framework which implements the logic of OAuth1 or OAuth2 without
assuming a specific HTTP request object or web framework. Use it to graft OAuth
client support onto your favorite HTTP library, or provide support onto your
favourite web framework. If you're a maintainer of such a library, write a thin
veneer on top of OAuthLib and get OAuth support for very little effort.,Full documentation is available on ,. All contributions are very
welcome! The documentation is still quite sparse, please open an issue for what
you'd like to know, or discuss it in our ,, or even better, send a
pull request!,Then you might be more interested in using , which has OAuthLib
powered OAuth support provided by the , library.,The following packages provide OAuth support using OAuthLib.,If you have written an OAuthLib package that supports your favorite framework,
please open a Pull Request, updating the documentation.,Patching OAuth support onto an http request framework? Creating an OAuth
provider extension for a web framework? Simply using OAuthLib to Get Things Done
or to learn?,No matter which we'd love to hear from you in our , or if you have
anything in particular you would like to have, change or comment on don't
hesitate for a second to send a pull request or open an issue. We might be quite
busy and therefore slow to reply but we love feedback!,Chances are you have run into something annoying that you wish there was
documentation for, if you wish to gain eternal fame and glory, and a drink if we
have the pleasure to run into each other, please send a docs pull request =),OAuthLib is yours to use and abuse according to the terms of the BSD license.
Check the LICENSE file for full details.,OAuthLib has been started and maintained several years by Idan Gazit and other
amazing ,. Thanks to their wonderful work, the open-source ,
creation has been possible and the project can stay active and reactive to users
requests., See , for
details.,For a full changelog see ,.,
      A generic, spec-compliant, thorough implementation of the OAuth request-signing logic
    "
name,content
plotly,"Plotly Open Source Graphing Library for Python,
          Plotly's Python graphing library makes interactive, publication-quality graphs. Examples of how to make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts. ,Plotly.py is
          , and you can
          ,.
        ,Deploy Python AI Dash apps on private Kubernetes clusters: 
    ,
     | 
    ,
     | 
    ,
     | 
    ,
  , Sign up to stay in the loop with all things Plotly — from Dash Club to product
                updates, webinars, and more!"
name,content
greenlet,"greenlet: Lightweight concurrent programming,Contents,If this page has piqued your interest in greenlets,
continue reading by seeing ,.,To get started building your own code with greenlets, read
,, and then ,.,What are greenlets?,greenlets are lightweight coroutines for in-process sequential concurrent
programming.,greenlets can be used on their own, but they are frequently used with
frameworks such as , to provide higher-level abstractions and
asynchronous I/O.,greenlets are frequently defined by analogy to , or Python’s built-in coroutines (generators and , functions). The rest of this section will explore those
analogies. For a more precise introduction, see ,.,See , for how the greenlet library was created, and its
relation to other similar concepts.,Are greenlets similar to threads?,For many purposes, you can usually think of greenlets as cooperatively
scheduled ,. The major differences are
that since they’re cooperatively scheduled, you are in control of
when they execute, and since they are coroutines, many greenlets can
exist in a single native thread.,How are greenlets different from threads?,Threads (in theory) are preemptive and parallel ,, meaning that multiple
threads can be processing work at the same time, and it’s impossible
to say in what order different threads will proceed or see the effects
of other threads. This necessitates careful programming using
,, ,, or
other approaches to avoid ,, ,, or other
bugs.,In contrast, greenlets are cooperative and sequential. This means that
when one greenlet is running, no other greenlet can be running; the
programmer is fully in control of when execution switches between
greenlets. This can eliminate race conditions and greatly simplify the
programming task.,Also, threads require resources from the operating system (the thread
stack, and bookkeeping in the kernel). Because greenlets are
implemented entirely without involving the operating system, they can
require fewer resources; it is often practical to have many more
greenlets than it is threads.,How else can greenlets be used?,greenlets have many uses:,They can be treated like cooperative threads. You can implement any
scheduling policy you desire.,Because greenlets work well with C libraries (greenlets can switch
even with C functions in the call stack), they are well suited for
integrating with GUIs or other event loops., is an example of using greenlets to integrate with IO
event loops (, and ,) to provide a complete
asynchronous environment using familiar programming patterns.,Similar to the above, greenlets can be used to transform apparently
asynchronous tasks into a simple synchronous style. See
, for an example of writing an asynchronous event-driven GUI app
in a simple synchronous style.,In general, greenlets can be used for advanced control flow. For
example, you can ,—without
the use of the , keyword!,Are greenlets similar to generators? What about asyncio?,All three of greenlets, generators, and asyncio use a concept of
coroutines. However, greenlets, unlike the other two, require no
special keywords or support from the Python language. In addition,
greenlets are capable of switching between stacks that feature C
libraries, whereas the other two are not.,Footnotes,In CPython, the ,
generally prevents two threads from executing Python code at
the same time. Parallelism is thus limited to code sections
that release the GIL, i.e., C code.,
        © Copyright 2011, Armin Rigo, Christian Tismer
      
        ,
      

    "
name,content
overrides,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,mkorpela/overrides,Name already in use,overrides,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A decorator to automatically detect mismatch when overriding a method
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A decorator , that verifies that a method that should override an inherited method actually does it.,Copies the docstring of the inherited method to the overridden method.,Since signature validation and docstring inheritance are performed on class creation and not on class instantiation,
this library significantly improves the safety and experience of creating class hierarchies in
Python without significantly impacting performance. See , for the
initial inspiration for this library.,Python has no standard mechanism by which to guarantee that (1) a method that previously overrode an inherited method
continues to do so, and (2) a method that previously did not override an inherited will not override now.
This opens the door for subtle problems as class hierarchies evolve over time. For example,,These can be only checked by explicitly marking method override in the code.,Python also has no standard mechanism by which to inherit docstrings in overridden methods. Because
most standard linters (e.g., flake8) have rules that require all public methods to have a docstring,
this inevitably leads to a proliferation of , docstrings on overridden
methods, or, worse, to a disabling of these rules altogether. In addition, mediocre or missing
docstrings degrade the quality of tooltips and completions that can be provided by an editor.,Compatible with Python 3.6+.,Use , to indicate that a subclass method should override a superclass method.,Use , to require subclass methods that shadow superclass methods to be decorated
with ,.,Use , to indicate that a superclass method cannot be overriden.
With Python 3.11 and above , is directly ,.,Note that , and , must be declared before ,.,This project exists only through the work of all the people who contribute.,mkorpela, drorasaf, ngoodman90, TylerYep, leeopop, donpatrice, jayvdb, joelgrus, lisyarus,
soulmerge, rkr-at-dbx, ashwin153, brentyi,  jobh, tjsmart, bersbersbers.,
      A decorator to automatically detect mismatch when overriding a method
    "
name,content
frozenlist,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,aio-libs/frozenlist,Name already in use,frozenlist,mutable,Matrix Space,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        `FrozenList` is a `list`-like structure that implements `collections.abc.MutableSequence` and can be made immutable.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., is a list-like structure which implements
,. The list is , until ,
is called, after which list modifications raise ,:,FrozenList is also hashable, but only when frozen. Otherwise it also throws a RuntimeError:,The library requires Python 3.8 or newer.,We have a , , which is
also accessible via Gitter., is offered under the Apache 2 license.,The project is hosted on ,Please file an issue in the , if you have found a bug
or have some suggestions to improve the library.,
      `FrozenList` is a `list`-like structure that implements `collections.abc.MutableSequence` and can be made immutable.
    "
name,content
aiohttp,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,aio-libs/aiohttp,Name already in use,Async http client/server framework,aio-libs Discussions,gitter chat,aiohttp,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Asynchronous HTTP client/server framework for asyncio and Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,To get something from the web:,This prints:,Coming from , ? Read ,.,An example using a simple server:,Feel free to make a Pull Request for adding your link to these pages!,: , ,We support ,.
Please add , tag to your question there.,Optionally you may install the , and , libraries (highly
recommended for sake of speed)., is offered under the Apache 2 license.,The aiohttp community would like to thank Keepsafe
(,) for its support in the early days of
the project.,The latest developer version is available in a GitHub repository:
,If you are interested in efficiency, the AsyncIO community maintains a
list of benchmarks on the official wiki:
,
      Asynchronous HTTP client/server framework for asyncio and Python
    "
name,content
keep,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,OrkoHunter/keep,Name already in use,A Meta CLI toolkit,command,Ctrl+R,X,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A Meta CLI toolkit : Personal shell command keeper and snippets manager
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., ,Your personal shell command keeper,Writwick Wraj loves using the command line.,Writwick googles ""How to do X in terminal?"" and multiple forums and
blog posts finally provide him the magical , for the rescue.
Problem Solved !,Fast forward couple weeks, Writwick has to do X in terminal, again. Wraj
remembers solving this few weeks ago. Let him do a reverse-i-search with
,. Nope, can't remember sh*t. Browser search history? 25 web
pages found matching ,. Argh!,Writwik finally finds the solution. From this time Writwik starts
writing the commands somewhere online for the future.,Wait, why shouldn't he keep the command in his terminal itself if this
is only place where he'll ever have use it?,Use Python 3.6 or later.,You can install pip3 using apt-get as ,.,To enable command-line completion (TAB completion) follow these steps for the shell of your choice,Create a directory in your home directory called ,Copy , to ,Add the following lines to , file,Create a directory in your home called ,Copy , to ,Add the following lines inside , file,This is a very young project. If you have got any suggestions for new
features or improvements, please comment over
,. Pull Requests are
most welcome !,Not a command line fanatic? Here are some resources for you :,
      A Meta CLI toolkit : Personal shell command keeper and snippets manager
    "
name,content
langcodes,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,rspeer/langcodes,Name already in use,Langcodes: a library for language codes,Documentation,Changelog,in,macro,macro,language,script,territory,extlangs,variants,script,territory,extensions,private,normalize=False,valid,in a language,same,different,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A Python library for working with and comparing language codes.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., knows what languages are. It knows the standardized codes that
refer to them, such as , for English, , for Spanish and , for Hindi.,These are ,. You may know them by their old name, ISO 639
language codes. IETF has done some important things for backward compatibility
and supporting language variations that you won't find in the ISO standard.,It may sound to you like langcodes solves a pretty boring problem. At one
level, that's right. Sometimes you have a boring problem, and it's great when a
library solves it for you.,But there's an interesting problem hiding in here. How do you work with
language codes? How do you know when two different codes represent the same
thing? How should your code represent relationships between codes, like the
following?,One way to know is to read IETF standards and Unicode technical reports.
Another way is to use a library that implements those standards and guidelines
for you, which langcodes does.,When you're working with these short language codes, you may want to see the
name that the language is called , a language: , is called ""French"" in
English. That language doesn't have to be English: , is called ""français"" in
French. A supplement to langcodes, ,, provides
this information.,langcodes is maintained by Elia Robyn Lake a.k.a. Robyn Speer, and is released
as free software under the MIT license.,Although this is not the only reason to use it, langcodes will make you more
acronym-compliant.,langcodes implements ,, the IETF Best
Current Practices on Tags for Identifying Languages. BCP 47 is also known as
RFC 5646. It subsumes ISO 639 and is backward compatible with it, and it also
implements recommendations from the ,.,langcodes can also refer to a database of language properties and names, built
from Unicode CLDR and the IANA subtag registry, if you install ,.,In summary, langcodes takes language codes and does the Right Thing with them,
and if you want to know exactly what the Right Thing is, there are some
documents you can go read.,This function standardizes tags, as strings, in several ways.,It replaces overlong tags with their shortest version, and also formats them
according to the conventions of BCP 47:,It removes script subtags that are redundant with the language:,It replaces deprecated values with their correct versions, if possible:,Sometimes this involves complex substitutions, such as replacing Serbo-Croatian
(,) with Serbian in Latin script (,), or the entire tag ,
with , (American Sign Language).,If , is True, it uses macrolanguage codes as a replacement for the most
common standardized language within that macrolanguage.,Even when , is False, it shortens tags that contain both the
macrolanguage and the language:,If the tag can't be parsed according to BCP 47, this will raise a
LanguageTagError (a subclass of ValueError):,This package defines one class, named Language, which contains the results
of parsing a language tag. Language objects have the following fields,
any of which may be unspecified:,The , method converts a string to a Language instance, and the
, method makes a Language instance from its fields.  These values
are cached so that calling , or , again with the
same values returns the same object, for efficiency.,By default, it will replace non-standard and overlong tags as it interprets
them. To disable this feature and get the codes that literally appear in the
language tag, use the , option.,Here are some examples of replacing non-standard tags:,Use the , function on a Language object to convert it back to its
standard string form:,A language code is , when every part of it is assigned a meaning by IANA.
That meaning could be ""private use"".,In langcodes, we check the language subtag, script, territory, and variants for
validity. We don't check other parts such as extlangs or Unicode extensions.,For example, , is a valid language code, and , is not:,The top-level function , is possibly more convenient to use,
because it can return False even for tags that don't parse:,If one subtag is invalid, the entire code is invalid:, is valid, though it's a deprecated alias for ,:,The empty language tag (,) is valid:,Private use codes are valid:,Language tags that are very unlikely are still valid:,Tags with non-ASCII characters are invalid, because they don't parse:,Before there was BCP 47, there was ISO 639-2. The ISO tried to make room for the
variety of human languages by assigning every language a 3-letter code,
including the ones that already had 2-letter codes.,Unfortunately, this just led to more confusion. Some languages ended up with two
different 3-letter codes for legacy reasons, such as French, which is , as a
""terminology"" code, and , as a ""biblographic"" code. And meanwhile, , was
still a code that you'd be using if you followed ISO 639-1.,In BCP 47, you should use 2-letter codes whenever they're available, and that's
what langcodes does. Fortunately, all the languages that have two different
3-letter codes also have a 2-letter code, so if you prefer the 2-letter code,
you don't have to worry about the distinction.,But some applications want the 3-letter code in particular, so langcodes
provides a method for getting those, ,. It returns the
'terminology' code by default, and passing , returns the
bibliographic code.,When this method returns, it always returns a 3-letter string.,For many languages, the terminology and bibliographic alpha3 codes are the same.,When you use any of these ""overlong"" alpha3 codes in langcodes, they normalize
back to the alpha2 code:,The methods in this section require an optional package called ,.
You can install it with ,, or request the optional
""data"" feature of langcodes with ,.,The dependency that you put in setup.py should be ,.,It's often helpful to be able to describe a language code in a way that a user
(or you) can understand, instead of in inscrutable short codes. The
, method lets you describe a Language object ,.,The , method will look up the name of the
language. The names come from the IANA language tag registry, which is only in
English, plus CLDR, which names languages in many commonly-used languages.,The default language for naming things is English:,But you can ask for language names in numerous other languages:,Why does everyone get Slovak and Slovenian confused? Let's ask them.,If the language has a script or territory code attached to it, these will be
described in parentheses:,Sometimes these can be the result of tag normalization, such as in this case
where the legacy tag 'sh' becomes 'sr-Latn':,Naming a language in itself is sometimes a useful thing to do, so the
, method makes this easy, providing the display name of a language
in the language itself:,The names come from the Unicode CLDR data files, and in English they can
also come from the IANA language subtag registry. Together, they can give
you language names in the 196 languages that CLDR supports.,You can get the parts of the name separately with the methods ,,
,, and ,, or get a dictionary of all the parts
that are present using the , method. These methods also accept a
language code for what language they should be described in.,As the reverse of the above operations, you may want to look up a language by
its name, converting a natural language name such as ""French"" to a code such as
'fr'.,The name can be in any language that CLDR supports (see ""Ambiguity"" below).,However, this method currently ignores the parenthetical expressions that come from
,:,There is still room to improve the way that language names are matched, because
some languages are not consistently named the same way. The method currently
works with hundreds of language names that are used on Wiktionary.,For the sake of usability, , doesn't require you to specify what
language you're looking up a language in by name. This could potentially lead to
a conflict: what if name ""X"" is language A's name for language B, and language C's
name for language D?,We can collect the language codes from CLDR and see how many times this
happens. In the majority of cases like that, B and D are codes whose names are
also overlapping in the , language and can be resolved by some general
principle.,For example, no matter whether you decide ""Tagalog"" refers to the language code
, or the largely overlapping code ,, that distinction doesn't depend on
the language you're saying ""Tagalog"" in. We can just return , consistently.,In the few cases of actual interlingual ambiguity, langcodes won't match a result.
You can pass in a , parameter to say what language the name is in.,For example, there are two distinct languages called ""Tonga"" in various languages.
They are ,, the language of Tonga which is called ""Tongan"" in English; and ,,
a language of Malawi that can be called ""Nyasa Tonga"" in English.,Other ambiguous names written in Latin letters are ""Kiga"", ""Mbundu"", ""Roman"", and ""Ruanda"".,The , and ,
methods get Unicode's estimates of how many people in the world use a
language.,As with the language name data, this requires the optional ,
package to be installed., estimates how many people speak a language. It can
be limited to a particular territory with a territory code (such as a country
code).,Script codes will be ignored, because the script is not involved in speaking:, estimates how many people write a language.,The estimates for ""writing population"" are often overestimates, as described
in the ,. In most cases,
they are derived from published data about literacy rates in the places where
those languages are spoken. This doesn't take into account that many literate
people around the world speak a language that isn't typically written, and
write in a , language.,Like ,, this can be limited to a particular territory:,The , function returns a number from 0 to 134 indicating the
distance between the language the user desires and a supported language.,The distance data comes from CLDR v38.1 and involves a lot of judgment calls
made by the Unicode consortium.,This table summarizes the language distance values:,See the docstring of , for more explanation and examples.,Suppose you have software that supports any of the ,. The
user wants to use ,.,The function ,
lets you choose the right language, even if there isn't an exact match.
It returns the language tag of the best-supported language, even if there
isn't an exact match.,The , parameter lets you set a cutoff on what counts as language
support. It has a default of 25, a value that is probably okay for simple
cases of i18n, but you might want to set it lower to require more precision.,A similar function is ,,
which returns both the best matching language tag and the distance. If there is
no match, it returns ('und', 1000).,There are many more methods for manipulating and comparing language codes,
and you will find them documented thoroughly in ,.,The interesting functions all live in this one file, with extensive docstrings
and annotations. Making a separate Sphinx page out of the docstrings would be
the traditional thing to do, but here it just seems redundant. You can go read
the docstrings in context, in their native habitat, and they'll always be up to
date.,Updated to CLDR v40.,Updated the IANA subtag registry to version 2021-08-06.,Bug fix: recognize script codes that appear in the IANA registry even if
they're missing from CLDR for some reason. 'cu-Cyrs' is valid, for example.,Switched the build system from , to ,.,To install the package in editable mode before PEP 660 is better supported, use
, instead of ,.,Supports Python 3.6 through 3.10.,Added the top-level function ,, for determining if a string
is a valid language tag without having to parse it first.,Added the top-level function ,,
which is similar to , but with a simpler return value. It
returns the language tag of the closest match, or None if no match is close
enough.,Bug fix: a lot of well-formed but invalid language codes appeared to be
valid, such as 'aaj' or 'en-Latnx', because the regex could match a prefix of
a subtag. The validity regex is now required to match completely.,Bug fixes that address some edge cases of validity:,Updated dependencies so they are compatible with Python 3.10, including
switching back from , to , in ,.,In bugfix release 3.2.1, corrected cases where the parser accepted
ill-formed language tags:,Added the , method, for getting a three-letter code for a
language according to ISO 639-2.,Updated the type annotations from obiwan-style to mypy-style.,Moved bulky data, particularly language names, into a separate
, package. In situations where the data isn't needed,
, becomes a smaller, pure-Python package with no dependencies.,Language codes where the language segment is more than 4 letters no longer
parse: Language.get('nonsense') now returns an error.,(This is technically stricter than the parse rules of BCP 47, but there are
no valid language codes of this form and there should never be any. An
attempt to parse a language code with 5-8 letters is most likely a mistake or
an attempt to make up a code.),Added a method for checking the validity of a language code.,Added methods for estimating language population.,Updated to CLDR 38.1, which includes differences in language matching.,Tested on Python 3.6 through 3.9; no longer tested on Python 3.5.,Added the , method to be a more intuitive way to get a string
describing a language code, and made the , method use it instead of
,.,Updated to CLDR v37.,Previously, some attempts to get the name of a language would return its
language code instead, perhaps because the name was being requested in a
language for which CLDR doesn't have name data. This is unfortunate because
names and codes should not be interchangeable.,Now we fall back on English names instead, which exists for all IANA codes.
If the code is unknown, we return a string such as ""Unknown language [xx]"".,Version 2.0 involves some significant changes that may break compatibility with 1.4,
in addition to updating to version 36.1 of the Unicode CLDR data and the April 2020
version of the IANA subtag registry.,This version requires Python 3.5 or later.,Originally, the goodness of a match between two different language codes was defined
in terms of a ""match score"" with a maximum of 100. Around 2016, Unicode started
replacing this with a different measure, the ""match distance"", which was defined
much more clearly, but we had to keep using the ""match score"".,As of langcodes version 2.0, the ""score"" functions (such as
,, ,, and ,) are deprecated.
They'll keep using the deprecated language match tables from around CLDR 27.,For a better measure of the closeness of two language codes, use ,,
,, and ,.,We were always out of step with CLDR here. Following the example of the IANA
database, we referred to things like the 'US' in 'en-US' as a ""region code"",
but the Unicode standards consistently call it a ""territory code"".,In langcodes 2.0, parameters, dictionary keys, and attributes named ,
have been renamed to ,.  We try to support a few common cases with
deprecation warnings, such as looking up the , property of a Language
object.,A nice benefit of this is that when a dictionary is displayed with 'language',
'script', and 'territory' keys in alphabetical order, they are in the same
order as they are in a language code.,
      A Python library for working with and comparing language codes.
    "
name,content
nest-asyncio,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,erdewit/nest_asyncio,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Patch asyncio to allow nested event loops
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., ,
 , ,
 ,By design asyncio ,
its event loop to be nested. This presents a practical problem:
When in an environment where the event loop is
already running it's impossible to run tasks and wait
for the result. Trying to do so will give the error
"","".,The issue pops up in various environments, such as web servers,
GUI applications and in Jupyter notebooks.,This module patches asyncio to allow nested use of , and
,.,Python 3.5 or higher is required.,Optionally the specific loop that needs patching can be given
as argument to ,, otherwise the current event loop is used.
An event loop can be patched whether it is already running
or not. Only event loops from asyncio can be patched;
Loops from other projects, such as uvloop or quamash,
generally can't be patched.,
      Patch asyncio to allow nested event loops
    "
name,content
pexpect,"Pexpect version 4.8,Indices and tables,Pexpect makes Python a better tool for controlling other
applications.,Pexpect is a pure Python module for spawning child applications;
controlling them; and responding to expected patterns in their output.
Pexpect works like Don Libes’ Expect. Pexpect allows your script to
spawn a child application and control it as if a human were typing
commands.,Pexpect can be used for automating interactive applications such as
ssh, ftp, passwd, telnet, etc. It can be used to a automate setup
scripts for duplicating software package installations on different
servers. It can be used for automated software testing. Pexpect is in
the spirit of Don Libes’ Expect, but Pexpect is pure Python. Unlike
other Expect-like modules for Python, Pexpect does not require TCL or
Expect nor does it require C extensions to be compiled. It should work
on any platform that supports the standard Python pty module. The
Pexpect interface was designed to be easy to use.,Contents:,Pexpect is developed ,. Please
report , there as well.,
        © Copyright 2013, Noah Spurrier and contributors
      
        ,
      

    "
name,content
prompt-toolkit,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,prompt-toolkit/python-prompt-toolkit,Name already in use,Python Prompt Toolkit,is a library for building powerful interactive command line applications in Python.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Library for building powerful interactive command line applications in Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,  ,  ,  ,  , ,Read the ,., is an interactive
Python Shell, build on top of ,., could be a replacement for ,, but it can be much
more than that.,Some features:,Feel free to create tickets for bugs and feature requests, and create pull
requests if you have nice patches that you would like to share with others.,For Conda, do:, is cross platform, and everything that you build on top
should run fine on both Unix and Windows systems. Windows support is best on
recent Windows 10 builds, for which the command line window supports vt100
escape sequences. (If not supported, we fall back to using Win32 APIs for color
and cursor movements).,It's worth noting that the implementation is a ""best effort of what is
possible"". Both Unix and Windows terminals have their limitations. But in
general, the Unix experience will still be a little better.,For Windows, it's recommended to use either , or ,.,The most simple example of the library would look like this:,For more complex examples, have a look in the , directory. All
examples are chosen to demonstrate only one thing. Also, don't be afraid to
look at the source code. The implementation of the , function could be
a good start.,The source code of , should be ,, , and
,. We prefer short functions focusing each on one task and for which
the input and output types are clearly specified. We mostly prefer composition
over inheritance, because inheritance can result in too much functionality in
the same object. We prefer immutable objects where possible (objects don't
change after initialization). Reusability is important. We absolutely refrain
from having a changing global state, it should be possible to have multiple
independent instances of the same code in the same process. The architecture
should be layered: the lower levels operate on primitive operations and data
structures giving -- when correctly combined -- all the possible flexibility;
while at the higher level, there should be a simpler API, ready-to-use and
sufficient for most use cases. Thinking about algorithms and efficiency is
important, but avoid premature optimization.,
      Library for building powerful interactive command line applications in Python
    "
name,content
inflect,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jaraco/inflect,Name already in use,not,singular,plural,does,singular,singular,singular,singular,plural,No.,not,not,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Correctly generate plurals, ordinals, indefinite articles; convert numbers to words
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,inflect.py - Correctly generate plurals, singular nouns, ordinals, indefinite articles; convert numbers to words.,The methods of the class , in module , provide plural
inflections, singular noun inflections, ""a""/""an"" selection for English words,
and manipulation of numbers as words.,Plural forms of all nouns, most verbs, and some adjectives are
provided. Where appropriate, ""classical"" variants (for example: ""brother"" ->
""brethren"", ""dogma"" -> ""dogmata"", etc.) are also provided.,Single forms of nouns are also provided. The gender of singular pronouns
can be chosen (for example ""they"" -> ""it"" or ""she"" or ""he"" or ""they"").,Pronunciation-based ""a""/""an"" selection is provided for all English
words, and most initialisms.,It is also possible to inflect numerals (1,2,3) to ordinals (1st, 2nd, 3rd)
and to English words (""one"", ""two"", ""three"").,In generating these inflections, , follows the Oxford
English Dictionary and the guidelines in Fowler's Modern English
Usage, preferring the former where the two disagree.,The module is built around standard British spelling, but is designed
to cope with common American variants as well. Slang, jargon, and
other English dialects are , explicitly catered for.,Where two or more inflected forms exist for a single word (typically a
""classical"" form and a ""modern"" form), , prefers the
more common form (typically the ""modern"" one), unless ""classical""
processing has been specified
(see MODERN VS CLASSICAL INFLECTIONS).,All of the , plural inflection methods take the word to be
inflected as their first argument and return the corresponding inflection.
Note that all such methods expect the , form of the word. The
results of passing a plural form are undefined (and unlikely to be correct).
Similarly, the , singular inflection method expects the ,
form of the word.,The , methods also take an optional second argument,
which indicates the grammatical ""number"" of the word (or of another word
with which the word being inflected must agree). If the ""number"" argument is
supplied and is not , (or , or ,, or some other adjective that
implies the singular), the plural form of the word is returned. If the
""number"" argument , indicate singularity, the (uninflected) word
itself is returned. If the number argument is omitted, the plural form
is returned unconditionally.,The , method takes a second argument in a similar fashion. If it is
some form of the number ,, or is omitted, the singular form is returned.
Otherwise the plural is returned unaltered.,The various methods of , are:,The method , takes a , English noun,
pronoun, verb, or adjective and returns its plural form. Where a word
has more than one inflection depending on its part of speech (for
example, the noun ""thought"" inflects to ""thoughts"", the verb ""thought""
to ""thought""), the (singular) noun sense is preferred to the (singular)
verb sense.,Hence , will return ""knives"" (""knife"" having been treated
as a singular noun), whereas , will return ""knife""
(""knifes"" having been treated as a 3rd person singular verb).,The inherent ambiguity of such cases suggests that,
where the part of speech is known, ,, ,, and
, should be used in preference to ,.,Note that all these methods ignore any whitespace surrounding the
word being inflected, but preserve that whitespace when the result is
returned. For example, , returns "" cats  "".,The , methods return only the inflected word, not the count that
was used to inflect it. Thus, in order to produce ""I saw 3 ducks"", it
is necessary to use:,Since the usual purpose of producing a plural is to make it agree with
a preceding count, inflect.py provides a method
(,) which, given a word and a(n optional) count, returns the
count followed by the correctly inflected word. Hence the previous
example can be rewritten:,In addition, if the count is zero (or some other term which implies
zero, such as ,, ,, etc.) the count is replaced by the
word ""no"". Hence, if , had the value zero, the previous example
would print (the somewhat more elegant):,rather than:,Note that the name of the method is a pun: the method
returns either a number (a ,) or a ,, in front of the
inflected word.,In some contexts, the need to supply an explicit count to the various
, methods makes for tiresome repetition. For example:,inflect.py therefore provides a method
(,) which may be used to set a persistent ""default number""
value. If such a value is set, it is subsequently used whenever an
optional second ""number"" argument is omitted. The default value thus set
can subsequently be removed by calling , with no arguments.
Hence we could rewrite the previous example:,Normally, , returns its first argument, so that it may also
be ""inlined"" in contexts like:,However, in certain contexts (see INTERPOLATING INFLECTIONS IN STRINGS)
it is preferable that , return an empty string. Hence ,
provides an optional second argument. If that argument is supplied (that is, if
it is defined) and evaluates to false, , returns an empty string
instead of its first argument. For example:,inflect.py also provides a solution to the problem
of comparing words of differing plurality through the methods
,, ,,
,, and ,.
Each  of these methods takes two strings, and  compares them
using the corresponding plural-inflection method (,, ,,
,, and , respectively).,The comparison returns true if:,Hence all of the following return true:,As indicated by the comments in the previous example, the actual value
returned by the various , methods encodes which of the
three equality rules succeeded: ""eq"" is returned if the strings were
identical, ""s:p"" if the strings were singular and plural respectively,
""p:s"" for plural and singular, and ""p:p"" for two distinct plurals.
Inequality is indicated by returning an empty string.,It should be noted that two distinct singular words which happen to take
the same plural form are , considered equal, nor are cases where
one (singular) word's plural is the other (plural) word's singular.
Hence all of the following return false:,Note too that, although the comparison is ""number-insensitive"" it is ,
case-insensitive (that is, , returns false. To obtain
both number and case insensitivity, use the , method on both strings
(that is, , returns true).,Shout out to these libraries that provide related functionality:,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,.,
      Correctly generate plurals, ordinals, indefinite articles; convert numbers to words
    "
name,content
cli-helpers,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,dbcli/cli_helpers,Name already in use,CLI Helpers,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python helpers for common CLI tasks
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,CLI Helpers is a Python package that makes it easy to perform common tasks when
building command-line apps. It's a helper library for command-line interfaces.,Libraries like , and
,
are amazing tools that help you create quality apps. CLI Helpers complements
these libraries by wrapping up common tasks in simple interfaces.,CLI Helpers is not focused on your app's design pattern or framework -- you can
use it on its own or in combination with other libraries. It's lightweight and
easy to extend.,What's included in CLI Helpers?,Read the documentation at ,
      Python helpers for common CLI tasks
    "
name,content
fire,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,google/python-fire,Name already in use,Python Fire ,Python Fire is a library for automatically generating command line interfaces
(CLIs) from absolutely any Python object.,Note that these flags are separated from the Fire command by an isolated ,.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python Fire is a library for automatically generating command line interfaces (CLIs) from absolutely any Python object.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,To install Python Fire with pip, run: ,To install Python Fire with conda, run: ,To install Python Fire from source, first clone the repository and then run:
,You can call , on any Python object:,
functions, classes, modules, objects, dictionaries, lists, tuples, etc.
They all work!,Here's an example of calling Fire on a function.,Then, from the command line, you can run:,Here's an example of calling Fire on a class.,Then, from the command line, you can run:,To learn how Fire behaves on functions, objects, dicts, lists, etc, and to learn
about Fire's other features, see the ,.,For additional examples, see ,.,When you call ,, it fires off (executes) your command.,Please see ,.,Licensed under the
, License.,This is not an official Google product.,
      Python Fire is a library for automatically generating command line interfaces (CLIs) from absolutely any Python object.
    "
name,content
hpack,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python-hyper/hpack,Name already in use,hpack: HTTP/2 Header Encoding for Python,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        HTTP/2 Header Encoding for Python
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This module contains a pure-Python HTTP/2 header encoding (HPACK) logic for use
in Python programs that implement HTTP/2.,Documentation is available at , ., welcomes contributions from anyone! Unlike many other projects we are
happy to accept cosmetic contributions and small contributions, in addition to
large feature requests and changes.,Before you contribute (either by opening an issue or filing a pull request),
please ,., is made available under the MIT License. For more details, see the
, file in the repository., is maintained by Cory Benfield, with contributions from others. For
more details about the contributors, please see ,.,
      HTTP/2 Header Encoding for Python
    "
name,content
convertdate,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,fitnr/convertdate,Name already in use,convertdate,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Utils for converting between date formats and calculating holidays
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,The convertdate package was originally developed as "","" by Phil
Schwartz. It has been significantly updated and expanded.,.,Available calendars:,The , module also provides some useful holiday-calculation,
with a focus on North American and Jewish holidays.,Or download the package and run ,.,Note that in some calendar systems, the day begins at sundown.
Convertdate gives the conversion for noon of the day in question.,Each module includes a , function, which will generate a
calender-like nested list for a year and month (each list of dates runs
from Sunday to Saturday),The Armenian calendar begins on 11 July 552 (Julian) and has two modes of
reckoning. The first is the invariant-length version consisting of 12 months
of 30 days each and five epagomenal days; the second is the version
established by Yovhannes Sarkawag in 1084, which fixed the first day of the
year with respect to the Julian calendar and added a sixth epagomenal day
every four years.,By default the invariant calendar is used, but the Sarkawag calendar can be
used beginning with the Armenian year 533 (11 August 1084) by passing the
parameter , to the relevant functions.,Leap year calculations in the French Republican calendar are a matter of
dispute. By default, , calculates leap years using the
autumnal equinox. You can also use one of three more systematic methods
proposed over the years.,You can specify any of these three methods with the method keyword
argument in , conversion functions.,All the conversion methods correctly assign the leap years implemented
while calendar was in use (3, 7, 11).,The Bahá'í (Badí) calendar has an intercalary period, Ayyam-i-Há, which occurs between the 18th and 19th months.
Dates in this period are returned as month 19, and the month of ‘Alá is reported as month 20.,For dates before the Common Era (year 1), , uses
astronomical notation: 1 BC is recorded as 0, 2 BC is -1, etc. This
makes arithmatic much easier at the expense of ignoring custom.,Note that for dates before 4 CE, , uses the ,. The
Julian Calendar was in use from 45 BC, but before 4 CE the leap year
leap year pattern was irregular.,The , is
used for dates before 1582 CE, the year of the Gregorian calendar
reform.,North American holidays are the current focus of the , module,
but pull requests are welcome.,Convertdate includes some utilities for manipulating and calculating
dates.,Note that when calculating weekdays, convertdate uses the convention of
the calendar and time modules: Monday is 0, Sunday is 6.,Other utility functions:,
      Utils for converting between date formats and calculating holidays
    "
name,content
moreorless,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,thatch/moreorless,Name already in use,moreorless,License,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Wrapper to make difflib.unified_diff more fun to use
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This is a thin wrapper around , that Does The Right Thing
for ""No newline at eof"".  The args are also simplified compared to ,:,moreorless is copyright ,, and licensed under
the MIT license.  I am providing code in this repository to you under an open
source license.  This is my personal repository; the license you receive to
my code is from me and not from my employer. See the , file for details.,
      Wrapper to make difflib.unified_diff more fun to use
    "
name,content
importlib-metadata,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,python/importlib_metadata,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Backport of the importlib.metadata module
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Library to access the metadata for a Python package.,This package supplies third-party access to the functionality of
,
including improvements added to subsequent Python versions.,New features are introduced in this third-party library and later merged
into CPython. The following table indicates which versions of this library
were contributed to different versions in the standard library:,See the ,
for usage details., can
also add support for custom package installers.  See the above documentation
for details.,This project primarily supports third-party packages installed by PyPA
tools (or other conforming packages). It does not support:,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,.,
      Backport of the importlib.metadata module
    "
name,content
bleach,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,mozilla/bleach,Name already in use,Bleach,untrusted,any,security AT mozilla DOT org,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Bleach is an allowed-list-based HTML sanitizing library that escapes or strips markup and attributes
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., See issue:
,Bleach is an allowed-list-based HTML sanitizing library that escapes or strips
markup and attributes.,Bleach can also linkify text safely, applying filters that Django's ,
filter cannot, and optionally setting , attributes, even on links already
in the text.,Bleach is intended for sanitizing text from , sources. If you find
yourself jumping through hoops to allow your site administrators to do lots of
things, you're probably outside the use cases. Either trust those users, or
don't.,Because it relies on ,, Bleach is as good as modern browsers at dealing
with weird, quirky HTML fragments. And , of Bleach's methods will fix
unbalanced or mis-nested tags.,The version on , is the most up-to-date and contains the latest bug
fixes. You can find full documentation on ,.,For regular bugs, please report them ,.,If you believe that you've found a security vulnerability, please ,
or send an email to ,.,For more information on security-related bug disclosure and the PGP key to use
for sending encrypted mail or to verify responses received from that address,
please read our wiki page at
,.,Bleach is a security-focused library.,We have a responsible security vulnerability reporting process. Please use
that if you're reporting a security issue.,Security issues are fixed in private. After we land such a fix, we'll do a
release.,For every release, we mark security issues we've fixed in the , in
the , section. We include any relevant CVE links.,Bleach is available on ,, so you can install it with ,:,Warning,Before doing any upgrades, read through , for backwards
incompatible changes, newer versions, etc.,Bleach follows , versioning. Vendored libraries will not
be changed in patch releases.,The simplest way to use Bleach is:,This project and repository is governed by Mozilla's code of conduct and
etiquette guidelines. For more details please see the ,
      Bleach is an allowed-list-based HTML sanitizing library that escapes or strips markup and attributes
    "
name,content
msgpack,"Sketch>Include Library>Add .zip library,Note that some reflection based serializer tests failed with AOT related limitation.,not,generic,all,compact,read or write exactly one data structure,reserved,Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License You may obtain a copy of the License at,Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.,unpacking,v5,A High Performance, Feature-Rich, Idiomatic encode/decode and rpc library,Maps must have , keys.,any,Please, please, please,upgraded,Note that this is the second version of MessagePack for JavaScript. The first version, which was implemented in ES5 and was never released to npmjs.com, is tagged as ,.,value,ref something,circular reference,void,msgpack,Initial work & Maintainer,Initial work,Check the , section below on how to pack custom types.,The type detection mode (,/,) adds some overhead
which can be noticed when you pack large (16- and 32-bit) arrays or strings.
However, if you know the value type in advance (for example, you only work with
UTF-8 strings or/and associative arrays), you can eliminate this overhead by
forcing the packer to use the appropriate type, which will save it from running
the auto-detection routine. Another option is to explicitly specify the value
type. The library provides 2 auxiliary classes for this, , and ,.
Check the , section below for details.,1. The binary MessagePack format has unsigned 64-bit as its largest integer
data type, but PHP does not support such integers, which means that
an overflow can occur during unpacking.,2. Make sure the , extension
is enabled.,3. Make sure the , extension is enabled.,serialize,More type examples can be found in the , directory.,serializing,More type transformer examples can be found in the , directory.,serialization,deserialization,predefined,application-specific,More extension examples can be found in the , directory.,To learn more about how extension types can be useful, check out this
,.,See a list of various images ,.,With JIT:,see a , of available targets,not set,see a , of available tests,With JIT:,Note that the msgpack extension (v2.1.2) doesn't support ,, , and UTF-8 , types.,$enable,$enable,$enable,A flowchart describing the conversion of R objects into msgpack objects and back.,master,develop,MessagePack is an efficient binary serialization format. It lets you exchange data among multiple languages like JSON. But it's faster and smaller. Small integers are encoded into a single byte, and typical short strings require only one extra byte in addition to the strings themselves.,MessagePack is supported by over 50 programming languages and environments.,See ,.,Redis scripting has support for MessagePack because it is a fast and compact serialization format with a simple to implement specification. I liked it so much that I implemented a MessagePack C extension for Lua just to include it into Redis.,Salvatore Sanfilippo, creator of Redis,Fluentd uses MessagePack for all internal data representation. It's crazy fast because of zero-copy optimization of msgpack-ruby. Now MessagePack is an essential component of Fluentd to achieve high performance and flexibility at the same time.,Sadayuki Furuhashi, creator of Fluentd,Treasure Data built a multi-tenant database optimized for analytical queries using MessagePack. The schemaless database is growing by billions of records every month. We also use MessagePack as a glue between components. Actually we just wanted a fast replacement of JSON, and MessagePack is simply useful.,Kazuki Ohta, CTO,MessagePack has been simply invaluable to us. We use MessagePack + Memcache to cache many of our feeds on Pinterest. These feeds are compressed and very quick to unpack thanks to MessagePack while Memcache gives us fast atomic pushes.,Marty Weiner, Software Engineer,Also use MessagePack? ,as3-msgpack was designed to work with the interfaces IDataInput and IDataOutput, thus the API might be easily connected with the native classes that handle binary data (such as ByteArray, Socket, FileStream and URLStream).,
Moreover, as3-msgpack is capable of decoding data from binary streams.,
Get started: ,For downloads, source code and further information, check the project repository: ,.,MessagePack implementation for Arduino (compatible with other C++ apps),This library is only for serialize / deserialize.
To send / receive serialized data with , class, please use ,.,In msgpack, there are two collection types: , and ,.
C++ containers will be converted to one of them but you can do that from individual parameters.
To , / , values as such collections in a simple way, please use these functions.,The same conversion can be achieved using , and ,.,Here, , and , are used to identify the size of , and , format in , or ,.
This way is expandable to , and , complex data structure because it can be nested.,To serialize / deserialize custom type you defined, please use , macro inside of your class. This macro enables you to convert your custom class to , format.,After that, you can , your class completely same as other types.,You can also wrap your custom class to , format by using , macro.
Please note that you need ""key"" string for , format.,Also you can use , macro to pack values of base class.,If you wamt to use , format in derived class, add ""key"" for your ,.,You can nest custom classes to express complex data structure.,And you can , / , as same as other types.,In other languages like JavaScript, Python and etc. has also library for msgpack.
But some libraries can NOT convert msgpack in ""plain"" style.
They always wrap them into collections like , or , by default.
For example, you can't convert ""plain"" format in other languages.,It is because the msgpack is used as based on JSON (I think).
So you need to use , format for JSON array, and , for Json Object.
To achieve that, there are several ways.,You can directly save/load to/from JSON file with this library. ,, ,, ,, ,, etc. are available for the target file system. Please see , example for more details.,In Arduino, you can use the MsgPack utility to save/load to/from EEPROM. Following code shows how to use them. Please see , example for more details.,These are the lists of types which can be , and ,.
You can also , or , variable one by one.,There are some additional types are defined to express msgpack formats easily.,These types have type aliases like this:,For general C++ apps (not Arduino), , is defined as:, is used to , and , Nil type.
This object is just a dummy and do nothing., holds binary data of Ext type., is used to , and , Timestamp type.,Error information report is disabled by default. You can enable it by defining this macro.,Also you can change debug info stream by calling this macro (default: ,).,See , for details.,STL is used to handle packet data by default, but for following boards/architectures, , is used to store the packet data because STL can not be used for such boards.
The storage size of such boards for max packet binary size and number of msgpack objects are limited.,As mentioned above, for such boards like Arduino Uno, the storage sizes are limited.
And of course you can manage them by defining following macros.
But these default values are optimized for such boards, please be careful not to excess your boards storage/memory.,These macros have no effect for STL enabled boards.,In addtion for such boards, type aliases for following types are different from others.,Please see ""Memory Management"" section and , for detail.,For such boards, there are several STL libraries, like ,, ,, and so on.
But such libraries are mainly based on , and it has many lack of function.
I considered to support them but I won't support them unless uClibc++ becomes much better compatibility to standard C++ library.
I reccomend to use low cost but much better performance chip like ESP series.,MIT,This Arduino library provides a light weight serializer and parser for messagepack.,Download the zip, and import it with your Arduino IDE: ,See the either the , file, or the examples (, and ,).,In short:,Notes:,Currently the library does , support:, ,CMP is a C implementation of the MessagePack serialization format.  It
currently implements version 5 of the ,.,CMP's goal is to be lightweight and straightforward, forcing nothing on the
programmer.,While I'm a big believer in the GPL, I license CMP under the MIT license.,The following examples use a file as the backend, and are modeled after the
examples included with the msgpack-c project.,See the , folder.,CMP uses no internal buffers; conversions, encoding and decoding are done on
the fly.,CMP's source and header file together are ~4k LOC.,CMP makes no heap allocations.,CMP uses standardized types rather than declaring its own, and it depends only
on ,, , and ,.,CMP is written using C89 (ANSI C), aside, of course, from its use of
fixed-width integer types and ,.,On the other hand, CMP's test suite requires C99.,CMP only requires the programmer supply a read function, a write function, and
an optional skip function.  In this way, the programmer can use CMP on memory,
files, sockets, etc.,CMP is portable.  It uses fixed-width integer types, and checks the endianness
of the machine at runtime before swapping bytes (MessagePack is big-endian).,CMP provides a fairly comprehensive error reporting mechanism modeled after
, and ,.,CMP is thread aware; while contexts cannot be shared between threads, each
thread may use its own context freely.,CMP is tested using the MessagePack test suite as well as a large set of custom
test cases.  Its small test program is compiled with clang using , along with several other flags, and generates no compilation
errors in either clang or GCC.,CMP's source is written as readably as possible, using explicit, descriptive
variable names and a consistent, clear style.,CMP's source is written to be as secure as possible.  Its testing suite checks
for invalid values, and data is always treated as suspect before it passes
validation.,CMP's API is designed to be clear, convenient and unsurprising.  Strings are
null-terminated, binary data is not, error codes are clear, and so on.,CMP provides optional backwards compatibility for use with other MessagePack
implementations that only implement version 4 of the spec.,There is no build system for CMP.  The programmer can drop , and ,
in their source tree and modify as necessary.  No special compiler settings are
required to build it, and it generates no compilation errors in either clang or
gcc.,CMP's versions are single integers.  I don't use semantic versioning because
I don't guarantee that any version is completely compatible with any other.  In
general, semantic versioning provides a false sense of security.  You should be
evaluating compatibility yourself, not relying on some stranger's versioning
convention.,I only guarantee stability for versions released on
,.  While rare, both , and ,
branches may have errors or mismatched versions.,Version 4 of the MessagePack spec has no , type, and provides no ,
marker.  In order to remain backwards compatible with version 4 of MessagePack,
do the following:,Avoid these functions:,Use these functions in lieu of their v5 counterparts:,Thanks to , it's possible to disable
floating point operations in CMP by defining ,. No floating point
functionality will be included.  Fair warning: this changes the ABI.,CMP will honor ,. If defined to , it will convert data
to/from little-endian format when writing/reading. If defined to , it won't.
If not defined, CMP will check at runtime.,MPack is a C implementation of an encoder and decoder for the , serialization format. It is:,The core of MPack contains a buffered reader and writer, and a tree-style parser that decodes into a tree of dynamically typed nodes. Helper functions can be enabled to read values of expected type, to work with files, to grow buffers or allocate strings automatically, to check UTF-8 encoding, and more.,The MPack code is small enough to be embedded directly into your codebase. Simply download the , and add , and , to your project.,MPack supports all modern compilers, all desktop and smartphone OSes, WebAssembly, ,, and even 8-bit microcontrollers such as Arduino. The MPack featureset can be customized at compile-time to set which features, components and debug checks are compiled, and what dependencies are available.,
,The Node API parses a chunk of MessagePack data into an immutable tree of dynamically-typed nodes. A series of helper functions can be used to extract data of specific types from each node.,Note that no additional error handling is needed in the above code. If the file is missing or corrupt, if map keys are missing or if nodes are not in the expected types, special ""nil"" nodes and false/zero values are returned and the tree is placed in an error state. An error check is only needed before using the data.,The above example allocates nodes automatically. A fixed node pool can be provided to the parser instead in memory-constrained environments. For maximum performance and minimal memory usage, the , can be used to parse data of a predefined schema.,The Write API encodes structured data to MessagePack.,In the above example, we encode to a growable memory buffer. The writer can instead write to a pre-allocated or stack-allocated buffer (with up-front sizes for compound types), avoiding the need for memory allocation. The writer can also be provided with a flush function (such as a file or socket write function) to call when the buffer is full or when writing is done.,If any error occurs, the writer is placed in an error state. The writer will flag an error if too much data is written, if the wrong number of elements are written, if an allocation failure occurs, if the data could not be flushed, etc. No additional error handling is needed in the above code; any subsequent writes are ignored when the writer is in an error state, so you don't need to check every write for errors.,The above example uses , to automatically determine the number of key-value pairs contained. If you know up-front the number of elements needed, you can pass it to , instead. In that case the corresponding , will assert in debug mode that the expected number of elements were actually written, which is something that other MessagePack C/C++ libraries may not do.,MPack is rich in features while maintaining very high performance and a small code footprint. Here's a short feature table comparing it to other C parsers:,A larger feature comparison table is available , which includes descriptions of the various entries in the table., compares the performance of MPack to other implementations of schemaless serialization formats. MPack outperforms all JSON and MessagePack libraries (except ,), and in some tests MPack is several times faster than , for equivalent data.,Conceptually, MessagePack stores data similarly to JSON: they are both composed of simple values such as numbers and strings, stored hierarchically in maps and arrays. So why not just use JSON instead? The main reason is that JSON is designed to be human-readable, so it is not as efficient as a binary serialization format:,Compound types such as strings, maps and arrays are delimited, so appropriate storage cannot be allocated upfront. The whole object must be parsed to determine its size.,Strings are not stored in their native encoding. Special characters such as quotes and backslashes must be escaped when written and converted back when read.,Numbers are particularly inefficient (especially when parsing back floats), making JSON inappropriate as a base format for structured data that contains lots of numbers.,Binary data is not supported by JSON at all. Small binary blobs such as icons and thumbnails need to be Base64 encoded or passed out-of-band.,The above issues greatly increase the complexity of the decoder. Full-featured JSON decoders are quite large, and minimal decoders tend to leave out such features as string unescaping and float parsing, instead leaving these up to the user or platform. This can lead to hard-to-find platform-specific and locale-specific bugs, as well as a greater potential for security vulnerabilites. This also significantly decreases performance, making JSON unattractive for use in applications such as mobile games.,While the space inefficiencies of JSON can be partially mitigated through minification and compression, the performance inefficiencies cannot. More importantly, if you are minifying and compressing the data, then why use a human-readable format in the first place?,The MPack build process does not build MPack into a library; it is used to build and run the unit tests. You do not need to build MPack or the unit testing suite to use MPack.,See , for information on how to test MPack.,CWPack is a lightweight and yet complete implementation of the
, serialization format
,.
It also supports the Timestamp extension type.,Together with ,, CWPack is the fastest open-source messagepack implementation. Both totally outperform
, and ,CWPack does no memory allocations and no file handling in its basic setup. All that is done outside of CWPack. Example extensions are included.,CWPack is working against memory buffers. User defined handlers are called when buffers are filled up (packing) or needs refill (unpack).,Containers (arrays, maps) are read/written in parts, first the item containing the size and then the contained items one by one. Exception to this is the , function which skip whole containers.,Pack and unpack example from the MessagePack home page:,In the examples folder there are more examples.,CWPack may be run in compatibility mode. It affects only packing; EXT & TIMESTAMP is considered illegal, BIN are transformed to STR and generation of STR8 is supressed.,When an error is detected in a context, the context is stopped and all future calls to that context are immediatly returned without any actions. Thus it is possible to make some calls and delay error checking until all calls are done.,CWPack does not check for illegal values (e.g. in STR for illegal unicode characters).,CWPack consists of a single src file and three header files. It is written in strict ansi C and the files are together ~ 1.4K lines. No separate build is neccesary, just include the files in your own build.,CWPack has no dependencies to other libraries.,Included in the test folder are a module test and a performance test and shell scripts to run them.,CWPack also contains an Objective-C interface. The MessagePack home page example would look like:,CWPack also contains a Swift interface. The MessagePack home page example would pack like:,This is MessagePack serialization/deserialization for CLI (Common Language Infrastructure) implementations such as .NET Framework, Silverlight, Mono (including Moonlight.)
This library can be used from ALL CLS compliant languages such as C#, F#, Visual Basic, Iron Python, Iron Ruby, PowerShell, C++/CLI or so.,You can serialize/deserialize objects as following:,
If you do not pre-generated serializers, MsgPack for CLI uses reflection in AOT environments, it is slower and it sometimes causes AOT related error (, for runtime JIT compilation). , See , for details.,See ,Install Visual Studio 2017 (Community edition is OK) and 2015 (for MsgPack.Windows.sln).,Install latest .NET Core SDK.,Run with Visual Studio Developer Command Prompt:,msbuild MsgPack.sln /t:Restore
msbuild MsgPack.sln,Or (for Unity 3D drops):,Or (for Windows Runtime/Phone drops and Silverlight 5 drops):,Or (for Xamarin unit testing, you must have Xamarin Business or upper license and Mac machine on the LAN to build on Windows):,Or open one of above solution files in your IDE and run build command in it.,First of all, there are binary drops on github release page, you should use it to save your time.,
Because we will not guarantee source code organization compatibilities, we might add/remove non-public types or members, which should break source code build.,
If you want to import sources, you must include just only described on MsgPack.Unity3D.csproj.,
If you want to use "".NET 2.0 Subset"" settings, you must use just only described on MsgPack.Unity3D.CorLibOnly.csproj file, and define , compiler constants.,If you run on Windows, it is recommended to use HXM instead of Hyper-V based emulator.,
You can disable Hyper-V from priviledged (administrator) powershell as follows:,If you want to use Hyper-V again (such as for Docker for Windows etc.), you can do it by following in priviledged (administrator) powershell:,You must create provisoning profiles in your MacOS devices.,
See , for details.,There are bundle IDs of current iOS tests:,See ,This solution contains Silverlight5 and (old) UWP project for backward compability. They are required Visual Studio 2015 to build and test.,
You can download Visual Studio 2015 community edition from ,.,MessagePack implementation for C# / msgpack.org[C#],Binary files distributed via the NuGet package ,.,It's like JSON but small and fast.,.NET Framework 4.x,This library is a lightweight implementation of the , binary serialization format. MessagePack is a 1-to-1 binary representation of JSON, and the official specification can be found here: ,., (,),MPack is available as a NuGet package!,Create a object model that can be represented as MsgPack. Here we are creating a dictionary, but really it can be anything:,Serialize the data to a byte array or to a stream to be saved, transmitted, etc:,Parse the binary data back into a MPack object model (you can also cast back to an MPackMap or MPackArray after reading if you want dictionary/array methods):,Turn MPack objects back into types that we understand with the generic , method. Since we know the types of everything here we can just call , to reconstruct our bool, but if you don't know you can access the instance enum , to know what kind of value it is:,The following people/projects have made this possible:,MsgPack debugging and validation tool also usable as Fiddler plugin,More info about this application (and screenshots) can be found at:
,Although the original was optimised for debugging and analysing, a lightweight version of the lib is included which does not keep track of all offsets and other overhead needed for debugging. It can be used in your code.,Add LsMsgPackL.dll as a reference.,I have never run any benchmarks so I have no idea how it will perform against other implementations.,In order to use this tool as a Fiddler plugin, copy the following files to the Fiddler Inspectors directory (usually C:\Program Files\Fiddler2\Inspectors):,Restart fiddler and you should see a MsgPack option in the Inspectors list.,This module contains the ""parser"" and generator of MsgPack Packages. It breaks down the binary file into a hirarchical structure, keeping track of offsets and errors. And it can also be used to generate MsgPack files.,The main winforms executable, containing a MsgPackExplorer UserControl (so it can easily be integrated into other tools such as Fiddler).,A tiny wrapper enabling the use of MsgPack Explorer as a Fiddler Inspector.,Some unit tests on the core LsMsgPack.dll. No full coverage yet, but at least it's a start.,A light version of the ""parser"". The parsing and generating methods are almost identical to the LsMsgPack lib, but with allot of overhead removed that comes with keeping track of offsets, original types and other debugging info. I'm planning to use this version in my projects that use the MsgPack format.
The LightUnitTests are the same as LsMsgPackUnitTests with some tests omitted.,
,
,
,The extremely fast , serializer for C#.
It is 10x faster than , and outperforms other C# serializers. MessagePack for C# also ships with built-in support for LZ4 compression - an extremely fast compression algorithm. Performance is important, particularly in applications like games, distributed computing, microservices, or data caches.,MessagePack has a compact binary size and a full set of general purpose expressive data types. Please have a look at the , and learn ,.,This library is distributed via NuGet. Special , is available, too.,We target .NET Standard 2.0 with special optimizations for .NET Core 2.1+, making it compatible with most reasonably recent .NET runtimes such as Core 2.0 and later, Framework 4.6.1 and later, Mono 5.4 and later and Unity 2018.3 and later.
The library code is pure C# (with Just-In-Time IL code generation on some platforms).,To install with NuGet, just install the , package:,Install the optional C# , package to get warnings about coding mistakes and automatic fix suggestions to save you time:,There are also a range of official and third party Extension Packages available (learn more in our ,):,For Unity projects, the , page provides downloadable , files. When using in Unity IL2CPP or Xamarin AOT environments, please carefully read the ,.,If you were using MessagePack for C# v1.x, check out the , document.,Define the struct or class to be serialized and annotate it with a , attribute.
Annotate members whose values should be serialized (fields as well as properties) with , attributes.,Call , to serialize/deserialize your object instance.
You can use the , method to get a human readable representation of any MessagePack binary blob.,By default, a , annotation is required. This can be made optional; see the , and the , for details.,The MessagePackAnalyzer package aids with:,If you want to allow a specific custom type (for example, when registering a custom type), put , at the project root and change the Build Action to ,.,An example ,:,These types can serialize by default:,You can add support for custom types, and there are some official/third-party extension packages for:,Please see the ,., is the built-in type representing null/void in MessagePack for C#.,MessagePack for C# can serialize your own public , or , types. By default, serializable types must be annotated with the , attribute and members with the , attribute. Keys can be either indexes (,) or arbitrary strings. If all keys are indexes, arrays are used for serialization, which offers advantages in performance and binary size. Otherwise, MessagePack maps (dictionaries) will be used.,If you use ,, then members do not require explicit , attributes, but string keys will be used.,All public instance members (fields as well as properties) will be serialized. If you want to ignore certain public members, annotate the member with a , attribute.,Please note that any serializable struct or class must have public accessibility; private and internal structs and classes cannot be serialized!
The default of requiring , annotations is meant to enforce explicitness and therefore may help write more robust code.,Should you use an indexed (,) key or a string key?
We recommend using indexed keys for faster serialization and a more compact binary representation than string keys.
However, the additional information in the strings of string keys can be quite useful when debugging.,When classes change or are extended, be careful about versioning. , will initialize members to their , value if a key does not exist in the serialized binary blob, meaning members using reference types can be initialized to ,.
If you use indexed (,) keys, the keys should start at 0 and should be sequential. If a later version stops using certain members, you should keep the obsolete members (C# provides an , attribute to annotate such members) until all other clients had a chance to update and remove their uses of these members as well. Also, when the values of indexed keys ""jump"" a lot, leaving gaps in the sequence, it will negatively affect the binary size, as , placeholders will be inserted into the resulting arrays. However, you shouldn't reuse indexes of removed members to avoid compatibility issues between clients or when trying to deserialize legacy blobs.,Example of index gaps and resulting placeholders:,If you do not want to explicitly annotate with the ,/, attributes and instead want to use MessagePack for C# more like e.g. ,, you can make use of the contractless resolver.,If you want to serialize private members as well, you can use one of the , resolvers.,If you want to use MessagePack for C# more like a BinaryFormatter with a typeless serialization API, use the typeless resolver and helpers. Please consult the ,.,Resolvers are the way to add specialized support for custom types to MessagePack for C#. Please refer to the ,.,You can use , annotations instead of , ones. If type is annotated with ,, you can use , annotations instead of , ones and , instead of ,.,Then , will behave the same as ,, , the same as ,, and , the same as ,.,Using ,, e.g. in shared libraries, makes your classes/structs independent from MessagePack for C# serialization. However, it is not supported by the analyzers nor in code generation by the , tool. Also, features like ,, ,, ,, etc can not be used. Due to this, we recommend that you use the specific MessagePack for C# annotations when possible.,MessagePack for C# supports serialization of readonly/immutable objects/members. For example, this struct can be serialized and deserialized., will choose the constructor with the best matched argument list, using argument indexes index for index keys, or parameter names for string keys. If it cannot determine an appropriate constructor, a , exception will be thrown.
You can specify which constructor to use manually with a , annotation.,C# 9.0 record with primary constructor is similar immutable object, also supports serialize/deserialize.,When using , property setters in , classes, , prevents our most efficient code generation from invoking the property setter.
As a result, you should avoid using , on property setters in generic classes when using the public-only ,/,.,When using the ,/, resolver the bug does not apply and you may use , without restriction.,Objects implementing the , interface will received , and , calls during serialization/deserialization.,MessagePack for C# supports serializing interface-typed and abstract class-typed objects. It behaves like , or ,. In MessagePack for C# these are called ,. Only interfaces and abstracts classes are allowed to be annotated with , attributes. Unique union keys are required.,Unions are internally serialized to two-element arrays.,Using , with abstract classes works the same way.,Please be mindful that you cannot reuse the same keys in derived types that are already present in the parent type, as internally a single flat array or map will be used and thus cannot have duplicate indexes/keys.,When calling , or ,, any values present in the blob will be converted to primitive values, i.e. ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,.,Exploring object trees using the dictionary indexer syntax is the fastest option for untyped deserialization, but it is tedious to read and write.
Where performance is not as important as code readability, consider deserializing with ,., and , can serialize ,/anonymous typed objects.,Unity supports is limited.,When deserializing, the behavior will be the same as Dynamic (Untyped) Deserialization.,The typeless API is similar to ,, as it will embed type information into the blobs, so no types need to be specified explicitly when calling the API.,Type information is represented by the MessagePack , format, type code ,., is a shortcut of ,.
If you want to configure it as the default resolver, you can use ,., can used standalone or combined with other resolvers.,If a type's name is changed later, you can no longer deserialize old blobs. But you can specify a fallback name in such cases, providing a , function of your own.,Deserializing data from an untrusted source can introduce security vulnerabilities in your application.
Depending on the settings used during deserialization, , or cause a denial of service attack.
Untrusted data might come from over the network from an untrusted source (e.g. any and every networked client) or can be tampered with by an intermediary when transmitted over an unauthenticated connection, or from a local storage that might have been tampered with, or many other sources. MessagePack for C# does not provide any means to authenticate data or make it tamper-resistant. Please use an appropriate method of authenticating data before deserialization - such as a , .,Please be very mindful of these attack scenarios; many projects and companies, and serialization library users in general, have been bitten by untrusted user data deserialization in the past.,When deserializing untrusted data, put MessagePack into a more secure mode by configuring your , property:,You should also avoid the Typeless serializer/formatters/resolvers for untrusted data as that opens the door for the untrusted data to potentially deserialize unanticipated types that can compromise security.,The , mode merely hardens against some common attacks, but is no fully secure solution in itself.,Benchmarks comparing MessagePack For C# to other serializers were run on ,. Benchmark code is , - and their ,.
, and , have infinitely fast deserializers, so ignore their deserialization performance.,MessagePack for C# uses many techniques to improve performance.,Before creating this library, I implemented a fast serializer with ,. This is a further evolved implementation. MessagePack for C# is always fast and optimized for all types (primitive, small struct, large object, any collections).,Performance varies depending on the options used. This is a micro benchmark with ,. The target object has 9 members (, ~ ,), values are zero.,, ,, ,, , are MessagePack for C# options. All MessagePack for C# options achieve zero memory allocations in the deserialization process. ,/, is deserialized from strings. ,/, is deserialized from UTF-8 byte arrays using ,. Deserialization is normally read from Stream. Thus, it will be restored from byte arrays (or Stream) instead of strings.,MessagePack for C# , is the fastest. , is slower than , because matching the character string of property names is required. , works by reading the array length, then ,. , works by reading map length, ,, so it requires an additional two steps (decoding of keys and lookups of keys).,String key is often a useful, contractless, simple replacement of JSON, interoperability with other languages, and more robust versioning. MessagePack for C# is also optimized for string keys as much a possible. First of all, it does not decode UTF-8 byte arrays to full string for matching with the member name; instead it will look up the byte arrays as it is (to avoid decoding costs and extra memory allocations).,And It will try to match each , (per 8 character, if it is not enough, pad with 0) using , and inline it when generating IL code.,This also avoids calculating the hash code of byte arrays, and the comparison can be made several times faster using the long type.,This is the sample of decompiled generated deserializer code, decompiled using ,.,If the number of nodes is large, searches will use an embedded binary search.,Extra note, this is serialization benchmark result.,Of course, , is fastest but , also performs reasonably well.,The msgpack format does not provide for reusing strings in the data stream.
This naturally leads the deserializer to create a new , object for every string encountered,
even if it is equal to another string previously encountered.,When deserializing data that may contain the same strings repeatedly it can be worthwhile
to have the deserializer take a little extra time to check whether it has seen a given string before
and reuse it if it has.,To enable string interning on , string values, use a resolver that specifies ,
before any of the standard ones, like this:,If you know which fields of a particular type are likely to contain duplicate strings,
you can apply the string interning formatter to just those fields so the deserializer only pays
for the interned string check where it matters most.
Note that this technique requires a , or , class.,If you are writing your own formatter for some type that contains strings,
you can call on the , directly from your formatter as well for the strings.,MessagePack is a fast and , format but it is not compression. , is an extremely fast compression algorithm, and using it MessagePack for C# can achieve extremely fast performance as well as extremely compact binary sizes!,MessagePack for C# has built-in LZ4 support. You can activate it using a modified options object and passing it into an API like this:, has two modes, , and ,. Neither is a simple binary LZ4 compression, but a special compression integrated into the serialization pipeline, using MessagePack , code (, or ,). Therefore, it is not readily compatible with compression offered in other languages., compresses an entire MessagePack sequence as a single LZ4 block. This is the simple compression that achieves best compression ratio, at the cost of copying the entire sequence when necessary to get contiguous memory., compresses an entire MessagePack sequence as a array of LZ4 blocks. Compressed/decompressed blocks are  chunked and thus do not enter the GC's Large-Object-Heap, but the compression ratio is slightly worse.,We recommend to use , as the default when using compression.
For compatibility with MessagePack v1.x, use ,.,Regardless of which LZ4 option is set at the deserialization, both methods can be deserialized. For example, when the , option was used, binary data using either , and , can be deserialized. Neither can be decompressed and hence deserialized when the compression option is set to ,.,LZ4 compression support is using Milosz Krajewski's , code with some modifications., is major, widely used binary-format library on .NET. I love protobuf-net and respect their great work. But when you use protobuf-net as a general purpose serialization format, you may encounter an annoying issue.,protobuf(-net) cannot handle null and empty collection correctly, because protobuf has no , representation (see ,)., can correctly serialize the entire C# type system. This is a strong reason to recommend MessagePack over protobuf.,Protocol Buffers have good IDL and , support. If you want to use IDL, I recommend , over MessagePack.,JSON is good general-purpose format. It is simple, human-readable and thoroughly-enough specified. , - which I created as well - adopts same architecture as MessagePack for C# and avoids encoding/decoding costs as much as possible just like this library does. If you want to know more about binary vs text formats, see ,., is similar as , but specialized to C#, and special in that regard. Deserialization is infinitely fast but the produced binary size is larger. And ZeroFormatter's caching algorithm requires additional memory.,For many common uses, MessagePack for C# would be a better fit.,MessagePack for C# prioritizes maximum performance by default. However, there are also some options that sacrifice performance for convenience.,The , section shows the results of indexed keys (,) vs string keys (,) performance. Indexed keys serialize the object graph as a MessagePack array. String keys serializes the object graph as a MessagePack map.,For example this type is serialized to, is always fast in both serialization and deserialization because it does not have to handle and lookup key names, and always has the smaller binary size., is often a useful, contractless, simple replacement for JSON, interoperability with other languages with MessagePack support, and less error prone versioning. But to achieve maximum performance, use ,., is an easy way to create composite resolvers. But formatter lookups have some overhead. If you create a custom resolver (or use ,), you can avoid this overhead.,NOTE: If you are creating a library, recommend using the above custom resolver instead of ,. Also, libraries must not use , - as it is global state - to avoid compatibility issues.,By default, MessagePack for C# serializes GUID as string. This is much slower than the native .NET format GUID. The same applies to Decimal. If your application makes heavy use of GUID or Decimal and you don't have to worry about interoperability with other languages, you can replace them with the native serializers , and , respectively.,Also, , is serialized using the MessagePack timestamp format. By using the ,, it is possible to maintain Kind and perform faster serialization., returns , in default. The final , is copied from an internal buffer pool. That is an extra cost.  You can use , or the , API to write to buffers directly. If you want to use a buffer pool outside of the serializer, you should implement custom , or use an existing one such as , from the , package.,During deserialization, , is better than the , overload. This is because the Stream API version starts by reading the data, generating a ,, and only then starts the deserialization.,Compression is generally effective when there is duplicate data. In MessagePack, arrays containing objects using string keys (Contractless) can be compressed efficiently because compression can be applied to many duplicate property names. Indexed keys compression is not as effectively compressed as string keys, but indexed keys are smaller in the first place.,This is some example benchmark performance data;, is not as effectively compressed, but performance is still somewhat degraded. On the other hand, , can be expected to have a sufficient effect on the binary size. However, this is just an example. Compression can be quite effective depending on the data, too, or have little effect other than slowing down your program. There are also cases in which well-compressible data exists in the values (such as long strings, e.g. containing HTML data with many repeated HTML tags). It is important to verify the actual effects of compression on a case by case basis.,MessagePack for C# has extension points that enable you to provide optimal serialization support for custom types. There are official extension support packages.,The , package adds support for types of the , library. It adds ,, ,, ,, ,, , serialization support. It is useful for save viewmodel state.,The , package provides shims for ,'s standard structs (,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,) and corresponding formatters. It can enable proper communication between servers and Unity clients.,After installation, extension packages must be enabled, by creating composite resolvers. Here is an example showing how to enable all extensions.,For configuration details, see: ,.,The , is add-on for ,'s serialization to boost up performance. This is configuration sample.,Other authors are creating extension packages, too.,You can make your own extension serializers or integrate with frameworks. Let's create and share!,MessagePack for C# has experimental features which provides you with very performant formatters. There is an official package.,For detailed information, see: ,The , class is the entry point of MessagePack for C#. Static methods make up the main API of MessagePack for C#.,The , class offers most of the same APIs as above, but removes all type arguments from the API, forcing serialization to include the full type name of the root object. It uses the ,. Consider the result to be a .NET-specific MessagePack binary that isn't readily compatible with MessagePack deserializers in other runtimes.,MessagePack for C# fundamentally serializes using , and deserializes using , or ,. Method overloads are provided to conveniently use it with common buffer types and the .NET , class, but some of these convenience overloads require copying buffers once and therefore have a certain overhead.,The high-level API uses a memory pool internally to avoid unnecessary memory allocation. If result size is under 64K, it allocates GC memory only for the return bytes.,Each serialize/deserialize method takes an optional , parameter which can be used to specify a custom , to use or to activate LZ4 compression support.,To deserialize a , that contains multiple consecutive MessagePack data structures,
you can use the , class to efficiently identify the ,
for each data structure and deserialize it. For example:,The , interface is responsible for serializing a unique type. For example , represents Int32 MessagePack serializer.,Many built-in formatters exists under ,. Your custom types are usually automatically supported with the built-in type resolvers that generate new , types on-the-fly using dynamic code generation. See our , support for platforms that do not support this.,However, some types - especially those provided by third party libraries or the runtime itself - cannot be appropriately annotated, and contractless serialization would produce inefficient or even wrong results.
To take more control over the serialization of such custom types, write your own , implementation.
Here is an example of such a custom formatter implementation. Note its use of the primitive API that is described in the next section.,The , and , statements provide a level of security while deserializing untrusted data
that might otherwise be able to execute a denial of service attack by sending MessagePack data that would
deserialize into a very deep object graph leading to a , that would crash the process.
This pair of statements should surround the bulk of any , method.,: A message pack formatter must ,.
In the above example we just read/write a string. If you have more than one element to write out,
you must precede it with a map or array header. You must read the entire map/array when deserializing.
For example:,Your custom formatters must be discoverable via some ,. Learn more in our , section.,You can see many other samples from ,.,The , and , structs make up the lowest-level API. They read and write the primitives types defined in the MessagePack specification.,A , can efficiently read from , or , without any allocations, except to allocate a new , as required by the , method. All other methods return either value structs or , slices for extensions/arrays.
Reading directly from , means the reader can directly consume some modern high performance APIs such as ,.,The , is capable of automatically interpreting both the old and new MessagePack spec.,A , writes to a given instance of ,. Several common implementations of this exist, allowing zero allocations and minimal buffer copies while writing directly to several I/O APIs including ,.,The , writes the new MessagePack spec by default, but can write MessagePack compatible with the old spec by setting the , property to ,., is serialized to ,, it serialize/deserialize UTC and loses , info and requires that ,.
If you use the ,, , values will be serialized using .NET's native , representation, which preserves , info but may not be interoperable with non-.NET platforms.,An , is storage of typed serializers. The , API accepts a , object which specifies the , to use, allowing customization of the serialization of complex types.,Each instance of , accepts only a single resolver. Most object graphs will need more than one for serialization, so composing a single resolver made up of several is often required, and can be done with the , as shown below:,A resolver can be set as default with ,, but ,:
When developing an application where you control all MessagePack-related code it may be safe to rely on this mutable static to control behavior.
For all other libraries or multi-purpose applications that use , you should explicitly specify the , to use with each method invocation to guarantee your code behaves as you expect even when sharing an , or process with other MessagePack users that may change this static property.,Here is sample of use , with , (It is Json.NET-like lightweight setting.),If you want to make an extension package, you should write both a formatter and resolver
for easier consumption.
Here is sample of a resolver:,MessagePackFormatterAttribute is a lightweight extension point of class, struct, interface, enum and property/field. This is like Json.NET's JsonConverterAttribute. For example, serialize private field, serialize x10 formatter.,Formatter is retrieved by ,, it is included in ,., is lightweight extension point of class and struct. If there exists types that can't be serialized, you can register , that serializes those to nil/null.,MessagePack for C# already used some MessagePack extension type codes, be careful to avoid using the same ext code for other purposes.,This leaves the following ranges for your use:,Within the , ranges, this library defines or implements extensions that use these type codes:,Unity lowest supported version is ,, API Compatibility Level supports both , and ,.,You can install the , from the , page.
If your build targets .NET Framework 4.x and runs on mono, you can use it as is.
But if your build targets IL2CPP, you can not use ,, so it is required to use pre-code generation. Please see ,.,MessagePack for C# includes some additional , libraries that originally provides in NuGet. They are located under ,. If other packages use these libraries (e.g. Unity Collections package using ,), to avoid conflicts, please delete the DLL under ,.,Currently , does not work on IL2CPP, so it is recommended to use , instead.,In Unity, MessagePackSerializer can serialize ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, , and their nullable, array and list types with the built-in extension ,. It is included in StandardResolver by default.,MessagePack for C# has an additional unsafe extension.  , is special resolver for extremely fast but unsafe serialization/deserialization of struct arrays.,x20 faster Vector3[] serialization than native JsonUtility. If use ,, serialization uses a special format (ext:typecode 30~39)  for ,, ,, ,, ,, ,, ,. If use ,, it supports ,, ,, , too. This special feature is useful for serializing Mesh (many ,) or many transform positions.,If you want to use unsafe resolver, register , or ,.,Here is sample of configuration.,The , NuGet package is for .NET server-side serialization support to communicate with Unity. It includes shims for Vector3 etc and the Safe/Unsafe serialization extension.,If you want to share a class between Unity and a server, you can use , or , or a glob reference (with ,), etc. Anyway, you need to share at source-code level. This is a sample project structure using a glob reference (recommended).,By default, MessagePack for C# serializes custom objects by , on the fly at runtime to create custom, highly tuned formatters for each type. This code generation has a minor upfront performance cost.
Because strict-AOT environments such as Xamarin and Unity IL2CPP forbid runtime code generation, MessagePack provides a way for you to run a code generator ahead of time as well.,Note: When using Unity, dynamic code generation only works when targeting .NET Framework 4.x + mono runtime.
For all other Unity targets, AOT is required.,If you want to avoid the upfront dynamic generation cost or you need to run on Xamarin or Unity, you need AOT code generation. , (MessagePackCompiler) is the code generator of MessagePack for C#. mpc uses , to analyze source code.,First of all, mpc requires ,. The easiest way to acquire and run mpc is as a dotnet tool.,Installing it as a local tool allows you to include the tools and versions that you use in your source control system. Run these commands in the root of your repo:,Check in your , file. On another machine you can ""restore"" your tool using the , command.,Once you have the tool installed, simply invoke using , within your repo:,Alternatively, you can download mpc from the , page, that includes platform native binaries (that don't require a separate dotnet runtime)., targets C# code with , or , annotations.,By default, , generates the resolver as , and formatters as,.,Here is the full sample code to register a generated resolver in Unity.,In Unity, you can use MessagePack CodeGen windows at ,.,Install the .NET Core runtime, install mpc (as a .NET Core Tool as described above), and execute ,. Currently this tool is experimental so please tell me your opinion.,In Xamarin, you can install the , into your projects to pre-compile fast serialization code and run in environments where JIT compilation is not allowed.,MessagePack advocated ,, but work on it has stopped and it is not widely used.,I've created a gRPC based MessagePack HTTP/2 RPC streaming framework called ,. gRPC usually communicates with Protocol Buffers using IDL. But MagicOnion uses MessagePack for C# and does not need IDL. When communicating C# to C#, schemaless (or rather C# classes as schema) is better than using IDL.,The StreamJsonRpc library is based on , and includes , and as of v2.3 includes ,.,See our ,.,Yoshifumi Kawai (a.k.a. neuecc) is a software developer in Japan.
He is the Director/CTO at Grani, Inc.
Grani is a mobile game developer company in Japan and well known for using C#.
He is awarding Microsoft MVP for Visual C# since 2011.
He is known as the creator of , (Reactive Extensions for Unity),
,Form validation library. Includes MsgPack and JSON serializer/deserializer.,GoodForm uses std::any, which requires c++17. When c++17 is not available, boost::any is expected and will be installed automatically when using ,.,
,
,msgpack11 is a tiny MsgPack library for C++11, providing MsgPack parsing and serialization.,
This library is inspired by ,.,
The API of msgpack11 is designed to be similar with json11.,Using CMake,Using Buck,There are more specific examples in example.cpp.
Please see it.,Derived from ,CPU : 2.6 GHz Intel Core i7,
Memory : 16 GB 2133 MHz LPDDR3,
Git revision : 6f6b4302b68b3c88312eb24367418b7fce81298c,This software is released under the MIT License, see LICENSE.txt.,A modern (c++17 required) implementation of the ,.,Msgpack is a binary serialization specification. It allows you to save and load application objects like classes and structs over networks, to files, and between programs and even different languages.,Check out , for my rational creating this library.,Want to use this library? Just #include the header and you're good to go. Its less than 1000 lines of code.,Easily pack objects into byte arrays using a pack free function:,It's like JSON but smaller and faster., is an efficient binary serialization
format, which lets you exchange data among multiple languages like JSON,
except that it's faster and smaller. Small integers are encoded into a
single byte and short strings require only one extra byte in
addition to the strings themselves.,See ,See ,You can get additional information including the tutorial on the
,., is developed on GitHub at ,.
To report an issue or send a pull request, use the
,.,Here's the list of ,., is licensed under the Boost Software License, Version 1.0. See
the , file for details.,clojure-msgpack is a lightweight and simple library for converting
between native Clojure data structures and MessagePack byte formats.
clojure-msgpack only depends on Clojure itself; it has no third-party
dependencies.,
, provides a streaming API for situations where it is more
convenient or efficient to work with byte streams instead of fixed byte arrays
(e.g. size of object is not known ahead of time).,The streaming counterpart to , is ,
which returns nil and accepts either
,
or
,
as an additional argument., is in ""streaming mode"" when the argument is of type
,
or
,.,Serializing a value of unrecognized type will fail with ,.  See , if you want to register your own types.,Some native Clojure types don't have an obvious MessagePack counterpart. We can
serialize them as Extended types. To enable automatic conversion of these
types, load the , library.,With ,:,Without ,:,You can also define your own Extended types with ,.,All pack and unpack functions take an optional map of options:,
Serialize/deserialize strings and bytes using the raw-type defined here:
,Note: No error is thrown if an unpacked value is reserved under the old spec
but defined under the new spec. We always deserialize something if we can
regardless of ,.,clojure-msgpack is MIT licensed. See the included LICENSE file for more details.,MessagePack implementation in Crystal.,Add this to your application's ,:,Copyright 2015 Benoist Claassen,A low-level , codec for ,Add this to your application's ,:,Any type can become encodable by including , and defining ,Any type can become decodable by following the ,2016 (c) Copyright Barry Allard,MessagePack is a binary-based JSON-like serialization library.,MessagePack for D is a pure D implementation of MessagePack.,Note: The , type is only supported in D.
Don't use the , type when communicating with other programming languages.
Note that , will raise an exception if a loss of precision occurs.,Use dub to add it as a dependency:,Example code can be found in the , directory.,The documentation can be found ,msgpack-d is very simple to use. Use , for serialization, and , for deserialization:,Use the , attribute:,msgpack-d provides the functions , / , to allow you
to use custom routines during the serialization or deserialization of user-defined class and struct types.
This feature is especially useful when serializing a derived class object when that object is statically
typed as a base class object.,For example:,In addition, here is also a method using , attribute:,These types are used by the , and , functions.,See the documentation of ,, , and , for more details.,The official MessagePack protocol website.,Use this issue tracker to review and file bugs in msgpack-d.,Other language bindings and implementations of the msgpack protocol can be found here.,Distributed under the ,.,This is a very early release of my MessagePack library for Dart. Currently, message classes must be written by hand. For example:,For each class you need to define the , and , methods, which convert from and to a list of fields respectively.,For example usage, see the unit tests.,MessagePack implementation for dart.,Clean, simple, fast and with sane API and implementation.,QMsgPack is a simple and powerful Delphi & C++ Builder implementation for messagepack protocol.
QMsgPack is a part of QDAC 3.0,Source code hosted in Sourceforge(,).,· Full types support,include messagepack extension type,· Full open source,free for used in ANY PURPOSE,· Quick and simple interface,· RTTI support include,QMsgPack is not a desgin time package.So just place QMsgPack files into search path and add to your project.,· Topic in Website (,) ,CHINESE only,· Mail to author (,),· Post in forum (,),· QQ Group No：250530692 (,),· HTTP (,),· SVN (svn://svn.code.sf.net/p/qdac3/code/),Add , as a dependency in your , file.,Support string type. This options is , by default.,Support extention type.,See ,.,MIT,
,Msgpax is a high-performance and comprehensive library for serializing and deserializing Elixir terms using the , format.,.,A detailed table that shows the relationship between Elixir types and MessagePack types can be found in the ,.,Add , as a dependency in your , file:,Then, run , in your shell to fetch the new dependency.,Msgpax is released under ,.,
,
,, >= 17.0 Also based on
,.,Or as it is ,, just,might work.,Both for packing and unpacking. Default is ,. Major difference
between old and new spec is:,The default is new spec. Old spec mode does not handle these new types but
returns error. To use
,
mode, this option is explicitly added.,Only in packing. Atoms are packed as binaries. Default value is ,.
Otherwise, any term including atoms throws badarg.,Both in packing and unpacking. In packing, if an atom is in this list
a binary is encoded as a binary. In unpacking, msgpacked binaries are
decoded as atoms with , with encoding
,. Default value is an empty list.,Even if , is ,, known atoms are packed.,A switch to choose decoded term style of , type when ,.
Only available at new spec. Default is ,.,Only in unpacking, UTF-8 validation at unpacking from , type will
be enabled. Default value is ,.,A switch to choose packing of , when packing. Only available
at new spec. Default is , for symmetry with ,
option.,But the default option pays the cost of performance for symmetry. If
the overhead of UTF-8 validation is unacceptable, choosing , as
the option would be the best.,Both at packing and unpacking. Default value is ,.,At both. The default behaviour in case of facing ext data at decoding
is to ignore them as its length is known.,Now msgpack-erlang supports ext type. Now you can serialize everything
with your original (de)serializer. That will enable us to handle
erlang- native types like ,, , contained in ,. See
, for example code.,The Float type of Message Pack represents IEEE 754 floating point number, so it includes Nan and Infinity.
In unpacking, msgpack-erlang returns ,, , and ,.,Apache License 2.0,0.2 series works with OTP 17.0, R16, R15, and with MessagePack's new
and old format. But does not support , type introduced in
OTP 17.0.,It also supports JSX-compatible mode.,MessagePack is a fast and compact binary serialization library.,MessagePack for F# is a MessagePack implementation of F#, by F#, for F#.,Distributed under the , .,MessagePack.FSharpExtensions is a , extension library for F#.,Records, Struct Records and Anonymous Records are serialized and deserialized using , in ,.,
,
,
,msgpack is brought to you by , ,.
Uptrace is an open source and blazingly fast
, powered
by OpenTelemetry and ClickHouse. Give it a star as well!,msgpack supports 2 last Go versions and requires support for
,. So make sure to initialize a Go module:,And then install msgpack/v5 (note , in the import; omitting it is a popular mistake):,Thanks to all the people who already contributed!,.,To install:,Source: [,],
Online documentation: [,],Typical usage:,This is a code generation tool and serialization library for ,. You can read more about MessagePack ,, or at ,.,In a source file, include the following directive:,The , command will generate serialization methods for all exported type declarations in the file.,You can ,.,Field names can be set in much the same way as the , package. For example:,By default, the code generator will satisfy ,, ,, ,,
,, and ,. Carefully-designed applications can use these methods to do
marshalling/unmarshalling with zero heap allocations.,While , and , are quite similar to the standard library's
, and ,, , and , are useful for
stream serialization. (, and , are essentially protocol-aware versions
of , and ,, respectively.),Consider the following:,As long as the declarations of , and , are in the same file as ,, the parser will determine that the type information for , and , can be passed into the definition of , before its methods are generated.,MessagePack supports defining your own types through ""extensions,"" which are just a tuple of
the data ""type"" (,) and the raw binary. You ,Mostly stable, in that no breaking changes have been made to the , library in more than a year. Newer versions
of the code may generate different code than older versions for performance reasons. I (@philhofer) am aware of a
number of stability-critical commercial applications that use this code with good results. But, caveat emptor.,You can read more about how , maps MessagePack types onto Go types ,.,Here some of the known limitations/restrictions:,If the output compiles, then there's a pretty good chance things are fine. (Plus, we generate tests for you.) , file an issue if you think the generator is writing broken code.,If you like benchmarks, see , and ,.,As one might expect, the generated methods that deal with , are faster for small objects, but the , methods are generally more memory-efficient (and, at some point, faster) for large (> 2KB) objects.,
,
,
,
,If your application serializes only primitive types, array, map and struct, code generation is also recommended.
You can get the fastest performance with ,.,This package requires more than  version ,Current version is ,.,This result made from ,This library is under the MIT License.,Build Status: ,Msgpack for HHVM, It is a msgpack binding for HHVM,If you don't have , program, please intall package ,Feel free to send Pull Requests for bug report at: ,This is an implementation of , for ,.,It contains:,Execute following instructions:, documentation can be found on Hackage:,This implementation defines an messagepack , type, which is an instance of
, (from , ):,Thus, you can use cereal's , and , to pack and unpack objects., ,MessagePack (,) serialization library for Haxe,Simply use , to use this github repo or , to use the one in the haxelib repository., Yay!,This Jackson extension library handles reading and writing of data encoded in , data format.
It extends standard Jackson streaming API (,, ,, ,), and as such works seamlessly with all the higher level data abstractions (data binding, tree model, and pluggable extensions).,To use this module on Maven-based projects, use following dependency:,Only thing you need to do is to instantiate MessagePackFactory and pass it to the constructor of ObjectMapper.,Also, you can exchange data among multiple languages.,Java,Ruby,Java, is a binary serialization format. If you need a fast and compact alternative of JSON, MessagePack is your friend. For example, a small integer can be encoded in a single byte, and short strings only need a single byte prefix + the original byte array. MessagePack implementation is already available in various languages (See also the list in ,) and works as a universal data format.,MessagePack v7 (or later) is a faster implementation of the previous version ,, and
supports all of the message pack types, including ,.,.,
,For Maven users:,For sbt users:,For gradle users:,For using DirectByteBuffer (off-heap memory access methods) in JDK17, you need to specify two JVM options:,msgpack-java supports serialization and deserialization of Java objects through ,.
For details, see ,. The template-based serialization mechanism used in v06 is deprecated.,msgpack-java uses , for building the projects. For the basic usage of sbt, see:,Coding style,Enter the sbt console:,Here is a list of sbt commands for daily development:,To publish a new version, you only need to add a new git tag and push it to GitHub. GitHub Action will deploy a new release version to Maven Central (Sonatype).,To generate a release notes, you can use this command line:,If you need to publish to Maven central using a local machine, you need to configure , plugin. First set Sonatype account information (user name and password) in the global sbt settings. To protect your password, never include this file in your project.,You may also need to configure GPG. See the instruction in ,.,Then, run , followed by ,:,If some sporadic error happens (e.g., Sonatype timeout), rerun , again.,Fast Pure JavaScript MessagePack Encoder and Decoder,Online demo: ,A CLI tool bin/msgpack converts data stream from JSON to MessagePack and vice versa.,Run tests on node.js:,Run tests on browsers:,Browser version , is also available. 50KB minified, 14KB gziped.,Step #1: write some code at first.,Proceed to the next steps if you prefer faster browserify compilation time.,Step #2: add , property on , in your project. This refers the global , object instead of including whole of , source code.,Step #3: compile it with , and ,.,Step #4: load , before your code.,It is tested to have basic compatibility with other Node.js MessagePack modules below:,A benchmark tool , is available to compare encoding/decoding speed
(operation per second) with other MessagePack modules.
It counts operations of , in 10 seconds.,Streaming benchmark tool , is also available.
It counts milliseconds for 1,000,000 operations of 30 bytes fluentd msgpack fragment.
This shows streaming encoding and decoding are super faster.,Test environment: msgpack-lite 0.1.14, Node v4.2.3, Intel(R) Xeon(R) CPU E5-2666 v3 @ 2.90GHz,The following table shows how JavaScript objects (value) will be mapped to
,
and vice versa.,Note that both , and , are mapped to nil , type.
This means , value will be , to , in other words.,The MessagePack specification allows 128 application-specific extension types.
The library uses the following types to make round-trip conversion possible
for JavaScript native objects.,Other extension types are mapped to built-in ExtBuffer object.,Register a custom extension type number to serialize/deserialize your own class instances.,The first argument of , and , should be an integer within the range of 0 and 127 (0x0 and 0x7F). , is a function that accepts an instance of ,, and should return a buffer representing that instance. , is the opposite: it accepts a buffer and should return an instance of ,.,If you pass an array of functions to , or ,, the value to be encoded/decoded will pass through each one in order. This allows you to do things like this:,You can also pass the , option to ,, ,, ,, and ,.,If you wish to modify the default built-in codec, you can access it at ,., function accepts some options.,It does NOT have the preset extension types defined when no options given.,: It has the preset extension types described above.,: It runs a validation of the value before writing it into buffer. This is the default behavior for some old browsers which do not support , object.,: It uses , formats instead of , and ,.,: It decodes msgpack's ,/, formats with , object.,: It ties msgpack's , format with , object, instead of , object.,: It returns Uint8Array object when encoding, instead of , object.,: Uses the global JavaScript Map type, if available, to unpack
MessagePack map elements.,The , respects for ,. Set , to ,.,The MIT License (MIT),Copyright (c) 2015-2016 Yusuke Kawasaki,Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ""Software""), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:,The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.,THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.,This is a , serializer and deserializer written in JavaScript for web browsers (including IE 11) and Node.js.,It is compact but still fully-featured. This library supports the complete , released on 2017-08-09, including date/time values. No other extension types are implemented in this library, it’s only the standard types which is perfectly fine for interoperability with MessagePack codecs in other programming languages.,I’m using the , library on the server side in my .NET applications.,MessagePack is an efficient binary serialisation format. It lets you exchange data among multiple languages like JSON. But it’s faster and smaller. Small integers are encoded into a single byte, and typical short strings require only one extra byte in addition to the strings themselves.,This library is very lightweight. The source code has around , (incl. browser/Node detection), the minified file has 7.0 kB and can be GZip-compressed to ,.,The file msgpack-tests.html contains some tests and a benchmark function that compares this library with ,. Here are the results, in milliseconds (lower is better). All tests done on an Intel Core i7-3770 and Windows 10.,The numbers show that this library is comparable with msgpack-lite. In Chrome it’s only 10% slower. But serializing in Firefox and deserializing in Microsoft browsers is twice as fast.,In browsers, a global , object is created that contains the functions , and ,. The first can be called with any data and returns the serialized bytes. The second works in reverse, taking the serialized bytes and returning the runtime value.,Include the JavaScript file into your HTML document like this:,You can use the library functions after loading the script.,If there should be a naming conflict with another library you want to load, you can change the global object name from , to something else by setting , before loading the script file:,In Node.js, these functions are exported in the object you get from the , function.,Here’s a simple example:,You can also use the functions , and , which are aliases to , and ,. This makes it easier to replace other libraries that use these function names with msgpack.js.,New projects should use the preferred (and more precisely named) , and , functions though.,
,
,
,
,
,
,The msgpackr package is an extremely fast MessagePack NodeJS/JavaScript implementation. Currently, it is significantly faster than any other known implementations, faster than Avro (for JS), and generally faster than native V8 JSON.stringify/parse, on NodeJS. It also includes an optional record extension (the , in msgpackr), for defining record structures that makes MessagePack even faster and more compact, often over twice as fast as even native JSON functions, several times faster than other JS implementations, and 15-50% more compact. See the performance section for more details. Structured cloning (with support for cyclical references) is also supported through optional extensions.,Install with:,And , or , it for basic standard serialization/encoding (,) and deserialization/decoding (,) functions:,This , function will generate standard MessagePack without any extensions that should be compatible with any standard MessagePack parser/decoder. It will serialize JavaScript objects as MessagePack ,s by default. The , function will deserialize MessagePack ,s as an , with the properties from the map.,The msgpackr package runs on any modern JS platform, but is optimized for NodeJS usage (and will use a node addon for performance boost as an optional dependency).,We can use the including streaming functionality (which further improves performance). The , is a NodeJS transform stream that can be used to serialize objects to a binary stream (writing to network/socket, IPC, etc.), and the , can be used to deserialize objects from a binary sream (reading from network/socket, etc.):,Or for a full example of sending and receiving data on a stream:,The , and , instances  will have also the record structure extension enabled by default (see below).,Msgpackr modules are standard ESM modules and can be loaded directly from the , for use in Deno. The standard pack/encode and unpack/decode functionality is available on Deno, like other platforms.,Msgpackr works as standalone JavaScript as well, and runs on modern browsers. It includes a bundled script, at , for ease of direct loading:,This is UMD based, and will register as a module if possible, or create a , global with all the exported functions.,For module-based development, it is recommended that you directly import the module of interest, to minimize dependencies that get pulled into your application:,The package also includes a minified bundle in index.min.js.
Additionally, the package includes a version that excludes dynamic code evaluation called index-no-eval.js, for situations where Content Security Policy (CSP) forbids eval/Function in code. The dynamic evaluation provides important performance optimizations (for records), so is not recommended unless required by CSP policy.,You can also use msgpackr for ,. By enabling the , option, you can include references to other objects or cyclic references, and object identity will be preserved. Structured cloning also enables preserving certain typed objects like ,, ,, , and TypedArray instances. For example:,This option is disabled by default because it uses extensions and reference checking degrades performance (by about 25-30%). (Note this implementation doesn't serialize every class/type specified in the HTML specification since not all of them make sense for storing across platforms.),If you prefer to use encoder/decode terminology, msgpackr exports aliases, so , is equivalent to ,, , is ,, , is ,, , is ,, and , and , can be used as well.,There is a critical difference between maps (or dictionaries) that hold an arbitrary set of keys and values (JavaScript , is designed for these), and records or object structures that have a well-defined set of fields. Typical JS objects/records may have many instances re(use) the same structure. By using the record extension, this distinction is preserved in MessagePack and the encoding can reuse structures and not only provides better type preservation, but yield much more compact encodings and increase decoding performance by 2-3x. Msgpackr automatically generates record definitions that are reused and referenced by objects with the same structure. There are a number of ways to use this to our advantage. For large object structures with repeating nested objects with similar structures, simply serializing with the record extension can yield significant benefits. To use the record structures extension, we create a new , instance. By default a new , instance will have the record extension enabled:,Another way to further leverage the benefits of the msgpackr record structures is to use streams that naturally allow for data to reuse based on previous record structures. The stream classes have the record structure extension enabled by default and provide excellent out-of-the-box performance.,When creating a new ,, ,, ,, or , instance, we can enable or disable the record structure extension with the , property. When this is ,, the record structure extension will be disabled (standard/compatibility mode), and all objects will revert to being serialized using MessageMap ,s, and all ,s will be deserialized to JS ,s as properties (like the standalone , and , functions).,Streaming with record structures works by encoding a structure the first time it is seen in a stream and referencing the structure in later messages that are sent across that stream. When an encoder can expect a decoder to understand previous structure references, this can be configured using the , flag, which is auto-enabled by streams, but can also be used with Packr instances.,Another useful way of using msgpackr, and the record extension, is for storing data in a databases, files, or other storage systems. If a number of objects with common data structures are being stored, a shared structure can be used to greatly improve data storage and deserialization efficiency. In the simplest form, provide a , array, which is updated if any new object structure is encountered:,If you are working with persisted data, you will need to persist the , data when it is updated. Msgpackr provides an API for loading and saving the , on demand (which is robust and can be used in multiple-process situations where other processes may be updating this same , array), we just need to provide a way to store the generated shared structure so it is available to deserialize stored data in the future:,Msgpackr will automatically add and saves structures as it encounters any new object structures (up to a limit of 32, by default). It will always add structures in an incremental/compatible way: Any object encoded with an earlier structure can be decoded with a later version (as long as it is persisted).,By default there is a limit of 32 shared structures. This default is designed to record common shared structures, but also be resilient against sharing too many structures if there are many objects with dynamic properties that are likely to be repeated. This also allows for slightly more efficient one byte encoding. However, if your application has more structures that are commonly repeated, you can increase this limit by setting , to a higher value. The maximum supported shared structures is 8160.,You can also provide a , function in the options if you want to specifically indicate which structures should be shared. This is called during the encoding process with the array of keys for a structure that is being considered for addition to the shared structure. For example, you might want:,If you have a buffer with multiple values sequentially encoded, you can choose to parse and read multiple values. This can be done using the , function/method, which can return an array of all the values it can sequentially parse within the provided buffer. For example:,Alternately, you can provide a callback function that is called as the parsing occurs with each value, and can optionally terminate the parsing by returning ,:,The following options properties can be provided to the Packr or Unpackr constructor:,By default all non-integer numbers are serialized as 64-bit float (double). This is fast, and ensures maximum precision. However, often real-world data doesn't not need 64-bits of precision, and using 32-bit encoding can be much more space efficient. There are several options that provide more efficient encodings. Using the decimal rounding options for encoding and decoding provides lossless storage of common decimal representations like 7.99, in more efficient 32-bit format (rather than 64-bit). The , property has several possible options, available from the module as constants:,Note, that the performance is decreased with decimal rounding by about 20-25%, although if only 5% of your values are floating point, that will only have about a 1% impact overall.,In addition, msgpackr exports a , function that can be used to round floating point numbers to the maximum significant decimal digits that can be stored in 32-bit float, just as DECIMAL_ROUND does when decoding. This can be useful for determining how a number will be decoded prior to encoding it.,Msgpackr employs an optional native node-addon to accelerate the parsing of strings. This should be automatically installed and utilized on NodeJS. However, you can verify this by checking the , property that is exported from msgpackr. If this is ,, the , package may not have been properly installed, and you may want to verify that it is installed correctly:,Msgpackr is fast. Really fast. Here is comparison with the next fastest JS projects using the benchmark tool from , (and the sample data is from some clinical research data we use that has a good mix of different value types and structures). It also includes comparison to V8 native JSON functionality, and JavaScript Avro (,, a very optimized Avro implementation):,All benchmarks were performed on Node 15 / V8 8.6 (Windows i7-4770 3.4Ghz).
(, is schema-based and more comparable in style to msgpackr with shared structures).,Here is a benchmark of streaming data (again borrowed from ,'s benchmarking), where msgpackr is able to take advantage of the structured record extension and really demonstrate its performance capabilities:,See the , for more benchmarks and information about benchmarking.,You can add your own custom extensions, which can be used to encode specific types/classes in certain ways. This is done by using the , function, and specifying the class, extension , code (should be a number from 1-100, reserving negatives for MessagePack, 101-127 for msgpackr), and your , and , functions (or just the one you need).,If you want to use msgpackr to encode and decode the data within your extensions, you can use the , and , functions and read and write data/objects that will be encoded and decoded by msgpackr, which can be easier and faster than creating and receiving separate buffers:,Note that you can just return the same object from ,, and in this case msgpackr will encode it using the default object/array encoding:,You can also create an extension with , and , methods, but no , (or ,), if you just want to customize how a class is serialized without using MessagePack extension encoding.,Msgpackr is already fast, but here are some tips for making it faster:,Msgpackr is designed to work well with reusable buffers. Allocating new buffers can be relatively expensive, so if you have Node addons, it can be much faster to reuse buffers and use memcpy to copy data into existing buffers. Then msgpackr , can be executed on the same buffer, with new data, and optionally take a second paramter indicating the effective size of the available data in the buffer.,During the serialization process, data is written to buffers. Again, allocating new buffers is a relatively expensive process, and the , method can help allow reuse of buffers that will further improve performance. With , method, you can provide a buffer, serialize data into it, and when it is known that you are done using that buffer, you can call , again to reuse it. The use of , is never required, buffers will still be handled and cleaned up through GC if not used, it just provides a small performance boost.,The record struction extension uses extension id 0x72 (""r"") to declare the use of this functionality. The extension ""data"" byte (or bytes) identifies the byte or bytes used to identify the start of a record in the subsequent MessagePack block or stream. The identifier byte (or the first byte in a sequence) must be from 0x40 - 0x7f (and therefore replaces one byte representations of positive integers 64 - 127, which can alternately be represented with int or uint types). The extension declaration must be immediately follow by an MessagePack array that defines the field names of the record structure.,Once a record identifier and record field names have been defined, the parser/decoder should proceed to read the next value. Any subsequent use of the record identifier as a value in the block or stream should parsed as a record instance, and the next n values, where is n is the number of fields (as defined in the array of field names), should be read as the values of the fields. For example, here we have defined a structure with fields ""foo"" and ""bar"", with the record identifier 0x40, and then read a record instance that defines the field values of 4 and 2, respectively:,Which should generate an object that would correspond to JSON:,msgpackr supports , (using fixext1 + type: 0 + data: 0 to match other JS implementations), ,, ,, and , (using standard IEEE 754 representations with doubles/floats).,msgpackr saves all JavaScript ,s using the standard MessagePack date extension (type -1), using the smallest of 32-bit, 64-bit or 96-bit format needed to store the date without data loss (or using 32-bit if useTimestamp32 options is specified).,With structured cloning enabled, msgpackr will also use extensions to store Set, Map, Error, RegExp, ArrayBufferView objects and preserve their types.,The high-performance serialization and deserialization algorithms in the msgpackr package are also available in the , for the CBOR format, with the same API and design. A quick summary of the pros and cons of using MessagePack vs CBOR are:,MIT,MessagePack can be a great choice for high-performance data delivery to browsers, as reasonable data size is possible without compression. And msgpackr works very well in modern browsers. However, it is worth noting that if you want highly compact data, brotli or gzip are most effective in compressing, and MessagePack's character frequency tends to defeat Huffman encoding used by these standard compression algorithms, resulting in less compact data than compressed JSON.,Various projects have been inspirations for this, and code has been borrowed from , and ,., , , , ,This is a JavaScript/ECMA-262 implementation of ,, an efficient binary serilization format:,This library is a universal JavaScript, meaning it is compatible with all the major browsers and NodeJS. In addition, because it is implemented in ,, type definition files (,) are always up-to-date and bundled in the distribution.,This library is published to , as ,.,It encodes , into a single MessagePack-encoded object, and returns a byte array as ,. It throws errors if , is, or includes, a non-serializable object such as a , or a ,.,for example:,If you'd like to convert an , to a NodeJS ,, use , in order not to copy the underlying ,, while , copies it:,It decodes , that includes a MessagePack-encoded object, and returns the decoded object typed ,., must be an array of bytes, which is typically , or ,. , is defined as ,.,The , must include a single encoded object. If the , includes extra bytes after an object or the , is empty, it throws ,. To decode , that includes multiple encoded objects, use , or , (recommended) instead.,for example:,NodeJS , is also acceptable because it is a subclass of ,.,You can use , to limit the length of each type decoded.,It decodes , that includes multiple MessagePack-encoded objects, and returns decoded objects as a generator. See also ,, which is an asynchronous variant of this function.,This function is not recommended to decode a MessagePack binary via I/O stream including sockets because it's synchronous. Instead, , decodes a binary stream asynchronously, typically spending less CPU and memory.,for example:,It decodes ,, where , is defined as ,, in an async iterable of byte arrays, and returns decoded object as , type, wrapped in ,.,This function works asynchronously, and might CPU resources more efficiently compared with synchronous ,, because it doesn't wait for the completion of downloading., is the same as , for ,.,This function is designed to work with whatwg , like this:,It is alike to ,, but only accepts a , that includes an array of items, and emits a decoded item one by one.,for example:,It is alike to , and ,, but the input , must consist of multiple MessagePack-encoded items. This is an asynchronous variant for ,.,In other words, it could decode an unlimited stream and emits a decoded item one by one.,for example:,This function is available since v2.4.0; previously it was called as ,., and , classes is provided to have better performance by reusing instances:,According to our benchmark, reusing , instance is about 20% faster
than , function, and reusing , instance is about 2% faster
than , function. Note that the result should vary in environments
and data structure.,To handle ,, this library provides , class.,This is an example to setup custom extension types that handles , and , classes in TypeScript:,Not that extension types for custom objects must be ,, while , is reserved for MessagePack itself.,When you use an extension codec, it might be necessary to have encoding/decoding state to keep track of which objects got encoded/re-created. To do this, pass a , to the , and ,:,This library does not handle BigInt by default, but you can handle it with , like this:,There is a proposal for a new date/time representations in JavaScript:,This library maps , to the MessagePack timestamp extension by default, but you can re-map the temporal module (or ,) to the timestamp extension like this:,This will become default in this library with major-version increment, if the temporal module is standardized., is a binary data container provided by browsers. To read its contents, you can use , or ,. ,
is recommended if your target platform support it. This is because streaming
decode should be faster for large objects. In both ways, you need to use
asynchronous API.,This library is compatible with the ""August 2017"" revision of MessagePack specification at the point where timestamp ext was added:,The living specification is here:,Note that as of June 2019 there're no official ""version"" on the MessagePack specification. See , for the discussions.,The following table shows how JavaScript values are mapped to , and vice versa.,This is a universal JavaScript library that supports major browsers and NodeJS.,ES2018 standard library used in this library can be polyfilled with ,.,If you support IE11, import , in your application entrypoints, as this library does in testing for browsers.,NodeJS v10 is required, but NodeJS v12 or later is recommended because it includes the V8 feature of ,.,NodeJS before v10 will work by importing ,.,This module requires type definitions of ,, ,, whatwg streams, and so on. They are provided by , in ,.,Regarding the TypeScript compiler version, only the latest TypeScript is tested in development.,Run-time performance is not the only reason to use MessagePack, but it's important to choose MessagePack libraries, so a benchmark suite is provided to monitor the performance of this library.,V8's built-in JSON has been improved for years, esp. , is ,, it is the fastest deserializer as of 2019, as the benchmark result bellow suggests.,However, MessagePack can handles binary data effectively, actual performance depends on situations. You'd better take benchmark on your own use-case if performance matters.,Benchmark on NodeJS/v18.1.0 (V8/10.1),Note that , cases use , to emulate I/O where a JavaScript string must be converted into a byte array encoded in UTF-8, whereas MessagePack modules deal with byte arrays.,The NPM package distributed in npmjs.com includes both ES2015+ and ES5 files:,If you use NodeJS and/or webpack, their module resolvers use the suitable one automatically.,This library is available via CDN:,It loads , module to the global object.,You can use this module on Deno.,See , for examples., is not supported yet.,For simple testing:,This library uses Travis CI.,test matrix:,See , and , for details.,Copyright 2019 The MessagePack community.,This software uses the ISC license:,See , for details.,Ultra-fast MessagePack for NodeJS & Browsers.,MIT | @davalapar,Optional Retrofit support:,This is a Kotilin implementation of MessagePack serialization and deserialization built ontop of Moshi to take advantage of Moshi's type adapters and utilizes okio for reading and writing MessagePack bytes.,The library is intended to be consumed in a Kotlin project, and is not intended for Java use.,Inspired by Kaushik Gopal's ,See , for adapter usage and reference.,This prints the MessagePack bytes as a hex string ,If you prefer to not instantiate a , instance you can access the API in a static fashion as well. Note this will create a new , instance every time you make an API call. You may want to use the API this way if you aren't providing , by some form of dependency injection and you do not have any specific builder parameters for ,See , for further reference.,Serializes an object into MessagePack. , ,Instance version:,Static version:,If you prefer to get a , instead of a , you can use this method.,Instance version only,Static can be done,Deserializes MessagePack bytes into an Object. , ,
Works with , and ,Instance version:,Static version:,Instance version:,Static version:,T can be an Object, a List, a Map, and can include generics. Unlike , you do not need to specify a parameterized type to deserialize to a List with generics. , can infer the paramterized type for you.,The following examples are valid for ,:,A typed List,A List of Any,An Object,A Map of Any, Any,Convert directly from MessagePack bytes to JSON. Use this method for the most effecient implementation as no objects are instantiated in the process. This uses the , class to match implementations of , and a ,. If you wanted to say support XML as a direct conversion to and from, you could implement Moshi's , and , classes and use the , class to convert directly to other formats. , , containing a JSON representation of the MessagePack data,Instance versions: (takes , or ,),Static versions: (takes , or ,),Convert directly from JSON to MessagePack bytes. Use this method for the most effecient implementation as no objects are instantiated in the process. , ,Instance versions: (takes , or ,),Static versions: (takes , or ,),The , constructor takes an optional , lambda which is applied to the builder that is used to instantiate the , instance it uses.,Example adding custom adapter:, is also a settable property which can be changed on a , instance:,The static version of the API also can be passed a lambda to applied to the , used to instantiate ,:,This will force all integers to be packed as the type given.
By default the smallest message pack type is used for integers.,Since this library is intended for Kotlin use, the , artifact is included as a depedency. A , is added by default to the instantiated , that , uses.
This adapter allows for the use of ,'s annotaions in Kotlin. To learn more about it see the , documentation.,If you'd like to use , with out a , supply a , instance for ,:,From ,'s README.md;
If you are using ProGuard you might need to add the following options:,An example of using the retorfit adapter can be found here:
, is an efficient binary serialization format.,It lets you exchange data among multiple languages like JSON but it's faster and smaller.,It's a pure Lua implementation, without dependency.,And it's really fast with ,.,The homepage is at ,,
and the sources are hosted at ,.,Copyright (c) 2012-2013 Francois Perrad,This library is licensed under the terms of the MIT/X11 license, like Lua itself.,This is a pure Lua implementation for encoding/decoding MessagePack (,).,Please report any bugs you encounter!,Features:,What's missing:,Example code:,Encodes the given Lua value to a binary MessagePack representation. It will return the binary string on succes or , plus an error message if it fails.,The encoder will encode Lua strings as MessagePack strings when they are properly UTF-8 encoded otherwise they will become MessagePack binary objects.,There is also a check if a Lua number can be lossless encoded as a 32-bit float., Empty Lua tables will be encoded as empty arrays!,Encodes all given values to a binary MessagePack representation. It will return the binary string or , plus an error message if it fails.,Decode the given MessagePack binary string to a corresponding Lua value. It will return the decoded Lua value and the position for next byte in stream
or , plus an error message if decoding went wrong. You can use the returned position to decode multiple MessagePack values in a stream.,The optional position argument is used to start the decoding at a specific position inside the the binary_data string., Extended types are not supported. Decoding will fail!, Binary data will be decoded as Lua strings, Arrays will be decoded as Lua tables starting with index 1 (like Lua uses tables as arrays), Values which are , will cause the key, value pair to disappear in a Lua table (that's how it works in Lua),Decode the given MessagePack binary string to one or more Lua values. It will return all decoded Lua values or , plus an error message if decoding failed.,The code is written in pure Matlab, and has no dependencies beyond Matlab itself. And it works in recent versions of Octave, too.,The files in this repository are taken from ,.,There is no way of encoding exts,Note that since , don't support arbitrary field names, they can't be used for representing ,. We use , instead.,MATLAB (R) is copyright of the Mathworks,Copyright (c) 2014 Bastian Bechtold
All rights reserved.,Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:,Redistributions of source code must retain the above copyright
notice, this list of conditions and the following disclaimer.,Redistributions in binary form must reproduce the above copyright
notice, this list of conditions and the following disclaimer in the
documentation and/or other materials provided with the
distribution.,Neither the name of the copyright holder nor the names of its
contributors may be used to endorse or promote products derived
from this software without specific prior written permission.,THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.,I will start this project once Nim compiler reaches 1.0,A MessagePack binding for Nim,API: ,msgpack-nim currently provides only the basic functionality.
Please see what's listed in Todo section. Compared to other language bindings, it's well-tested by
1000 auto-generated test cases by Haskell QuickCheck, which always runs
on every commit to Github repository. Please try , on your local machine
to see what happens (It will take a bit while. Be patient). Have a nice packing!,Akira Hayakawa (,), implementation written in pure nim,I am fully aware of , msgpack implementation written in nim.
But I want something easier to use. Another motivation come from the nim language itself.
The current version of nim compiler offer many improvements, including 'generics ' specialization.
I found out nim compiler is smart enough to make serialization/deserialization to/from msgpack easy and convenient., nim ver 0.18.1 or later,
,
,
,see? you only need to call 'pack' and 'unpack', and the compiler do the hard work for you. Very easy, convenient, and works well,if you think setting up a MsgStream too much for you, you can simply call pack(yourobject) and it will return a string containing msgpack data.,in case the compiler cannot decide how to serialize or deserialize your very very complex object, you can help it in easy way
by defining your own handler pack_type/unpack_type,If distinct types encountered, it will be converted back to it's base type.
If you don't like this behavior, since version 0.2.9 msgpack4nim allow you
to override this default behavior by supplying your own implementation of
, and ,.,object and tuple by default converted to msgpack array, however
you can tell the compiler to convert it to map by supplying --define:msgpack_obj_to_map,or --define:msgpack_obj_to_stream to convert object/tuple fields , into stream of msgpack objects,What this means? It means by default, each object/tuple will be converted to one , contains
field(s) value only without their field(s) name.,If you specify that the object/tuple will be converted to ,, then each object/tuple will be
converted to one , contains key-value pairs. The key will be field name, and the value will be field value.,If you specify that the object/tuple will be converted to msgpack stream, then each object/tuple will be converted
into one or more msgpack's type for each object's field and then the resulted stream will be concatenated
to the msgpack stream buffer.,Which one should I use?,Usually, other msgpack libraries out there convert object/tuple/record/struct or whatever structured data supported by
the language into ,, but always make sure to consult the documentation first.
If both of the serializer and deserializer agreed to one convention, then usually there will be no problem.
No matter which library/language you use, you can exchange msgpack data among them.,since version 0.2.4, you can set encoding mode at runtime to choose which encoding you would like to perform,note: the runtime encoding mode only available if you use MsgStream, otherwise only compile time flag available, :,:
altough detecting circular reference is not too difficult(using set of pointers),
the current implementation does not provide circular reference detection.
If you pack something contains circular reference, you know something bad will happened,:
For objects their type is , serialized.
This means essentially that it does not work if the object has some other runtime type than its compiletime type:,these types will be ignored:,these types cannot be automatically pack/unpacked:,however, you can provide your own handler for cstring and pointer,
because data conversion did not preserve original data types(only partial preservation),
the following code is perfectly valid and will raise no exception,another gotcha:,this implementation provide function to encode/decode msgpack bin/ext format header,
but for the body, you must write it yourself or read it yourself to/from the MsgStream,you can convert msgpack data to readable string using stringify function,the result will be:, takes a string of msgpack data or a stream, then it will produce ,
which you can interrogate of it's  type and value during runtime by accessing it's member , recognize all valid msgpack message and translate it into a group of types:,for example, , is a , data with content [1, ""hello"", {""a"": ""b""}], you can interrogate it like this:,since version 0.2.1, toAny was put into separate module ,,
it has functionality similar with json, with support of msgpack bin and ext natively,msgpack2any also support pretty printing similar with json pretty printing.,Primary usage for msgpack2any is to provide higher level API while dynamically querying underlying msgpack data at runtime.
Currently, msgpack2any decode all msgpack stream at once. There are room for improvements such as progressive decoding at
runtime, or selective decoding at runtime. Both of this improvements are not implemented, yet they are important for applications
that need for finer control over decoding step.,Start version 0.2.0, msgpack4nim receive additional family member, , module.
It consists of , and , to interact with stdlib's json module.,nimble install msgpack4nim,If an object can be represented in multiple possible output formats,
serializers SHOULD use the format which represents the data in the smallest number of bytes.,According to the spec, the serializer should use smallest number of bytes, and this behavior
is implemented in msgpack4nim. Therefore, some valid encoding would never produced by msgpack4nim.,For example: although 0xcdff00 and 0xceff000000 encoding is valid according to the spec which is decoded into positive integer 255,
msgpack4nim never produce it, because the internal algorithm will select the smallest number of bytes needed, which is 0xccff.,However, if msgpack4nim received encoded streams from other msgpack library contains those longer than needed sequence, as long as
it conforms to the spec, msgpack4nim will happily decoded it and convert it to the destination storage(variable) type.,Other msgpack library who consume msgpack4nim stream, will also decode it properly, although they might not produce smallest number
of bytes required.,enjoy it, happy nim-ing,A msgpack v5 implementation for node.js and the browser, with extension point support.,This library is compatible with ,.,If you want to use standalone, grab the file in the , folder of
this repo, and use in your own HTML page, the module will expose a
, global.,Creates a new instance on which you can register new types for being
encoded.,options:,Encodes , in msgpack, returns a ,.,Decodes buf from in msgpack. , can be a , or a , instance.,In order to support a stream interface, a user must pass in a , instance.,Register a new custom object type for being automatically encoded.
The arguments are:,Register a new custom object type for being automatically decoded.
The arguments are:,Register a new custom object type for being automatically encoded and
decoded. The arguments are:,This is just a commodity that calls
, and
, internally.,Builds a stream in object mode that encodes msgpack.,Supported options:,Builds a stream in object mode that decodes msgpack.,Supported options:, can be used as a LevelUp
, straight away:,This library is built fully on JS and on , to
simplify the code. Every improvement that keeps the same API is welcome.,This project was kindly sponsored by ,.,This library was originally built as the data format for
,.,MIT,
,
,
,An implementation of , middleware for ,.,With auto-detection and transformation enabled, the middleware detects automatically the HTTP header , and piggybacks the , method of the ExpressJS API, to encode the JSON response as Message Pack. This method is useful when you have existing applications that need to use the middleware, without changing the codebase very much.,Note: Remember to add the header , in the request.,Also, it can have auto-detection and transformation disabled. The middleware extends the , object of the ExpressJS framework, by adding the , method to it. Then to return an encoded response, you just use the , method that accepts the Javascript object as a parameter. For example,,Note: Initialize the middleware before the actual routes in the middleware chain to properly extend the , Object.,Node.js >= 6.0,With , do:,I , open source software!,Check out my other , or say , on ,.,Contributions are welcome ,. Please see the , and the ,.,See also the list of , who participated in this project.,msgpack-response is available under the MIT license. See the , file for more info.,See also, ,Setup development enviroment with docker:,If you want to use msgpack at OCaml, you need not do this section.
This section for user intrested in formal verification.,You need Coq 8.4 and omake.,Or via ,.,If you need to use an ordered dictionary.,This extension provides an API for communicating with MessagePack serialization.,MessagePack is a binary-based efficient object serialization library.
It enables to exchange structured objects between many languages just like JSON.
But unlike JSON, it is very fast and small.,Msgpack is an PECL extension, thus you can simply install it by:,
,
,A pure PHP implementation of the , serialization format.,The recommended way to install the library is through ,:,To pack values you can either use an instance of a ,:,or call a static method on the , class:,In the examples above, the method , automatically packs a value depending on its type. However, not all PHP types
can be uniquely translated to MessagePack types. For example, the MessagePack format defines , and , types,
which are represented by a single , type in PHP. By default, the packer will pack a PHP array as a MessagePack
array if it has sequential numeric keys, starting from , and as a MessagePack map otherwise:,However, sometimes you need to pack a sequential array as a MessagePack map.
To do this, use the , method:,Here is a list of type-specific packing methods:,The , object supports a number of bitmask-based options for fine-tuning
the packing process (defaults are in bold):,Examples:,To unpack data you can either use an instance of a ,:,or call a static method on the , class:,If the packed data is received in chunks (e.g. when reading from a stream), use the , method, which attempts
to unpack data and returns an array of unpacked messages (if any) instead of throwing an ,:,If you want to unpack from a specific position in a buffer, use ,:,To skip bytes from the current position, use ,:,To get the number of remaining (unread) bytes in the buffer:,To check whether the buffer has unread data:,If needed, you can remove already read data from the buffer by calling:,With the , method you can read raw (packed) data:,Besides the above methods , provides type-specific unpacking methods, namely:,The , object supports a number of bitmask-based options for fine-tuning
the unpacking process (defaults are in bold):,Examples:,In addition to the ,, the library
provides functionality to serialize and deserialize arbitrary types. This can be done in several ways, depending
on your use case. Let's take a look at them.,If you need to , an instance of one of your classes into one of the basic MessagePack types, the best way
to do this is to implement the , interface in the class. A good example of such
a class is the , type class that comes with the library. This type is useful when you want to explicitly specify
that a given PHP array should be packed as a MessagePack map without triggering an automatic type detection routine:,As with type objects, type transformers are only responsible for , values. They should be
used when you need to serialize a value that does not implement the ,
interface. Examples of such values could be instances of built-in or third-party classes that you don't
own, or non-objects such as resources.,A transformer class must implement the , interface. To use a transformer,
it must first be registered in the packer. Here is an example of how to serialize PHP streams into
the MessagePack , format type using one of the supplied transformers, ,:,In contrast to the cases described above, extensions are intended to handle
,
and are responsible for both , and , of values (types).,An extension class must implement the , interface. To use an extension,
it must first be registered in the packer and the unpacker.,The MessagePack specification divides extension types into two groups: , and ,.
Currently, there is only one predefined type in the specification, Timestamp.,The Timestamp extension type is a ,
type. Support for this type in the library is done through the , class. This class is responsible
for handling , objects, which represent the number of seconds and optional adjustment in nanoseconds:,When using the , class, the Timestamp extension is already registered:,In addition, the format can be extended with your own types. For example, to make the built-in PHP , objects
first-class citizens in your code, you can create a corresponding extension, as shown in the ,.
Please note, that custom extensions have to be registered with a unique extension ID (an integer from , to ,).,If an error occurs during packing/unpacking, a , or an ,
will be thrown, respectively. In addition, an , can be thrown during unpacking.,An , will be thrown in case an invalid option (or a combination of mutually
exclusive options) is used.,Run tests as follows:,Also, if you already have Docker installed, you can run the tests in a docker container. First, create a container:,The command above will create a container named , with PHP 8.1 runtime. You may change the default runtime
by defining the , environment variable:,Then run the unit tests:,To ensure that the unpacking works correctly with malformed/semi-malformed data, you can use a testing technique
called ,. The library ships with a help file (target)
for , and can be used as follows:,To check performance, run:,You may change default benchmark settings by defining the following environment
variables:,For example:,Another example, benchmarking both the library and the ,:,The library is released under the MIT License. See the bundled , file for details.,It's like JSON but small and fast.,first release
2014-08-15 13:05:13,add array support
2014-08-19 12:18:47,add andriod support
2014-09-08 00:45:27,fix  asVariant = null (thanks for cyw(26890954))
2014-11-14 09:05:52,fix AsInteger = -1 bug (thanks for cyw(26890954))
2014-11-14 12:15:52,fix AsInteger = -127 bug
check int64/integer/cardinal/word/shortint/smallint/byte assign, encode,decode, read
2014-11-14 12:30:38,fix AsFloat = 2.507182 bug
thanks fo [珠海]-芒果  1939331207
2014-11-21 12:37:04,add AddArrayChild func
2015-03-25 17:47:28,add remove/removeFromParent/Delete function
2015-08-29 22:37:48,Data::MessagePack - MessagePack serializing/deserializing,This module converts Perl data structures to MessagePack and vice versa.,MessagePack is a binary-based efficient object serialization format.
It enables to exchange structured objects between many languages like
JSON.  But unlike JSON, it is very fast and small.,PORTABLE,The MessagePack format does not depend on language nor byte order.,SMALL IN SIZE,The MessagePack format saves memory than JSON and Storable format.,STREAMING DESERIALIZER,MessagePack supports streaming deserializer. It is useful for
networking such as RPC.  See , for
details.,If you want to get more information about the MessagePack format,
please visit to ,.,Pack the $data to messagepack format string.,This method throws an exception when the perl structure is nested more
than $max_depth levels(default: 512) in order to detect circular
references.,Data::MessagePack->pack() throws an exception when encountering a
blessed perl object, because MessagePack is a language-independent
format.,unpack the $msgpackstr to a MessagePack format string.,Creates a new MessagePack instance.,If , is true (or missing), then the , method tries a
string as an integer if the string looks like an integer.,If , is true (or missing), then the , method will output
packed data by sorting their keys. This is adding a comparatively high
overhead.,If , is true (or missing), then the , method will
apply , to all the string values.,In other words, this property tell , to deal with ,.
See , for the meaning of ,.,Same as ,, but properties are respected.,Same as ,, but properties are respected.,$Data::MessagePack::PreferInteger,Packs a string as an integer, when it looks like an integer.,This variable is ,.
Use , property instead.,This is a result of , and ,
on my SC440(Linux 2.6.32-23-server #37-Ubuntu SMP).
(You should benchmark them with , data if the speed matters, of course.),This module can unpack 64 bit integers even if your perl does not support them
(i.e. where , is 4), but you cannot calculate these values
unless you use ,.,Error handling,MessagePack cannot deal with complex scalars such as object references,
filehandles, and code references. We should report the errors more kindly.,Streaming deserializer,The current implementation of the streaming deserializer does not have internal
buffers while some other bindings (such as Ruby binding) does. This limitation
will astonish those who try to unpack byte streams with an arbitrary buffer size
(e.g. ,).
We should implement the internal buffer for the unpacker.,Why does Data::MessagePack have pure perl implementations?,msgpack C library uses C99 feature, VC++6 does not support C99. So pure perl version is needed for VC++ users.,Tokuhiro Matsuno,Makamaka Hannyaharamitu,gfx,Jun Kuriyama,Dan Kogai,FURUHASHI Sadayuki,hanekomu,Kazuho Oku,syohex,This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself., is the official web site for the  MessagePack format.,Data::MessagePack - Perl 6 implementation of MessagePack,Or for streaming:,The present module proposes an implemetation of the MessagePack specification as described on ,. The implementation is now in Pure Perl which could come as a performance penalty opposed to some other packer implemented in C.,There are already some part of MessagePack implemented in Perl6, with for instance MessagePack available here: ,, however that module only implements the unpacking part of the specification. Futhermore, that module uses the unpack functionality which is tagged as experimental as of today,That function takes a data structure as parameter, and returns a Blob with the packed version of the data structure.,That function takes a MessagePack packed message as parameter, and returns the deserialized data structure.,Pierre VIGIER,Timo Paulssen,Artistic License 2.0,A pure Pony implementation of the ,.,msgpack is currently beta software. It implements a low-level API for encoding and decoding data. Still to do:,MessagePack implementation for PostgreSQL written in PL/pgSQL.,Execute , or/and , on your database server.,Encodes , object into , string.,Decodes , object from , string.,Development is sponsored by ,.,Copyright (c) 2017 Patrik Simek,The MIT License,Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ""Software""), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:,The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.,THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.,
, is an efficient binary serialization format.
It lets you exchange data among multiple languages like JSON.
But it's faster and smaller.
This package provides CPython bindings for reading and writing MessagePack data.,Package name on PyPI was changed from , to , from 0.5.,When upgrading from msgpack-0.4 or earlier, do , before
,.,You can use , option to pack ,
object into raw type in the old msgpack spec, instead of bin type in new msgpack spec.,You can unpack old msgpack format using , option.
It unpacks str (raw) type in msgpack into Python bytes.,See note below for detail.,Python 2,Packer,Unpacker,The extension module in msgpack (,) does not support
Python 2 and PyPy.,But msgpack provides a pure Python implementation (,)
for PyPy and Python 2.,When you can't use a binary distribution, you need to install Visual Studio
or Windows SDK on Windows.
Without extension, using pure Python implementation on CPython runs slowly.,NOTE: In examples below, I use , and , for users
using msgpack < 1.0. These options are default from msgpack 1.0 so you can omit them.,Use , for packing and , for unpacking.
msgpack provides , and , as an alias for compatibility with
, and ,., and , packs to a file-like object.
, and , unpacks from a file-like object., unpacks msgpack's array to Python's list, but can also unpack to tuple:,You should always specify the , keyword argument for backward compatibility.
See performance issues relating to ,_ below.,Read the docstring for other options., is a ""streaming unpacker"". It unpacks multiple objects from one
stream (or from bytes provided through its , method).,It is also possible to pack/unpack custom data types. Here is an example for
,.,'s , callback receives a dict; the
, callback may instead be used to receive a list of
key-value pairs.,It is also possible to pack/unpack custom data types using the , type.,As an alternative to iteration, , objects provide ,,
,, , and , methods. The former two
read an entire message from the stream, respectively de-serialising and returning
the result, or ignoring it. The latter two methods return the number of elements
in the upcoming container, so that each element in an array, or key-value pair
in a map, can be unpacked or skipped individually.,Early versions of msgpack didn't distinguish string and binary types.
The type for representing both string and binary types was named ,.,You can pack into and unpack from this old spec using ,
and , options.,To use the , type, pass , object to packer.,You can use it with , and ,. See below.,To unpacking data received from unreliable source, msgpack provides
two security options., (default: ,) limits the internal buffer size.
It is used to limit the preallocated list size too., (default: ,) limits the type of map keys to bytes and str.
While msgpack spec doesn't limit the types of the map keys,
there is a risk of the hashdos.
If you need to support other types for map keys, use ,.,CPython's GC starts when growing allocated object.
This means unpacking may cause useless GC.
You can use , when unpacking large message.,List is the default sequence type of Python.
But tuple is lighter than list.
You can use , while unpacking when performance is important.,u-msgpack-python is a lightweight , serializer and deserializer module written in pure Python, compatible with both Python 2 and 3, as well CPython and PyPy implementations of Python. u-msgpack-python is fully compliant with the latest ,.,u-msgpack-python is currently distributed on PyPI: , and as a single file: ,With pip:,With easy_install:,or simply drop , into your project!,Basic Example:,A more complicated example:,Streaming serialization with file-like objects:,Serializing and deserializing a raw Ext type:,Serializing and deserializing application-defined types with ,:,Serializing and deserializing application-defined types with Ext handlers:,Python standard library style names ,, ,, ,, , are also
available:,See the , for more information on options, exceptions, behavior, and testing.,u-msgpack-python is MIT licensed. See the included , file for more details.,
,ormsgpack is a fast msgpack library for Python. It is a fork/reboot of ,
It serializes faster than , and deserializes a bit slower (right now).
It supports serialization of:
,,
,,
,,
, and
, instances natively.,Its features and drawbacks compared to other Python msgpack libraries:,ormsgpack supports CPython 3.6, 3.7, 3.8, 3.9, and 3.10. ormsgpack does not support PyPy. Releases follow semantic
versioning and serializing a new object type without an opt-in flag is
considered a breaking change.,ormsgpack is licensed under both the Apache 2.0 and MIT licenses. The
repository and issue tracker is
,, and patches may be
submitted there. There is a
,
available in the repository.,To install a wheel from PyPI:,Notice that Linux environments with a , version shipped in 2018 or earlier
must first upgrade , to support , wheels.,To build a wheel, see ,.,This is an example of serializing, with options specified, and deserializing:, serializes Python objects to msgpack.,It natively serializes
,, ,, ,, ,, ,, ,, ,, ,,
,, ,, ,,
,, ,, ,, ,, and
, instances. It supports arbitrary types through ,. It
serializes subclasses of ,, ,, ,, ,,
,, and ,. It does not serialize subclasses
of , to avoid serializing , objects as arrays. To avoid
serializing subclasses, specify the option ,.,The output is a , object containing UTF-8.,The global interpreter lock (GIL) is held for the duration of the call.,It raises , on an unsupported type. This exception message
describes the invalid object with the error message
,. To fix this, specify
,.,It raises , on a , that contains invalid UTF-8.,It raises , if a , has a key of a type other than , or ,,
unless , is specified.,It raises , if the output of , recurses to handling by
, more than 254 levels deep.,It raises , on circular references.,It raises ,  if a , on a datetime object is
unsupported., is a subclass of ,. This is for compatibility
with the standard library.,To serialize a subclass or arbitrary types, specify , as a
callable that returns a supported type. , may be a function,
lambda, or callable class instance. To specify that a type was not
handled by ,, raise an exception such as ,.,The , callable may return an object that itself
must be handled by , up to 254 times before an exception
is raised.,It is important that , raise an exception if a type cannot be handled.
Python otherwise implicitly returns ,, which appears to the caller
like a legitimate value and is serialized:,To modify how data is serialized, specify ,. Each , is an integer
constant in ,. To specify multiple options, mask them together, e.g.,
,.,Serialize , objects without a , as UTC. This
has no effect on , objects that have , set.,Serialize , keys of type other than ,. This allows , keys
to be one of ,, ,, ,, ,, ,, ,,
,, ,, ,, and ,. For comparison,
the standard library serializes ,, ,, ,, , or , by
default.,These types are generally serialized how they would be as
values, e.g., , is still an RFC 3339 string and respects
options affecting it.,This option has the risk of creating duplicate keys. This is because non-,
objects may serialize to the same , as an existing key, e.g.,
,.
The last key to be inserted to the , will be serialized last and a msgpack deserializer will presumably take the last
occurrence of a key (in the above, ,). The first value will be lost.,Do not serialize the , field on , and
, instances.,Enables passthrough of big (Python) ints. By setting this option, one can set a , function for ints larger than 63 bits, smaller ints are still serialized efficiently.,Passthrough , instances to ,. This allows
customizing their output but is much slower.,Passthrough ,, ,, and , instances
to ,. This allows serializing datetimes to a custom format, e.g.,
HTTP dates:,This does not affect datetimes in , keys if using OPT_NON_STR_KEYS.,Passthrough subclasses of builtin types to ,.,This does not affect serializing subclasses as , keys if using
OPT_NON_STR_KEYS.,Passthrough tuples to ,.,Serialize , instances. For more, see
,.,Serialize , instances. Right now it ignores the config (str transformations), support might be added
later.,Serialize a UTC timezone on , instances as , instead
of ,., deserializes msgpack to Python objects. It deserializes to ,,
,, ,, ,, ,, ,, , and , objects.,, ,, , input are accepted.,ormsgpack maintains a cache of map keys for the duration of the process. This
causes a net reduction in memory usage by avoiding duplicate strings. The
keys must be at most 64 bytes to be cached and 512 entries are stored.,The global interpreter lock (GIL) is held for the duration of the call.,It raises , if given an invalid type or invalid
msgpack., is a subclass of ,., supports the , option, that is similar to original msgpack's ,.
Be aware that this option is considered unsafe and disabled by default in msgpack due to possibility of HashDoS.,ormsgpack serializes instances of , natively. It serializes
instances 40-50x as fast as other libraries and avoids a severe slowdown seen
in other libraries compared to serializing ,.,It is supported to pass all variants of dataclasses, including dataclasses
using ,, frozen dataclasses, those with optional or default
attributes, and subclasses. There is a performance benefit to not
using ,.,Dataclasses are serialized as maps, with every attribute serialized and in
the order given on class definition:,Users may wish to control how dataclass instances are serialized, e.g.,
to not serialize an attribute or to change the name of an
attribute when serialized. ormsgpack may implement support using the
metadata mapping on , attributes,
e.g., ,, if use cases are clear.,ormsgpack serializes , objects to
, format,
e.g., ""1970-01-01T00:00:00+00:00"". This is a subset of ISO 8601 and
compatible with , in the standard library., supports instances with a , that is ,,
,, a timezone instance from the python3.9+ ,
module, or a timezone instance from the third-party ,, ,, or
,/, libraries., objects must not have a ,., objects will always serialize.,Errors with , result in , being raised.,It is faster to have ormsgpack serialize datetime objects than to do so
before calling ,. If using an unsupported type such as
,, use ,.,To disable serialization of , objects specify the option
,.,To use ""Z"" suffix instead of ""+00:00"" to indicate UTC (""Zulu"") time, use the option
,.,To assume datetimes without timezone are UTC, se the option ,.,ormsgpack serializes enums natively. Options apply to their values.,Enums with members that are not supported types can be serialized using
,:,ormsgpack serializes and deserializes double precision floats with no loss of
precision and consistent rounding.,ormsgpack serializes and deserializes 64-bit integers by default. The range
supported is a signed 64-bit integer's minimum (-9223372036854775807) to
an unsigned 64-bit integer's maximum (18446744073709551615).,ormsgpack natively serializes , and individual ,,
,, ,, ,, ,, ,,
,, and , instances. Arrays may have a
, of ,, ,, ,, ,,
,, ,, ,, ,, or ,.
ormsgpack is faster than all compared libraries at serializing
numpy instances. Serializing numpy data requires specifying
,.,The array must be a contiguous C array (,) and one of the
supported datatypes.,If an array is not a contiguous C array or contains an supported datatype,
ormsgpack falls through to ,. In ,, , can be
specified. If an array is malformed, which is not expected,
, is raised.,
,
,
,
,ormsgpack serializes , instances to
, format, e.g.,
""f81d4fae-7dec-11d0-a765-00a0c91e6bf6"".,
ormsgpack serializes , instances natively. Currently it ignores ,.,
,
,
,
,
,
,
,The above was measured using Python 3.7.9 on Azure Linux VM (x86_64) with ormsgpack 0.2.1 and msgpack 1.0.2.,The latency results can be reproduced using , and graphs using
,.,Probably , needs to be upgraded to version 20.3 or later to support
the latest manylinux_x_y or universal2 wheel formats.,No. This requires a schema specifying what types are expected and how to
handle errors etc. This is addressed by data validation libraries a
level above this.,If someone implements it well.,To package ormsgpack requires , on the
nightly channel and the ,
build tool. maturin can be installed from PyPI or packaged as
well. This is the simplest and recommended way of installing
from source, assuming , is available from a
package manager:,This is an example of building a wheel using the repository as source,
, installed from upstream, and a pinned version of Rust:,Problems with the Rust nightly channel may require pinning a version.
, is known to be ok.,ormsgpack is tested for amd64 and aarch64 on Linux, macOS, and Windows. It
may not work on 32-bit targets. It has recommended ,
specified in , so it is recommended to either not set
, or include these options.,There are no runtime dependencies other than libc.,orjson was written by ijl <,>, copyright 2018 - 2021, licensed
under both the Apache 2 and MIT licenses.,ormsgpack was forked from orjson and is maintained by Aviram Hassan <,>, licensed
same as orjson.,For the latest source code, see , is a library for writing asynchronous
,
servers and clients in Python, using ,. Library is based on
,, but some
improvements and fixes were made.,To use UNIX sockets with Python 3 please use Twisted framework 15.3.0 and above.,Debian packages are available on project's ,.,Computation of PI using Chudnovsky algorithm in subprocess. For details,
see ,.,Example servers join to group 224.0.0.5 and listen on port 8000. Their only
method , returns its parameter.,Client joins group to 224.0.0.5, sends multicast request to group on port 8000
and waits for 5 seconds for responses. If some responses are received,
protocol callbacks with tuple of results and individual parts are checked for
errors. If no responses are received, protocol errbacks with TimeoutError.,Because there is no common way to determine number of peers in group,
MsgpackMulticastDatagramProtocol always wait for responses until waitTimeout
expires.,Full documentation is here ,Clone repository:,Packing,Unpacking:,Streaming API:,There is packers and unpackers for QColor, QTime, QDate, QDateTime, QPoint, QSize, QRect. Also you can create your own packer/unpacker methods for Qt or your own types. See , for details.,Convert to and from msgpack objects in R using the official msgpack-c API through Rcpp.,
,Msgpack EXT types are converted to raw vectors with EXT attributes containing the extension type.  The extension type must be an integer from 0 to 127.,Maps are converted to data.frames with additional class ""map"".  Map objects in R contain key and value list columns and can be simplified to named lists or named vectors.  The helper function , creates map objects that can be serialized into msgpack.,For more information on msgpack types, see ,.,See , for more examples.,The Rails way to serialize/deserialize objects with ,.
It implements the , , & , and the , , for Message Pack.,Add this line to your application's Gemfile:,And then execute:,Or install it yourself as:, converts data type using , before feeding it into ,.
Here are a few examples:,You can also use it as part of ,, similar to ,:,
,
,Retrofit Converter for MessagePack,To use, supply an instance of this converter when building your Retrofit instance.,An alternative msgpack.org implementation for Ruby and C++,RMP is a pure Rust , implementation.,
,This repository consists of three separate crates: the RMP core and two implementations to ease serializing and
deserializing Rust structs.,RMP is designed to be lightweight and straightforward. There are low-level API, which gives you
full control on data encoding/decoding process and makes no heap allocations. On the other hand
there are high-level API, which provides you convenient interface using Rust standard library and
compiler reflection, allowing to encode/decode structures using , attribute.,RMP allows to decode bytes from a buffer in a zero-copy manner easily and blazingly fast, while Rust
static checks guarantees that the data will be valid as long as the buffer lives.,RMP's error system guarantees that you never receive an error enum with unreachable variant.,This project is developed using TDD and CI, so any found bugs will be fixed without breaking
existing functionality.,for details of the module, visit:,for details of the SION serialization format, visit:,General usage is the same with msgpack-java. See this ,.,Enter the sbt console:,Here is a list of sbt commands for daily development:,For publishing to Maven central, msgpack-scala uses , plugin. Set Sonatype account information (user name and password) in the global sbt settings. To protect your password, never include this file in your project.,
,
,
,
,msgpack-cli is command line tool that converts data from JSON to , and vice versa. Also allows calling RPC methods via ,.,Debian packages and Windows binaries are available on project's
,.,Encoding/decoding:,RPC calling:,MessagePack serialization library for various Smalltalk dialects.,Sources are put as , for the neutral accesses from various Smalltalk dialects.,or:,or:,Please read ,.,You might need , on new encoder/decoder-related updates.,SwiftPack is MessagePack packer and unpacker written almost entirely in Swift.,Copyright (c) 2014 Brian Williams,This software is licensed under the terms of the MIT license.,
,
,A fast, zero-dependency MessagePack implementation written in Swift 4. Supports Apple platforms and Linux.,To use CocoaPods, add the following to your Podfile:,To use Carthage, add the following to your Cartfile:,You can easily integrate MessagePack.swift in your app with SPM. Just add MessagePack.swift as a dependency:,Alexsander Akers, ,MessagePack.swift is available under the MIT license. See the LICENSE file for more info.,YSMessagePack is a messagePack packer/unpacker written in swift (swift 3 ready). It is designed to be easy to use. YSMessagePack include following features:,1.6.2 (Dropped swift 2 support, swift 3 support only from now on),But what if we have some custom data structure to send?,YSMessagePack offer a number of different ways and options to unpack include unpack asynchronously, see the example project for detail.,To unpack a messagepacked bytearray is pretty easy:,
,
,
,
,
,
, is a , encoder & decoder for Swift and supports ,.,Add the following to your Cartfile:,Add the following to your Podfile:,Add MessagePacker as a dependency:,MessagePacker is released under the MIT license. See , for details., is an efficient binary serialization format. It lets you exchange data among multiple languages like JSON. But it's faster and smaller. Small integers are encoded into a single byte, and typical short strings require only one extra byte in addition to the strings themselves.,You can find this code and more in ,., contains simple command-line utilities for converting from , to , and vice-versa. They support options for lax parsing, lossy conversions, pretty-printing, and base64 encoding.,They can be used for dumping MessagePack from a file or web API to a human-readable format, or for converting hand-written or generated JSON to MessagePack. The lax parsing mode supports comments and trailing commas in JSON, making it possible to hand-write your app or game data in JSON and convert it at build-time to MessagePack.,To view a MessagePack file in a human-readable format for debugging purposes:,To convert a hand-written JSON file to a MessagePack file, ignoring comments and trailing commas, and allowing embedded base64 with a , prefix:,To fetch MessagePack from a web API and view it in a human-readable format:,To view the MessagePack-equivalent encoding of a JSON string:,To test a , server via netcat:,: ,, e.g. , (,): ,: , package for x86_64 in the ,; install with ,For other platforms, msgpack-tools must be built from source. Download the msgpack-tools tarball from the , (not the ""source code"" archive generated by GitHub, but the actual release package.),msgpack-tools uses CMake. A , wrapper is provided that calls CMake, so you can simply run the usual:,If you are building from the repository, you will need , to generate the man pages.,MessagePack is intended to be very close to JSON in supported features, so they can usually be transparently converted from one to the other. There are some differences, however, which can complicate conversions.,These are the differences in what objects are representable in each format:,JSON keys must be strings. MessagePack keys can be any type, including maps and arrays.,JSON supports ""bignums"", i.e. integers of any size. MessagePack integers must fit within a 64-bit signed or unsigned integer.,JSON real numbers are specified in decimal scientific notation and can have arbitrary precision. MessagePack real numbers are in IEEE 754 standard 32-bit or 64-bit binary.,MessagePack supports binary and extension type objects. JSON does not support binary data. Binary data is often encoded into a base64 string to be embedded into a JSON document.,A JSON document can be encoded in UTF-8, UTF-16 or UTF-32, and the entire document must be in the same encoding. MessagePack strings are required to be UTF-8, although this is not enforced by many encoding/decoding libraries.,By default, , and , convert in strict mode. If an object in the source format is not representable in the destination format, the converter aborts with an error. A lax mode is available which performs a ""lossy"" conversion, and base64 conversion modes are available to support binary data in JSON.,
,
,
,Check out , for progress.,This library provides , support for ,. It supports all of kotlin targets (JVM, JS, Native).,To also use timestamp support with ,, use ,:,:
Timestamp support is available in core library as well, the additional library just adds a specific serializer that can be used with , types. These are ,, , and ,.,For experimental kotlin unsigned types support, use ,:,To also use timestamp support with ,, use ,:,For experimental kotlin unsigned types support, use ,:,Library should be used in same way as any other kotlinx.serialization library. Created models are annotated with , annotation and their , can be passed to ,.,Check out ,.,MessagePack for mruby is MessagePack implimented in mruby language.,This is early vesion. Please check the methods that work in test folder.,I test MessagePack for mruby in mac OSX 10.8.4. In the future it will work in Windows and Linux OS.,Download MessagePack for mruby at the command prompt:,Add config.gem line to ,Test at the command prompt:,Build at the command prompt:,mruby-msgpack is based on ,(,),I encourage you to contribute to MessagePack for mruby!,Author : Jun Hiroe,Copyrigh : Copyright (c) 2013 Jun Hiroe,License : MIT License,Starting with Release 2.0 only mruby-3 is supported, if you are on an older version check out a commit from before 2021.,First get a working copy of , then add,to the build_conf.rb of the mruby directory,mruby-simplemsgpack searches for msgpack-c on your system, if it can find it it links against it, otherwise it builds against msgpack-c from source.
You need at least msgpack-c 1 and depending on your system also pkg-config.,For building from source you need to have cmake installed on your system, take a look at , for more information.,Objects can be packed with , or ,:,They are unpacked with ,:,A string with multiple packed values can be unpacked by handing a block to
,:,When using , with a block and passing it a incomplete packed Message
it returns the position of the first offending byte, if it was able to unpack the whole Message it returns self.
This is helpful if the given data contains an incomplete
last object and we want to continue unpacking after we have more data.,To customize how objects are packed, define an ,.,By default, MessagePack packs symbols as strings and does not convert them
back when unpacking them. Symbols can be preserved by registering an extension
type for them:,Other objects like classes can also be preserved:,For nil, true, false, Integer, Float, String, Array and Hash a registered
ext type is ignored. They are always packed according to the ,.,If you want to pack and unpack mruby blocks take a look at the , gem, it can be registered like the other extension types,It's not supported to override ,, , ignores it, same when that object is included in a Hash or Array.
This gem treats objects like ruby does, if you want to change the way your custom Class gets handled you can add ,, ,, , or , methods so it will be packed like a Hash, Array, Integer or String (in that order) then.,This is using code from ,Copyright (C) 2008-2015 FURUHASHI Sadayuki,Distributed under the Boost Software License, Version 1.0.
(See accompanying file LICENSE_1_0.txt or copy at
,),This is a command line tool to inspect/show a data serialized by ,.,Executable binary files are available from ,. Download a file for your platform, and use it.,Otherwise, you can install rubygem version on your CRuby runtime:, option is available oly with rubygem version, and unavailable with mruby binary release.,FILE is a file which msgpack binary stored. Specify , to inspect data from STDIN.
This command shows the all data contained in specified format (YAML in default).,This is an example to inspect a data from STDIN.
The data corresponds to , in JSON.,TODO: show more example,Bug reports and pull requests are welcome on GitHub at [,].,
,zerorpc is a flexible RPC implementation based on zeromq and messagepack. Service APIs exposed with zerorpc are called ""zeroservices"".,General purpose C++ library for Preferred Infrastructure, Inc. It includes MessagePack-RPC implementation for C++,MessagePack ™ Copyright © 2008-2021 Sadayuki Furuhashi"
name,content
jaraco.text,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,jaraco/jaraco.text,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,This package provides handy routines for dealing with text, such as
wrapping, substitution, trimming, stripping, prefix and suffix removal,
line continuation, indentation, comment processing, identifier processing,
values parsing, case insensitive comparison, and more. See the docs
(linked in the badge above) for the detailed documentation and examples.,One of the features of this package is the layouts module, which
provides a simple example of translating keystrokes from one keyboard
layout to another:,Need to know what newlines appear in a file?,Available as part of the Tidelift Subscription.,This project and the maintainers of thousands of other packages are working with Tidelift to deliver one enterprise subscription that covers all of the open source you use.,."
name,content
dbfread,"dbfread - Read DBF Files with Python,Version 2.0.7,DBF is a file format used by databases such dBase, Visual FoxPro, and
FoxBase+. This library reads DBF files and returns the data as native
Python data types for further processing. It is primarily intended for
batch jobs and one-off scripts.,Latest stable release: ,Latest development version: ,This document is available at ,To build documentation locally:,This requires Sphinx. The resulting files can be found in
,.,
        © Copyright Ole Martin Bjørndalen.
      
        ,
      

    "
name,content
jieba,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,fxsjy/jieba,Name already in use,jieba,特点,安装说明,算法,主要功能,其他词典,其他语言实现,友情链接,系统集成,分词速度,常见问题,修订历史,jieba,Features,Online demo,Usage,Algorithm,Main Functions,Using Other Dictionaries,Segmentation speed,Scroll down for English documentation.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        结巴中文分词
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,“结巴”中文分词：做最好的 Python 中文分词组件,""Jieba"" (Chinese for ""to stutter"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.,代码对 Python 2/3 均兼容,代码示例,输出:,更改分词器（默认为 ,）的 , 和 , 属性，可分别指定缓存文件所在的文件夹及其文件名，用于受限的文件系统。,范例：,自定义词典：,用法示例：,之前： 李小福 / 是 / 创新 / 办 / 主任 / 也 / 是 / 云 / 计算 / 方面 / 的 / 专家 /,加载自定义词库后：　李小福 / 是 / 创新办 / 主任 / 也 / 是 / 云计算 / 方面 / 的 / 专家 /,使用 , 和 , 可在程序中动态修改词典。,使用 , 可调节单个词语的词频，使其能（或不能）被分出来。,注意：自动计算的词频在使用 HMM 新词发现功能时可能无效。,代码示例：,代码示例 （关键词提取）,关键词提取所使用逆向文件频率（IDF）文本语料库可以切换成自定义语料库的路径,关键词提取所使用停止词（Stop Words）文本语料库可以切换成自定义语料库的路径,关键词一并返回关键词权重值示例,算法论文： ,见 ,paddle模式词性标注对应表如下：,paddle模式词性和专名类别标签集合如下表，其中词性标签 24 个（小写字母），专名类别标签 4 个（大写字母）。,原理：将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升,基于 python 自带的 multiprocessing 模块，目前暂不支持 Windows,用法：,例子：,实验结果：在 4 核 3.4GHz Linux 机器上，对金庸全集进行精确分词，获得了 1MB/s 的速度，是单进程版的 3.3 倍。,：并行分词仅支持默认分词器 , 和 ,。,使用示例：,命令行选项（翻译）：, 选项输出：,jieba 采用延迟加载，, 和 , 不会立即触发词典的加载，一旦有必要才开始加载词典构建前缀字典。如果你想手工初始 jieba，也可以手动初始化。,在 0.28 之前的版本是不能指定主词典的路径的，有了延迟加载机制后，你可以改变主词典的路径:,例子： ,占用内存较小的词典文件
,支持繁体分词更好的词典文件
,下载你所需要的词典，然后覆盖 jieba/dict.txt 即可；或者用 ,作者：piaolingxue
地址：,作者：yanyiwu
地址：,作者：messense, MnO2
地址：,作者：yanyiwu
地址：,作者：falood
地址：,作者：qinwf
地址：,作者：yanyiwu
地址：,作者：fukuball
地址：,作者：anderscui
地址：,详见： ,P(台中) ＜ P(台)×P(中)，“台中”词频不够导致其成词概率较低,解决方法：强制调高词频, 或者 ,解决方法：强制调低词频,或者直接删除该词 ,解决方法：关闭新词发现,
,：,""Jieba"" (Chinese for ""to stutter"") Chinese text segmentation: built to be the best Python Chinese word segmentation module.,(Powered by Appfog),Output:,Change a Tokenizer's , and , to specify the path of the cache file, for using on a restricted file system.,Example:,Use , and , to modify the dictionary dynamically in programs.,Use , to adjust the frequency of a single word so that it can (or cannot) be segmented.,Note that HMM may affect the final result.,Example:,Example (keyword extraction),Developers can specify their own custom IDF corpus in jieba keyword extraction,Developers can specify their own custom stop words corpus in jieba keyword extraction,There's also a , implementation available.,Use: ,Note that it filters POS by default., creates a new TextRank instance.,Principle: Split target text by line, assign the lines into multiple Python processes, and then merge the results, which is considerably faster.,Based on the multiprocessing module of Python.,Usage:,Example:
,Result: On a four-core 3.4GHz Linux machine, do accurate word segmentation on Complete Works of Jin Yong, and the speed reaches 1MB/s, which is 3.3 times faster than the single-process version., that parallel processing supports only default tokenizers, , and ,.,By default, Jieba don't build the prefix dictionary unless it's necessary. This takes 1-3 seconds, after which it is not initialized again. If you want to initialize Jieba manually, you can call:,You can also specify the dictionary (not supported before version 0.28) :,It is possible to use your own dictionary with Jieba, and there are also two dictionaries ready for download:,A smaller dictionary for a smaller memory footprint:
,There is also a bigger dictionary that has better support for traditional Chinese (繁體):
,By default, an in-between dictionary is used, called , and included in the distribution.,In either case, download the file you want, and then call , or just replace the existing ,.,
      结巴中文分词
    "
name,content
nvidia-cublas-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
Flask-Login,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,maxcountryman/flask-login,Name already in use,Flask-Login,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Flask user session management.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,Flask-Login provides user session management for Flask. It handles the common
tasks of logging in, logging out, and remembering your users' sessions over
extended periods of time.,Flask-Login is not bound to any particular database system or permissions
model. The only requirement is that your user objects implement a few methods,
and that you provide a callback to the extension capable of loading users from
their ID.,Install the extension with pip:,Once installed, the Flask-Login is easy to use. Let's walk through setting up
a basic application. Also please note that this is a very basic guide: we will
be taking shortcuts here that you should never take in a real application.,To begin we'll set up a Flask app:,Flask-Login works via a login manager. To kick things off, we'll set up the
login manager by instantiating it and telling it about our Flask app:,To keep things simple we're going to use a dictionary to represent a database
of users. In a real application, this would be an actual persistence layer.
However it's important to point out this is a feature of Flask-Login: it
doesn't care how your data is stored so long as you tell it how to retrieve it!,We also need to tell Flask-Login how to load a user from a Flask request and
from its session. To do this we need to define our user object, a
, callback, and a , callback.,Now we're ready to define our views. We can start with a login view, which will
populate the session with authentication bits. After that we can define a view
that requires authentication.,Finally we can define a view to clear the session and log users out:,We now have a basic working application that makes use of session-based
authentication. To round things off, we should provide a callback for login
failures:,Documentation for Flask-Login is available on ,.
For complete understanding of available configuration, please refer to the ,.,We welcome contributions! If you would like to hack on Flask-Login, please
follow these steps:,Please give us adequate time to review your submission. Thanks!,
      Flask user session management.
    "
name,content
notebook,"JupyterLab is the latest web-based interactive development environment for notebooks, code, and data. Its flexible interface allows users to configure and arrange workflows in data science, scientific computing, computational journalism, and machine learning. A modular design invites extensions to expand and enrich functionality.,The Jupyter Notebook is the original web application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience.,Jupyter supports over 40 programming languages, including Python, R, Julia, and Scala.,Notebooks can be shared with others using email, Dropbox, GitHub and the ,.,Your code can produce rich, interactive output: HTML, images, videos, LaTeX, and custom MIME types.,Leverage big data tools, such as Apache Spark, from Python, R, and Scala. Explore that same data with pandas, scikit-learn, ggplot2, and TensorFlow.,A multi-user version of the notebook designed for companies, classrooms and research labs,Manage users and authentication with PAM, OAuth or integrate with your own directory service system.,Deploy the Jupyter Notebook to thousands of users in your organization on centralized infrastructure on- or off-site.,Use Docker and Kubernetes to scale your deployment, isolate user processes, and simplify software installation.,Deploy the Notebook next to your data to provide unified software management and data access within your organization.,Voilà helps communicate insights by transforming notebooks into secure, stand-alone web applications that you can customize and share.,Project Jupyter promotes open standards that third-party developers can leverage to build customized applications. Think HTML and CSS for interactive computing on the web.,Jupyter Notebooks are an open document format based on JSON. They contain a complete record of the user's sessions and include code, narrative text, equations, and rich output.,The Notebook communicates with computational Kernels using the Interactive Computing Protocol, an open network protocol based on JSON data over ZMQ, and WebSockets.,Kernels are processes that run interactive code in a particular programming language and return output to the user. Kernels also respond to tab completion and introspection requests.,
              The Jupyter Trademark is registered with the U.S. Patent & Trademark Office. © 2023
          "
name,content
Plost,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,tvst/plost,Name already in use,🍅 Plost,plots,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A deceptively simple plotting library for Streamlit
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A deceptively simple plotting library for ,.,Because you've been writing , wrong all this time., , You can find interactive examples, documentation, and much more in the app above.,Plost makes it easy to build common plots using the
,
library but without having to delve into Vega-Lite specs (unless you're doing
something tricky), and without having to melt your DataFrame from long format to wide
format (the bane of most Vega-Lite plots!),For example, let's say you have a ""long-format"" table like this:,Then you can draw a line chart by simply calling , with some
column names:,Simple enough! But what if you instead have a ""wide-format"" table like this, which is
super common in reality:,Normally you'd have to , the table with Pandas first or create a complex
Vega-Lite layered plot. But with Plost, you can just specify what you're trying
to accomplish and it will melt the data internally for you:,Ok, now let's add a mini-map to make panning/zooming even easier:,But we're just scratching the surface. Basically the idea is that Plost allows
you to make beautiful Vega-Lite-driven charts for your most common needs, without
having to learn about the powerful yet complex language behind Vega-Lite.,Check out the , for
a taste of other amazing things you can do!,Check out ,!,This is in , too!,
      A deceptively simple plotting library for Streamlit
    "
name,content
progressbar2,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,wolph/python-progressbar,Name already in use,Text progress bar library for Python.,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Progressbar 2 - A progress bar for Python 2 and Python 3 - ""pip install progressbar2""
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Build status:,Coverage:,The package can be installed through pip (this is the recommended method):,Or if pip is not available, easy_install should work as well:,Or download the latest release from Pypi (,) or Github.,Note that the releases on Pypi are signed with my GPG key (,) and can be checked using GPG:,A text progress bar is typically used to display the progress of a long
running operation, providing a visual cue that processing is underway.,The progressbar is based on the old Python progressbar package that was published on the now defunct Google Code. Since that project was completely abandoned by its developer and the developer did not respond to email, I decided to fork the package. This package is still backwards compatible with the original progressbar package so you can safely use it as a drop-in replacement for existing project.,The ProgressBar class manages the current progress, and the format of the line
is given by a number of widgets. A widget is an object that may display
differently depending on the state of the progress bar. There are many types
of widgets:,The progressbar module is very easy to use, yet very powerful. It will also
automatically enable features like auto-resizing when the system supports it.,To report a security vulnerability, please use the
,.
Tidelift will coordinate the fix and disclosure.,There are many ways to use Python Progressbar, you can see a few basic examples
here but there are many more in the examples file.,Progressbars with logging require stderr redirection _before_ the
StreamHandler is initialized. To make sure the stderr stream has been
redirected on time make sure to call progressbar.streams.wrap_stderr() before
you initialize the logger.,One option to force early initialization is by using the WRAP_STDERR
environment variable, on Linux/Unix systems this can be done through:,If you need to flush manually while wrapping, you can do so using:,In most cases the following will work as well, as long as you initialize the
StreamHandler after the wrapping has taken place.,Naturally we can do this from separate threads as well:,
      Progressbar 2 - A progress bar for Python 2 and Python 3 - ""pip install progressbar2""
    "
name,content
ipyvuetify,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,widgetti/ipyvuetify,Name already in use,ipyvuetify,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Jupyter widgets based on vuetify UI components
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,
,Jupyter widgets based on , which implement Google's
, with the ,.,A small selection of widgets:,To install use pip:,For a development installation (requires npm),,To get started with using ipyvuetify, check out the full documentation,For examples see the ,.,The , can be used to find all available
components and attributes (in the left side bar or use the search field). Ipyvuetify tries to stay close to the Vue.js
and Vuetify template syntax, but there are some differences:,The .sync property modifier functionality can be achieved by using an event named:,
,.,For non scoped slots , and , can be omitted.,Available icons:,For a more web development centric way of development and a closer match to the Vue/Vuetify api, VuetifyTemplate can be used. See the , or ,.,Make a sub class of VuetifyTemplate, define your own traitlets and set a template string. The traitlets will be accessible from the template as if they were in a vue-model. Methods can be called by defining a method with a prefix , e.g. , and calling it from the template e.g. ,.,
      Jupyter widgets based on vuetify UI components
    "
name,content
htmldate,"htmldate: find the publication date of web pages,Indices and tables,htmldate,For infos on dependency management of Python packages see,htmldate,Find original and updated publication dates of any web page. From the command-line or within Python, all the steps needed from web page download to HTML parsing, scraping, and text analysis are included.,With Python:,On the command-line:,Multilingual, robust and efficient (used in production on millions of documents),URLs, HTML files, or HTML trees are given as input (includes batch processing),Output as string in any date format (defaults to ,),Detection of both original and updated dates,Compatible with all recent versions of Python, can examine markup and text. It provides the following ways to date an HTML document:,: Common patterns are used to identify relevant elements (e.g. , and , elements) including , attributes and a large number of CMS idiosyncrasies,: The whole document is then searched for structural markers: , or , elements and a series of attributes (e.g. ,),: Heuristics are run on text and markup:,in , mode the HTML page is cleaned and precise patterns are targeted,in , mode all potential dates are collected and a disambiguation algorithm determines the most probable one,The output is thoroughly verified in terms of plausibility and adequateness. If a valid date has been found the library outputs a date string corresponding to either the last update or the original publishing statement (the default), in the desired format.,Markup-based extraction is multilingual by nature, text-based refinements for better coverage currently support German, English and Turkish.,This Python package is tested on Linux, macOS and Windows systems; it is compatible with Python 3.6 upwards. It is available on the package repository , and can notably be installed with , or ,:,The additional library , (or its fork ,) can be installed for better execution speed. They may not work on all platforms and have thus been singled out although installation is recommended:,You can also install or update the packages separately, , will detect which ones are present on your system and opt for the best available combination.,The , package is noticeably slower in its latest versions, version , is recommended for speed., ,.,Experimental compilation with ,, as using pre-compiled library may shorten processing speed:,Install ,: ,Compile the package: ,Use the newly created wheel: ,In case the web page features easily readable metadata in the header, the extraction is straightforward. A more advanced analysis of the document structure is sometimes needed:, can resort to a guess based on a complete screening of the document (, parameter) which can be deactivated:,Already parsed HTML (that is a LXML tree object):,Change the output to a format known to Python’s , module, the default being ,:,Although the time delta between original publication and “last modified” info is usually a matter of hours or days, it can be useful to prioritize the ,:,For more information see ,.,A command-line interface is included:,For usage instructions see ,:,The batch mode , takes one URL per line as input and returns one result per line in tab-separated format:, is distributed under the ,. If you wish to redistribute this library but feel bounded by the license conditions please try interacting ,, , with ,, or ,.,See also ,This effort is part of methods to derive information from web documents in order to build , (chiefly linguistic analysis and natural language processing). Extracting and pre-processing web texts to the exacting standards of scientific research presents a substantial challenge for those who conduct such research. There are web pages for which neither the URL nor the server response provide a reliable way to find out when a document was published or modified. For more information:,Barbaresi, A. “,”, Journal of Open Source Software, 5(51), 2439, 2020. DOI: 10.21105/joss.02439,Barbaresi, A. “,”, Proceedings of KONVENS 2019, Kaleidoscope Abstracts, 2019.,Barbaresi, A. “,”, Proceedings of the ,, 2016.,You can contact me via my , or ,., are welcome!,Feel free to file issues on the ,. Thanks to the , who submitted features and bugfixes!,Kudos to the following software libraries:,, ,A few patterns are derived from the ,, ,, , and , libraries. This module extends their coverage and robustness significantly.,The granularity may not always match the desired output format. If only information about the year could be found and the chosen date format requires to output a month and a day, the result is ‘padded’ to be located at the middle of the year, in that case the 1st of January.,Besides, there are pages for which no date can be found, ever:,If the date is nowhere to be found, it might be worth considering , the web page, however this is computationally expensive. In addition, , features pattern-based date extraction for texts written in English.,
,
"
name,content
mysql-connector-python,"
,MySQL Connector/Python Developer Guide,
        This manual describes how to install and configure MySQL Connector/Python, a
        self-contained Python driver for communicating with MySQL
        servers, and how to use it to develop database applications.
      ,
        The latest MySQL Connector/Python version is recommended for use with MySQL
        Server version 5.7 and higher.
      ,
        For notes detailing the changes in each release of Connector/Python, see
        ,.
      ,
        For legal information, see the ,.
      ,
    For help with using MySQL, please visit the
    ,, where you
    can discuss your issues with other MySQL users.

  ,
          This product may include third-party software, used under
          license. If you are using a Commercial release of MySQL Connector/Python, see
          the
          , for
          licensing information, including licensing information
          relating to third-party software that may be included in this
          Commercial release. If you are using a Community release of
          MySQL Connector/Python, see the
          , for
          licensing information, including licensing information
          relating to third-party software that may be included in this
          Community release.
        ,
        Document generated on:

        2023-07-26



        (revision: 76335)
      "
name,content
pixcat,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,mirukana/pixcat,Name already in use,pixcat,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        CLI and Python 3.6+ API to display images on a kitty terminal with optional resizing.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,Display images on a , terminal
with optional custom/thumbnail/fit-to-screen resizing.,
Developed with the goal of being a more powerful alternative to ,,
while also providing an usable Python 3.6+ API.,Basic CLI examples:,The commands and options have short forms too.,
See , for more information.,Same examples using the Python package (no documentation yet):,Requires Python 3.6+, tested on GNU/Linux only.,
      CLI and Python 3.6+ API to display images on a kitty terminal with optional resizing.
    "
name,content
cachelib,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pallets-eco/cachelib,Name already in use,CacheLib,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Extract from werkzeug.cache
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,A collection of cache libraries in the same API interface. Extracted
from Werkzeug.,Install and update using ,:,The Pallets organization develops and supports Flask and the libraries
it uses. In order to grow the community of contributors and users, and
allow the maintainers to devote more time to the projects, ,.,
      Extract from werkzeug.cache
    "
name,content
debtcollector,"Welcome to debtcollector’s documentation!,Welcome to debtcollector’s documentation!,current,A collection of Python deprecation patterns and strategies that help you
collect your technical debt in a non-destructive manner.,Note,It should be noted that even though it is designed with OpenStack
integration in mind, and that is where most of its ,
integration is it aims to be generally usable and useful in any
project.,Indices and tables,
 Except where otherwise noted, this document is licensed under
 ,. See all ,.
,
          The OpenStack project is provided under the
          ,. Docs.openstack.org is powered by
          ,.
        "
name,content
markdownify,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,matthewwithanm/python-markdownify,Name already in use,emphasized,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Convert HTML to Markdown
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , ,Convert some HTML to Markdown:,Specify tags to exclude:,...or specify the tags you want to include:,Markdownify supports the following options:,When the HTML code contains , tags that in some way provide the code
language, for example as class, this callback can be used to extract the
language from the tag and prefix it to the converted , tag.
The callback gets one single argument, an BeautifylSoup object, and returns
a string containing the code language, or ,.
An example to use the class name as code language could be:,Defaults to ,.,Options may be specified as kwargs to the , function, or as a
nested , class in , subclasses.,If you have a special usecase that calls for a special conversion, you can
always inherit from , and override the method you want to
change:,Use , or pipe input from stdin
(,).
Call , to see all available options.
They are the same as listed above and take the same arguments.,To run tests and the linter run , once, then ,.,
      Convert HTML to Markdown
    "
name,content
nvidia-cufft-cu11,"CUDA Zone,CUDA® is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs.,In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.,The , from NVIDIA provides everything you need to develop GPU-accelerated applications. The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.,Thousands of applications developed with CUDA have been deployed to GPUs in embedded systems, workstations, datacenters and in the cloud.,CUDA serves as a common platform across all NVIDIA GPU families so you can deploy and scale your application across GPU configurations., , , , ,The first GPUs were designed as graphics accelerators, becoming more programmable over the 90s, culminating in NVIDIA's first GPU in 1999. Researchers and scientists rapidly began to apply the excellent floating point performance of this GPU for general purpose computing. In 2003, a team of researchers led by Ian Buck unveiled Brook, the first widely adopted programming model to extend C with data-parallel constructs. Ian Buck later joined NVIDIA and led the launch of CUDA in 2006, the world's first solution for general-computing on GPUs.,Since its inception, the CUDA ecosystem has grown rapidly to include software development tools, services and partner-based solutions. The , includes libraries, debugging and optimization tools, a compiler and a runtime library to deploy your application. You'll also find code samples, programming guides, user manuals, API references and other documentation to help you get started.,cuRAND,NPP,Math Library,cuFFT,nvGRAPH,NCCL,Nsight,Visual Profiler, CUDA GDB,CUDA MemCheck,OpenACC,CUDA Profiling Tools Interface,CUDA accelerates applications across a wide range of domains from image processing, to deep learning, numerical analytics and computational science.,Get started with CUDA by downloading the CUDA Toolkit and exploring introductory resources including videos, code samples, hands-on labs and webinars., July 25, 2023, July 25, 2023, July 25, 2023, July 24, 2023, July 3, 2023, June 28, 2023, June 27, 2023, June 27, 2023"
name,content
distlib,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,pypa/distlib,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        A low-level library which implements some Python packaging standards (PEPs) and which could be used by third-party packaging tools to achieve interoperability.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., ,Distlib is a library which implements low-level functions that relate to
packaging and distribution of Python software. It is intended to be used as the
basis for third-party packaging tools. The documentation is available at,Distlib currently offers the following features:,Distlib is intended to be used on and is tested on Python versions 2.7 and 3.6 or later,
pypy-2.7 and pypy3 on Linux, Windows, and macOS.,The project has reached a mature status in its development: there is a comprehensive
test suite and it has been exercised on Windows, Ubuntu and macOS. The project is used
by well-known projects such as , and ,.,This project was migrated from Mercurial to Git and from BitBucket to GitHub, and
although all information of importance has been retained across the migration, some
commit references in issues and issue comments may have become invalid.,Everyone interacting in the distlib project's codebases, issue trackers, chat
rooms, and mailing lists is expected to follow the ,.,
      A low-level library which implements some Python packaging standards (PEPs) and which could be used by third-party packaging tools to achieve interoperability.
    "
name,content
pdbr,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,cansarigol/pdbr,Name already in use,pdbr,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        pdb + Rich library
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., , , ,pdbr is intended to make the PDB results more colorful. it uses , library to carry out that.,Install with , or your favorite PyPi package manager.,In order to use ,, set , with ""pdbr.set_trace"",or just import pdbr, , print.,Search a phrase in the current frame.
In order to repeat the last one, type , character as arg.,Display value in sql format.
,It can be used for Django model queries as follows.,[ val,lexer ] Display ,.,Get the local variables list as table.,Get the local variables list as tree.,Config is specified in , and can be local or global. Local config (current working directory) has precedence over global (default) one. Global config must be located in , directory.,In order to use Rich's traceback, style, and theme:, setting is used to keep and reload history, even the prompt is closed and opened again:,In order to use , remote debugger with pdbr, use , as below sample. For more information see the ,.,Instead of using , or ,, in terms of using pdbr style, , command can be used.
,Also in order to activate history and be able to use arrow keys, install and use , package., integrates with ,.,This makes , available, for example:,To enable , features, install it separately, or like below:,In order to use , with pytest , flag, add , setting in your pytest.ini.,The , is a Python system hook that provides a way to customize the behavior when an unhandled exception occurs. Since , use  automatic traceback handler feaure of ,, formatting exception print is not necessary if , module is already imported.,In order to use post-mortem or perform other debugging features of ,,  override , with a function that will act as your custom excepthook:,Now, whenever an unhandled exception occurs, , will be triggered, allowing you to debug the issue interactively., and , (, corresponding) can be used as , or ,. It calls , if , is not none.,To being activated the pdb in Django test, change , like below. Unlike Django (since you are not allowed to use for smaller versions than 3), pdbr runner can be used for version 1.8 and subsequent versions.,In order to catch the problematic codes with post mortem, place the middleware class.,Running , command in terminal starts an , terminal app instance. Unlike default ,, the new shell uses pdbr as debugger class instead of ,.,If , command is used with an argument, it is invoked as a script and , can be used with it.,To create or edit your own snippets, select , under , (, on macOS), and then select ,.,Place the below snippet in json file for ,.,For , debug.,
      pdb + Rich library
    "
name,content
asttokens,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,gristlabs/asttokens,Name already in use,ASTTokens,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Annotate Python AST trees with source text and token information
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,The , module annotates Python abstract syntax trees (ASTs) with the positions of tokens
and text in the source code that generated them.,It makes it possible for tools that work with logical AST nodes to find the particular text that
resulted in those nodes, for example for automated refactoring or highlighting.,asttokens is available on PyPI: ,:,The code is on GitHub: ,.,The API Reference is here: ,.,ASTTokens works with both Python2 and Python3.,ASTTokens can annotate both trees built by ,,
AND those built by ,.,Here's an example:,Once the tree has been marked, nodes get ,, , attributes, and
the , object offers helpful methods:,Which produces this output:,The , object also offers methods to walk and search the list of tokens that make up
the code (or a particular AST node), which is more useful and powerful than dealing with the text
directly.,To contribute:,Fork this repository, and clone your fork.,Install the package with test dependencies (ideally in a virtualenv) with:,Run tests in your current interpreter with the command , or ,.,Run tests across all supported interpreters with the , command. You will need to have the interpreters installed separately. We recommend , for that. Use , to run the tests in parallel.,By default certain tests which take a very long time to run are skipped, but they are run on travis CI. To run them locally, set the environment variable ,. For example run , to run the full suite of tests.,
      Annotate Python AST trees with source text and token information
    "
name,content
courlan,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,adbar/courlan,Name already in use,coURLan: Clean, filter, normalize, and sample URLs,coURLan,Proceedings of ACL/IJCNLP 2021: System Demonstrations,Proceedings of the 15th Conference on Natural Language Processing (KONVENS 2019),Computer networks and ISDN systems,Proceedings of the 10th international conference on World Wide Web - WWW '01,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Clean, filter and sample URLs to optimize data collection – includes spam, content type and language filters
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,“It is important for the crawler to visit ""important"" pages first, so that the fraction of the Web that is visited (and kept up to date) is more meaningful.” (Cho et al. 1998),“Given that the bandwidth for conducting crawls is neither infinite nor free, it is becoming essential to crawl the Web in not only a scalable, but efficient way, if some reasonable measure of quality or freshness is to be maintained.” (Edwards et al. 2001),This library provides an additional “brain” for web crawling, scraping and management of web archives:,Using content and language-focused filters, Courlan helps navigating the Web so as to improve the resulting document collections. Additional functions include straightforward domain name extraction and URL sampling.,Separate , and optimize crawls by focusing on non-spam HTML pages containing primarily text.,Here is a , (source: ,, CC BY 2.0).,This package is compatible with with all common versions of Python, it is tested on Linux, macOS and Windows systems.,Courlan is available on the package repository , and can notably be installed with the Python package manager ,:,Most filters revolve around the , and , arguments.,All useful operations chained in ,:,Language-aware heuristics, notably internationalization in URLs, are available in ,:,Define stricter restrictions on the expected content type with ,. Also blocks certain platforms and pages types crawlers should stay away from if they don't target them explicitly and other black holes where machines get lost.,Determine if a link leads to another host:,Other useful functions dedicated to URL handling:,Other filters dedicated to crawl frontier management:,Helper function, scrub and normalize:,Basic scrubbing only:,Basic canonicalization/normalization only, i.e. modifying and standardizing URLs in a consistent manner:,Basic URL validation only:,Courlan uses an internal cache to speed up URL parsing. It can be reset as follows:,The , class allow for storing and retrieving domain-classified URLs, where a URL like , is stored as the path , within the domain ,. It features the following methods:,Optional settings:
- ,: activate compression of URLs and rules
- ,: focus on a particular target language (two-letter code)
- ,: stricter URL filtering
- ,: dump URLs if interrupted (requires use of ,),The main fonctions are also available through a command-line utility.,Manage input and output,Configure URL filters,Use sampling by host, configure sample size, is distributed under the ,. If you wish to redistribute this library but feel bounded by the license conditions please try interacting ,, , with ,, or ,.,See also , is optimized for English and German but its generic approach is also usable in other contexts.,Details of strict URL filtering can be reviewed and changed in the file ,. To override the default settings, , and ,., are welcome!,Feel free to file issues on the ,.,This effort is part of methods to derive information from web documents in order to build , (chiefly linguistic analysis and natural language processing). Extracting and pre-processing web texts to the exacting standards of scientific research presents a substantial challenge for those who conduct such research. Web corpus construction involves numerous design decisions, and this software package can help facilitate text data collection and enhance corpus quality.,Contact: see , or ,.,Software ecosystem: see ,.,These Python libraries perform similar normalization tasks but do not entail language or content filters. They also do not focus on crawl optimization:,
      Clean, filter and sample URLs to optimize data collection – includes spam, content type and language filters
    "
name,content
gmpy2,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,aleaxit/gmpy,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        General Multi-Precision arithmetic for Python 2.6+/3+ (GMP, MPIR, MPFR, MPC)
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,gmpy2 is an optimized, C-coded Python extension module that supports fast
multiple-precision arithmetic.  gmpy2 is based on the original gmpy module.
gmpy2 adds support for correctly rounded multiple-precision real arithmetic
(using the MPFR library) and complex arithmetic (using the MPC library).,gmpy2 2.1 was extensively refactored. Some of the significant changes are:,The gmpy2 2.1 series will be the last to offer compatibility with Python 2.7.
Release 2.1.3 is the last planned release of the 2.1 series.,Note: Versions 2.1.4 and 2.1.5 were released to address Apple Silicon wheel
build issues. There are no code changes.,Release 2.1.5 is the last planned release of the 2.1 series.,Version 2.2 will drop support for Python 2.7 and older Python 3.x versions.,The primary development focus will be on functions that operate on lists and
release the GIL. See powmod_base_list and powmod_exp_list as examples.,gmpy2 is available at ,Documentation is available at ,
      General Multi-Precision arithmetic for Python 2.6+/3+ (GMP, MPIR, MPFR, MPC)
    "
name,content
imageio,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,imageio/imageio,Name already in use,IMAGEIO,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python library for reading and writing image data
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
,
,
,
,
,
,Website: ,
Imageio is a Python library that provides an easy interface to read and
write a wide range of image data, including animated images, video,
volumetric data, and scientific formats. It is cross-platform, runs on
Python 3.7+, and is easy to install.
,
    Professional support is available via ,.
,See the , for more information.,Minimal requirements:,Optional Python packages:,
If you use imageio for scientific work, we would appreciate a citation.
We have a ,!
,To report a security vulnerability, please use the
,.
Tidelift will coordinate the fix and disclosure.,Available as part of the Tidelift Subscription.,The maintainers of imageio and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use.
,.,
    The core of ImageIO is a set of user-facing APIs combined with a plugin manager. API calls choose sensible defaults and then call the plugin manager, which deduces the correct plugin/backend to use for the given resource and file format. The plugin manager then adds sensible backend-specific defaults and then calles one of ImageIOs many backends to perform the actual loading. This allows ImageIO to take care of most of the gory details of loading images for you, while still allowing you to customize the behavior when and where you need to. You can find a more detailed explanation of this process in ,.
,We welcome contributions of any kind. Here are some suggestions on how you are able to contribute,To assist you in getting started with contributing code, take a look at the , of the docs. You will find instructions on setting up the dev environment as well as examples on how to contribute code.,
      Python library for reading and writing image data
    "
name,content
mutagen,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,quodlibet/mutagen,Name already in use,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        Python module for handling audio metadata
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,Mutagen is a Python module to handle audio metadata. It supports ASF, FLAC,
MP4, Monkey's Audio, MP3, Musepack, Ogg Opus, Ogg FLAC, Ogg Speex, Ogg Theora,
Ogg Vorbis, True Audio, WavPack, OptimFROG, and AIFF audio files. All
versions of ID3v2 are supported, and all standard ID3v2.4 frames are parsed.
It can read Xing headers to accurately calculate the bitrate and length of
MP3s. ID3 and APEv2 tags can be edited regardless of audio format. It can also
manipulate Ogg streams on an individual packet/page level.,Mutagen works with Python 3.7+ (CPython and PyPy) on Linux, Windows and macOS,
and has no dependencies outside the Python standard library. Mutagen is licensed
under ,.,For more information visit ,
      Python module for handling audio metadata
    "
name,content
peppercorn,"Peppercorn,A library for converting a token stream into a data structure comprised of
sequences, mappings, and scalars, developed primarily for converting HTTP
form post data into a richer data structure. It runs on Python 2.7, 3.4, 3.5,
3.6 and 3.7.,Example ""bare"" usage:,A , token pushes a data structure onto the stack.  Its
value is composed of a name and a type, separated by a colon
(e.g. ,).  Four , token types exist:,: begins a sequence.  Subsequent data elements will be
added as positional elements in the sequence.,: begins a mapping.  Subsequent data elements will be
added as key/value pairs in the mapping.,: begins a special mode.  The value of the first
subsequent data element in the stream will be used within its
parent sequence or mapping; any remaining data elements until the
corresponding , marker are ignored.,If the parent is a mapping, the key used in the mapping will be the
name of the , token (when ,, the
key will be ,).  The value will be the value of the
first data element.,If the parent is a sequence, the , token name is ignored,
and the value of the first data element is placed into the sequence., is mostly for radio controls; we surround sets of radio
controls in a , in order to provide a surrogate naming for
a group of radio control elements.  Radio control ,
attributes are used by the browser to perform grouping, so each
radio control that is a member of a the same group must share a
, attribute value.  Moreover, this group name must be unique
amongst all controls on the form to prevent ""select bleeding""
between radio controls.  However, on the server side, we're
uninterested in participating in this disambiguation process and
it's easier to not know about it when the form is posted.  We just
want the selected value back in the pstruct to be recorded under a
well-known name.  This name will be the name of the , token
surrounding some radio controls.,: The subsequent data elements will be ignored (not added
to the mapping or sequence) until the next , token. Useful
when forms include a field designed for client side scripting, such
as a ""select all"" checkbox in the middle of a series of checkboxes., markers can be unnamed; they are unnamed when their
value does not contain a colon.  For example, the start marker
, begins a mapping with the implied name
, (the empty string).,A sequence or mapping is closed when the corresponding ,
token for its , token is processed.  Mappings and
sequences can be nested arbitrarily.  The value of an ,
token is optional; it is useful as documentation, but they are
not required by Peppercorn.,The data structure returned from , will always
be a mapping.,To use Peppercorn in a web application, create a form that has the
tokens in order.  For instance, the below form will generate the above
token stream:,Then when the web post reaches the application, call the
, function with the ordered field pairs.  For a
, request, this means using the , method of a
Webob MultiDict such as ,:,The , attribute of a Python , object can
also be used as a source of information:,See ,."
name,content
Levenshtein,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,maxbachmann/Levenshtein,Name already in use,Levenshtein,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        The Levenshtein Python C extension module contains functions for fast computation of Levenshtein distance and string similarity
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,
  ,
  ,
  ,
  ,
  ,
,The Levenshtein Python C extension module contains functions for fast
computation of:,The documentation for the current version can be found at ,If you are using Levenshtein for your work and feel like giving a bit of your own benefit back to support the project, consider sending us money through GitHub Sponsors or PayPal that we can use to buy us free time for the maintenance of this great library, to fix bugs in the software, review and integrate code contributions, to improve its features and documentation, or to just take a deep breath and have a cup of tea every once in a while. Thank you for your support.,Support the project through , or via ,:,.,Levenshtein is free software; you can redistribute it and/or modify it
under the terms of the GNU General Public License as published by the Free
Software Foundation; either version 2 of the License, or (at your option)
any later version.,See the file , for the full text of GNU General Public License version 2.,
      The Levenshtein Python C extension module contains functions for fast computation of Levenshtein distance and string similarity
    "
name,content
django3-all-access,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,stormers/django-all-access,Name already in use,django-all-access,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        django-all-access is a reusable application for user registration and authentication from OAuth 1.0 and OAuth 2.0 providers such as Twitter and Facebook.
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again.,django-all-access is a reusable application for user registration and authentication
from OAuth 1.0 and OAuth 2.0 providers such as Twitter and Facebook.,The goal of this project is to make it easy to create your own workflows for
authenticating with these remote APIs. django-all-access will provide the simple
views with sane defaults along with hooks to override the default behavior.,You can find a basic demo application running at ,It is easiest to install django-all-access from PyPi using pip:,django-all-access requires Python 2.7 or 3.3+ along with the following Python
packages:,Additional documentation on using django-all-access is available on
,.,django-all-access is released under the BSD License. See the
, file for more details.,If you have questions about using django-all-access or want to follow updates about
the project you can join the ,
through Google Groups.,If you think you've found a bug or are interested in contributing to this project
check out ,.,
      django-all-access is a reusable application for user registration and authentication from OAuth 1.0 and OAuth 2.0 providers such as Twitter and Facebook.
    "
name,content
commonmark,"Search code, repositories, users, issues, pull requests...,
        Provide feedback
      ,
        Saved searches
      ,readthedocs/commonmark.py,Name already in use,commonmark.py,We read every piece of feedback, and take your input very seriously.,
            To see all available qualifiers, see our ,.
          ,
        DEPRECATED: Python CommonMark parser
      ,
        Use Git or checkout with SVN using the web URL.
    ,
      Work fast with our official CLI.
      ,.
    ,
                Please
                ,
                to use Codespaces.
              ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,
    If nothing happens, , and try again.
  ,Your codespace will open once ready.,There was a problem preparing your codespace, please try again., commonmark.py is now deprecated. We recommend using ,
for a commonmark parser going forward. See , for background
and discussion.,commonmark.py is a pure Python port of ,'s
,, a
Markdown parser and renderer for the
, specification, using only native
modules. Once both this project and the CommonMark specification are
stable we will release the first , version and attempt to keep up
to date with changes in ,.,commonmark.py is tested against the CommonMark spec with Python versions
2.7, 3.5, 3.6, 3.7, and 3.8., 0.9.1, , ,Or, without the syntactic sugar:,There is also a CLI:,If you would like to offer suggestions/optimizations/bugfixes through
pull requests please do! Also if you find an error in the
parser/renderer that isn't caught by the current test suite please open
a new issue and I would also suggest you send the
, project
a pull request adding your test to the existing test suite.,To work on commonmark.py, you will need to be able to run the test suite to
make sure your changes don't break anything. To run the tests, you can do
something like this:,The tests script, ,, is pretty much a devtool. As
well as running all the tests embedded in , it also allows you
to run specific tests using the , argument, provide information
about passed tests with ,, percentage passed by category of test
with ,, and enter markdown interactively with , (In
interactive mode end a block by inputting a line with just ,, to
quit do the same but with ,). , can be used to print call
tracing.,
      DEPRECATED: Python CommonMark parser
    "
