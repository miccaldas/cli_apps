content
"(['RaRe-Technologies/smart_open', 'Name already in use', 'smart_open — utils for streaming large files in Python', 'Important', 'and', 'Important'], ['\n        Utils for streaming large files (S3, HDFS, gzip, bz2...)\n      ', '\n        Use Git or checkout with SVN using the web URL.\n    ', '\n      Work fast with our official CLI.\n      ', '.\n    ', '\n                Please\n                ', '\n                to use Codespaces.\n              ', '\n    If nothing happens, ', ' and try again.\n  ', '\n    If nothing happens, ', ' and try again.\n  ', '\n    If nothing happens, ', ' and try again.\n  ', 'Your codespace will open once ready.', 'There was a problem preparing your codespace, please try again.', ' ', ' ', ' ', ' is a Python 3 library for ', ' from/to storages such as S3, GCS, Azure Blob Storage, HDFS, WebHDFS, HTTP, HTTPS, SFTP, or local filesystem. It supports transparent, on-the-fly (de-)compression for a variety of different formats.', "" is a drop-in replacement for Python's built-in "", ': it can do anything ', ' can (100% compatible, falls back to native ', ' wherever possible), plus lots of nifty extra stuff on top.', ' ', ', ', ""Working with large remote files, for example using Amazon's "", ' Python library, is a pain.\n', ""'s "", ' and ', ' methods require gotcha-prone boilerplate to use successfully, such as constructing file-like object wrappers.\n', ' shields you from that. It builds on boto3 and other remote storage libraries, but offers a ', '. The result is less code for you to write and fewer bugs to make.', ' is well-tested, well-documented, and has a simple Pythonic API:', 'Other examples of URLs that ', ' accepts:', ' supports a wide range of storage solutions, including AWS S3, Google Cloud and Azure.\nEach individual solution has its own dependencies.\nBy default, ', ' does not install any dependencies, in order to keep the installation size small.\nYou can install these dependencies explicitly using:', ""Or, if you don't mind installing a large number of third party libraries, you can install all dependencies using:"", 'Be warned that this option increases the installation size significantly, e.g. over 100MB.', ""If you're upgrading from "", ' versions 2.x and below, please check out the ', '.', 'For detailed API info, see the online help:', 'or click ', ' to view the help in your browser.', 'For the sake of simplicity, the examples below assume you have all the dependencies installed, i.e. you have done:', 'The top-level compression parameter controls compression/decompression behavior when reading and writing.\nThe supported values for this parameter are:', 'By default, ', ' determines the compression algorithm to use based on the file extension.', 'You can override this behavior to either disable compression, or explicitly specify the algorithm to use.\nTo disable compression:', 'To specify the algorithm explicitly (e.g. for non-standard file extensions):', 'You can also easily add support for other file extensions and compression formats.\nFor example, to open xz-compressed files:', ' is in the standard library in Python 3.3 and greater.\nFor 2.7, use ', '.', ' supports a wide range of transport options out of the box, including:', 'Each option involves setting up its own set of parameters.\nFor example, for accessing S3, you often need to set up authentication, like API keys or a profile name.\n', ""'s "", ' function accepts a keyword argument ', ' which accepts additional parameters for the transport layer.\nHere are some examples of using this parameter:', 'For the full list of keyword arguments supported by each transport option, see the documentation:', ' uses the ', ' library to talk to S3.\n', ' has several ', ' for determining the credentials to use.\nBy default, ', ' will defer to ', ' and let the latter take care of the credentials.\nThere are several ways to override this behavior.', 'The first is to pass a ', ' object as a transport parameter to the ', ' function.\nYou can customize the credentials when constructing the session for the client.\n', ' will then use the session when talking to S3.', 'Your second option is to specify the credentials within the S3 URL itself:', ': The two methods above are ', '. If you pass an AWS client ', ' the URL contains credentials, ', ' will ignore the latter.', ': ', ' ignores configuration files from the older ', ' library.\nPort your old ', ' settings to ', ' in order to use them with ', '.', ""Since going over all (or select) keys in an S3 bucket is a very common operation, there's also an extra function "", ' that does this efficiently, ', ' (using multiprocessing):', ' uses the ', ' library to talk to GCS.\n', ' uses the ', ' package under the hood to handle authentication.\nThere are several ', ' to provide\ncredentials.\nBy default, ', ' will defer to ', ' and let it take care of the credentials.', 'To override this behavior, pass a ', ' object as a transport parameter to the ', ' function.\nYou can ', '\nwhen constructing the client. ', ' will then use the client when talking to GCS. To follow allow with\nthe example below, ', '\nto setting up GCS authentication with a service account.', 'If you need more credential options, you can create an explicit ', ' object\nand pass it to the Client. To create an API token for use in the example below, refer to the\n', '.', ' uses the ', ' library to talk to Azure Blob Storage.\nBy default, ', ' will defer to ', ' and let it take care of the credentials.', 'Azure Blob Storage does not have any ways of inferring credentials therefore, passing a ', '\nobject as a transport parameter to the ', ' function is required.\nYou can ', '\nwhen constructing the client. ', ' will then use the client when talking to. To follow allow with\nthe example below, ', '\nto setting up authentication.', 'If you need more credential options, refer to the\n', '.', ' can also be used with ', ' objects.\nThe built-in Path.open() is not able to read text from compressed files, so use ', ' to replace it with smart_open.open() instead.\nThis can be helpful when e.g. working with compressed files.', 'See ', '.', 'See ', '.', ' comes with a comprehensive suite of unit tests.\nBefore you can run the test suite, install the test dependencies:', 'Now, you can run the unit tests:', 'The tests are also run automatically with ', ' on every commit push & pull request.', ' lives on ', '. You can file\nissues or pull requests there. Suggestions, pull requests and improvements welcome!', ' is open source software released under the ', '.\nCopyright (c) 2015-now ', '.', '\n      Utils for streaming large files (S3, HDFS, gzip, bz2...)\n    ', '\n      ', '\n      ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', 'Explore', '\n  ', '\n  ', '\n  ', '\n  ', '\n', '\n      ', '\n      ', 'For', '\n  ', '\n  ', '\n  ', '\n  ', 'By Solution', '\n  ', '\n  ', '\n  ', 'Case Studies', '\n  ', '\n  ', '\n', '\n      ', '\n      ', '\n  ', '\n  ', 'Repositories', '\n  ', '\n  ', '\n  ', '\n', '\n    ', '\n', '\n  ', '\n', '\n    ', '\n  ', '\n  ', '\n', '\n  ', '\n', '\n  ', '\n', '\n        ', '\n      ', '\n            ', '  ', '\n          ', '\n  ', '\n        ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n  ', '\n  ', '\n  ', '\n\n', '\n\n', '\n\n', '\n  ', '\n  ', '\n            ', '\n          ', ' (default behavior)', 'S3', 'HTTP, HTTPS (read-only)', 'SSH, SCP and SFTP', 'WebHDFS', 'GCS', 'Azure Blob Storage', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n        ', '\n    ', '\n        ', '\n    '])"
content
"(['RaRe-Technologies/smart_open', 'Name already in use', 'smart_open — utils for streaming large files in Python', 'Important', 'and', 'Important'], ['\n        Utils for streaming large files (S3, HDFS, gzip, bz2...)\n      ', '\n        Use Git or checkout with SVN using the web URL.\n    ', '\n      Work fast with our official CLI.\n      ', '.\n    ', '\n                Please\n                ', '\n                to use Codespaces.\n              ', '\n    If nothing happens, ', ' and try again.\n  ', '\n    If nothing happens, ', ' and try again.\n  ', '\n    If nothing happens, ', ' and try again.\n  ', 'Your codespace will open once ready.', 'There was a problem preparing your codespace, please try again.', ' ', ' ', ' ', ' is a Python 3 library for ', ' from/to storages such as S3, GCS, Azure Blob Storage, HDFS, WebHDFS, HTTP, HTTPS, SFTP, or local filesystem. It supports transparent, on-the-fly (de-)compression for a variety of different formats.', "" is a drop-in replacement for Python's built-in "", ': it can do anything ', ' can (100% compatible, falls back to native ', ' wherever possible), plus lots of nifty extra stuff on top.', ' ', ', ', ""Working with large remote files, for example using Amazon's "", ' Python library, is a pain.\n', ""'s "", ' and ', ' methods require gotcha-prone boilerplate to use successfully, such as constructing file-like object wrappers.\n', ' shields you from that. It builds on boto3 and other remote storage libraries, but offers a ', '. The result is less code for you to write and fewer bugs to make.', ' is well-tested, well-documented, and has a simple Pythonic API:', 'Other examples of URLs that ', ' accepts:', ' supports a wide range of storage solutions, including AWS S3, Google Cloud and Azure.\nEach individual solution has its own dependencies.\nBy default, ', ' does not install any dependencies, in order to keep the installation size small.\nYou can install these dependencies explicitly using:', ""Or, if you don't mind installing a large number of third party libraries, you can install all dependencies using:"", 'Be warned that this option increases the installation size significantly, e.g. over 100MB.', ""If you're upgrading from "", ' versions 2.x and below, please check out the ', '.', 'For detailed API info, see the online help:', 'or click ', ' to view the help in your browser.', 'For the sake of simplicity, the examples below assume you have all the dependencies installed, i.e. you have done:', 'The top-level compression parameter controls compression/decompression behavior when reading and writing.\nThe supported values for this parameter are:', 'By default, ', ' determines the compression algorithm to use based on the file extension.', 'You can override this behavior to either disable compression, or explicitly specify the algorithm to use.\nTo disable compression:', 'To specify the algorithm explicitly (e.g. for non-standard file extensions):', 'You can also easily add support for other file extensions and compression formats.\nFor example, to open xz-compressed files:', ' is in the standard library in Python 3.3 and greater.\nFor 2.7, use ', '.', ' supports a wide range of transport options out of the box, including:', 'Each option involves setting up its own set of parameters.\nFor example, for accessing S3, you often need to set up authentication, like API keys or a profile name.\n', ""'s "", ' function accepts a keyword argument ', ' which accepts additional parameters for the transport layer.\nHere are some examples of using this parameter:', 'For the full list of keyword arguments supported by each transport option, see the documentation:', ' uses the ', ' library to talk to S3.\n', ' has several ', ' for determining the credentials to use.\nBy default, ', ' will defer to ', ' and let the latter take care of the credentials.\nThere are several ways to override this behavior.', 'The first is to pass a ', ' object as a transport parameter to the ', ' function.\nYou can customize the credentials when constructing the session for the client.\n', ' will then use the session when talking to S3.', 'Your second option is to specify the credentials within the S3 URL itself:', ': The two methods above are ', '. If you pass an AWS client ', ' the URL contains credentials, ', ' will ignore the latter.', ': ', ' ignores configuration files from the older ', ' library.\nPort your old ', ' settings to ', ' in order to use them with ', '.', ""Since going over all (or select) keys in an S3 bucket is a very common operation, there's also an extra function "", ' that does this efficiently, ', ' (using multiprocessing):', ' uses the ', ' library to talk to GCS.\n', ' uses the ', ' package under the hood to handle authentication.\nThere are several ', ' to provide\ncredentials.\nBy default, ', ' will defer to ', ' and let it take care of the credentials.', 'To override this behavior, pass a ', ' object as a transport parameter to the ', ' function.\nYou can ', '\nwhen constructing the client. ', ' will then use the client when talking to GCS. To follow allow with\nthe example below, ', '\nto setting up GCS authentication with a service account.', 'If you need more credential options, you can create an explicit ', ' object\nand pass it to the Client. To create an API token for use in the example below, refer to the\n', '.', ' uses the ', ' library to talk to Azure Blob Storage.\nBy default, ', ' will defer to ', ' and let it take care of the credentials.', 'Azure Blob Storage does not have any ways of inferring credentials therefore, passing a ', '\nobject as a transport parameter to the ', ' function is required.\nYou can ', '\nwhen constructing the client. ', ' will then use the client when talking to. To follow allow with\nthe example below, ', '\nto setting up authentication.', 'If you need more credential options, refer to the\n', '.', ' can also be used with ', ' objects.\nThe built-in Path.open() is not able to read text from compressed files, so use ', ' to replace it with smart_open.open() instead.\nThis can be helpful when e.g. working with compressed files.', 'See ', '.', 'See ', '.', ' comes with a comprehensive suite of unit tests.\nBefore you can run the test suite, install the test dependencies:', 'Now, you can run the unit tests:', 'The tests are also run automatically with ', ' on every commit push & pull request.', ' lives on ', '. You can file\nissues or pull requests there. Suggestions, pull requests and improvements welcome!', ' is open source software released under the ', '.\nCopyright (c) 2015-now ', '.', '\n      Utils for streaming large files (S3, HDFS, gzip, bz2...)\n    ', '\n      ', '\n      ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', 'Explore', '\n  ', '\n  ', '\n  ', '\n  ', '\n', '\n      ', '\n      ', 'For', '\n  ', '\n  ', '\n  ', '\n  ', 'By Solution', '\n  ', '\n  ', '\n  ', 'Case Studies', '\n  ', '\n  ', '\n', '\n      ', '\n      ', '\n  ', '\n  ', 'Repositories', '\n  ', '\n  ', '\n  ', '\n', '\n    ', '\n', '\n  ', '\n', '\n    ', '\n  ', '\n  ', '\n', '\n  ', '\n', '\n  ', '\n', '\n        ', '\n      ', '\n            ', '  ', '\n          ', '\n  ', '\n        ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n  ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n                ', '              ', '\n  ', '\n  ', '\n  ', '\n\n', '\n\n', '\n\n', '\n  ', '\n  ', '\n            ', '\n          ', ' (default behavior)', 'S3', 'HTTP, HTTPS (read-only)', 'SSH, SCP and SFTP', 'WebHDFS', 'GCS', 'Azure Blob Storage', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n            ', '\n          ', '\n        ', '\n    ', '\n        ', '\n    '])"
