description
" knows what languages are. It knows the standardized codes that
refer to them, such as "
" for English, "
 for Spanish and 
 for Hindi.
These are 
". You may know them by their old name, ISO 639
language codes. IETF has done some important things for backward compatibility
and supporting language variations that you won't find in the ISO standard."
"It may sound to you like langcodes solves a pretty boring problem. At one
level, that's right. Sometimes you have a boring problem, and it's great when a
library solves it for you."
"But there's an interesting problem hiding in here. How do you work with
language codes? How do you know when two different codes represent the same
thing? How should your code represent relationships between codes, like the
following?"
"One way to know is to read IETF standards and Unicode technical reports.
Another way is to use a library that implements those standards and guidelines
for you, which langcodes does."
"When you're working with these short language codes, you may want to see the
name that the language is called "
 a language: 
" is called ""French"" in
English. That language doesn't have to be English: "
" is called ""français"" in
French. A supplement to langcodes, "
", provides
this information."
"langcodes is maintained by Elia Robyn Lake a.k.a. Robyn Speer, and is released
as free software under the MIT license."
"Although this is not the only reason to use it, langcodes will make you more
acronym-compliant."
langcodes implements 
", the IETF Best
Current Practices on Tags for Identifying Languages. BCP 47 is also known as
RFC 5646. It subsumes ISO 639 and is backward compatible with it, and it also
implements recommendations from the "
.
"langcodes can also refer to a database of language properties and names, built
from Unicode CLDR and the IANA subtag registry, if you install "
.
"In summary, langcodes takes language codes and does the Right Thing with them,
and if you want to know exactly what the Right Thing is, there are some
documents you can go read."
"This function standardizes tags, as strings, in several ways."
"It replaces overlong tags with their shortest version, and also formats them
according to the conventions of BCP 47:"
It removes script subtags that are redundant with the language:
"It replaces deprecated values with their correct versions, if possible:"
"Sometimes this involves complex substitutions, such as replacing Serbo-Croatian
("
) with Serbian in Latin script (
"), or the entire tag "
"
with "
 (American Sign Language).
If 
" is True, it uses macrolanguage codes as a replacement for the most
common standardized language within that macrolanguage."
Even when 
" is False, it shortens tags that contain both the
macrolanguage and the language:"
"If the tag can't be parsed according to BCP 47, this will raise a
LanguageTagError (a subclass of ValueError):"
"This package defines one class, named Language, which contains the results
of parsing a language tag. Language objects have the following fields,
any of which may be unspecified:"
The 
" method converts a string to a Language instance, and the
"
" method makes a Language instance from its fields.  These values
are cached so that calling "
 or 
" again with the
same values returns the same object, for efficiency."
"By default, it will replace non-standard and overlong tags as it interprets
them. To disable this feature and get the codes that literally appear in the
language tag, use the "
 option.
Here are some examples of replacing non-standard tags:
Use the 
" function on a Language object to convert it back to its
standard string form:"
A language code is 
" when every part of it is assigned a meaning by IANA.
That meaning could be ""private use""."
"In langcodes, we check the language subtag, script, territory, and variants for
validity. We don't check other parts such as extlangs or Unicode extensions."
"For example, "
" is a valid language code, and "
 is not:
The top-level function 
" is possibly more convenient to use,
because it can return False even for tags that don't parse:"
"If one subtag is invalid, the entire code is invalid:"
" is valid, though it's a deprecated alias for "
:
The empty language tag (
) is valid:
Private use codes are valid:
Language tags that are very unlikely are still valid:
"Tags with non-ASCII characters are invalid, because they don't parse:"
"Before there was BCP 47, there was ISO 639-2. The ISO tried to make room for the
variety of human languages by assigning every language a 3-letter code,
including the ones that already had 2-letter codes."
"Unfortunately, this just led to more confusion. Some languages ended up with two
different 3-letter codes for legacy reasons, such as French, which is "
" as a
""terminology"" code, and "
" as a ""biblographic"" code. And meanwhile, "
" was
still a code that you'd be using if you followed ISO 639-1."
"In BCP 47, you should use 2-letter codes whenever they're available, and that's
what langcodes does. Fortunately, all the languages that have two different
3-letter codes also have a 2-letter code, so if you prefer the 2-letter code,
you don't have to worry about the distinction."
"But some applications want the 3-letter code in particular, so langcodes
provides a method for getting those, "
". It returns the
'terminology' code by default, and passing "
" returns the
bibliographic code."
"When this method returns, it always returns a 3-letter string."
"For many languages, the terminology and bibliographic alpha3 codes are the same."
"When you use any of these ""overlong"" alpha3 codes in langcodes, they normalize
back to the alpha2 code:"
The methods in this section require an optional package called 
".
You can install it with "
", or request the optional
""data"" feature of langcodes with "
.
The dependency that you put in setup.py should be 
.
"It's often helpful to be able to describe a language code in a way that a user
(or you) can understand, instead of in inscrutable short codes. The
"
 method lets you describe a Language object 
.
The 
" method will look up the name of the
language. The names come from the IANA language tag registry, which is only in
English, plus CLDR, which names languages in many commonly-used languages."
The default language for naming things is English:
But you can ask for language names in numerous other languages:
Why does everyone get Slovak and Slovenian confused? Let's ask them.
"If the language has a script or territory code attached to it, these will be
described in parentheses:"
"Sometimes these can be the result of tag normalization, such as in this case
where the legacy tag 'sh' becomes 'sr-Latn':"
"Naming a language in itself is sometimes a useful thing to do, so the
"
" method makes this easy, providing the display name of a language
in the language itself:"
"The names come from the Unicode CLDR data files, and in English they can
also come from the IANA language subtag registry. Together, they can give
you language names in the 196 languages that CLDR supports."
You can get the parts of the name separately with the methods 
",
"
", and "
", or get a dictionary of all the parts
that are present using the "
" method. These methods also accept a
language code for what language they should be described in."
"As the reverse of the above operations, you may want to look up a language by
its name, converting a natural language name such as ""French"" to a code such as
'fr'."
"The name can be in any language that CLDR supports (see ""Ambiguity"" below)."
"However, this method currently ignores the parenthetical expressions that come from
"
:
"There is still room to improve the way that language names are matched, because
some languages are not consistently named the same way. The method currently
works with hundreds of language names that are used on Wiktionary."
"For the sake of usability, "
" doesn't require you to specify what
language you're looking up a language in by name. This could potentially lead to
a conflict: what if name ""X"" is language A's name for language B, and language C's
name for language D?"
"We can collect the language codes from CLDR and see how many times this
happens. In the majority of cases like that, B and D are codes whose names are
also overlapping in the "
" language and can be resolved by some general
principle."
"For example, no matter whether you decide ""Tagalog"" refers to the language code
"
 or the largely overlapping code 
", that distinction doesn't depend on
the language you're saying ""Tagalog"" in. We can just return "
 consistently.
"In the few cases of actual interlingual ambiguity, langcodes won't match a result.
You can pass in a "
 parameter to say what language the name is in.
"For example, there are two distinct languages called ""Tonga"" in various languages.
They are "
", the language of Tonga which is called ""Tongan"" in English; and "
",
a language of Malawi that can be called ""Nyasa Tonga"" in English."
"Other ambiguous names written in Latin letters are ""Kiga"", ""Mbundu"", ""Roman"", and ""Ruanda""."
The 
 and 
"
methods get Unicode's estimates of how many people in the world use a
language."
"As with the language name data, this requires the optional "
"
package to be installed."
" estimates how many people speak a language. It can
be limited to a particular territory with a territory code (such as a country
code)."
"Script codes will be ignored, because the script is not involved in speaking:"
 estimates how many people write a language.
"The estimates for ""writing population"" are often overestimates, as described
in the "
". In most cases,
they are derived from published data about literacy rates in the places where
those languages are spoken. This doesn't take into account that many literate
people around the world speak a language that isn't typically written, and
write in a "
 language.
Like 
", this can be limited to a particular territory:"
The 
" function returns a number from 0 to 134 indicating the
distance between the language the user desires and a supported language."
"The distance data comes from CLDR v38.1 and involves a lot of judgment calls
made by the Unicode consortium."
This table summarizes the language distance values:
See the docstring of 
 for more explanation and examples.
Suppose you have software that supports any of the 
". The
user wants to use "
.
The function 
"
lets you choose the right language, even if there isn't an exact match.
It returns the language tag of the best-supported language, even if there
isn't an exact match."
The 
" parameter lets you set a cutoff on what counts as language
support. It has a default of 25, a value that is probably okay for simple
cases of i18n, but you might want to set it lower to require more precision."
A similar function is 
",
which returns both the best matching language tag and the distance. If there is
no match, it returns ('und', 1000)."
"There are many more methods for manipulating and comparing language codes,
and you will find them documented thoroughly in "
.
"The interesting functions all live in this one file, with extensive docstrings
and annotations. Making a separate Sphinx page out of the docstrings would be
the traditional thing to do, but here it just seems redundant. You can go read
the docstrings in context, in their native habitat, and they'll always be up to
date."
"To install the package in editable mode before PEP 660 is better supported, use
"
 instead of 
.
"Version 2.0 involves some significant changes that may break compatibility with 1.4,
in addition to updating to version 36.1 of the Unicode CLDR data and the April 2020
version of the IANA subtag registry."
This version requires Python 3.5 or later.
"Originally, the goodness of a match between two different language codes was defined
in terms of a ""match score"" with a maximum of 100. Around 2016, Unicode started
replacing this with a different measure, the ""match distance"", which was defined
much more clearly, but we had to keep using the ""match score""."
"As of langcodes version 2.0, the ""score"" functions (such as
"
", "
", and "
") are deprecated.
They'll keep using the deprecated language match tables from around CLDR 27."
"For a better measure of the closeness of two language codes, use "
",
"
", and "
.
"We were always out of step with CLDR here. Following the example of the IANA
database, we referred to things like the 'US' in 'en-US' as a ""region code"",
but the Unicode standards consistently call it a ""territory code""."
"In langcodes 2.0, parameters, dictionary keys, and attributes named "
"
have been renamed to "
".  We try to support a few common cases with
deprecation warnings, such as looking up the "
" property of a Language
object."
"A nice benefit of this is that when a dictionary is displayed with 'language',
'script', and 'territory' keys in alphabetical order, they are in the same
order as they are in a language code."
description
" knows what languages are. It knows the standardized codes that
refer to them, such as "
" for English, "
 for Spanish and 
 for Hindi.
These are 
". You may know them by their old name, ISO 639
language codes. IETF has done some important things for backward compatibility
and supporting language variations that you won't find in the ISO standard."
"It may sound to you like langcodes solves a pretty boring problem. At one
level, that's right. Sometimes you have a boring problem, and it's great when a
library solves it for you."
"But there's an interesting problem hiding in here. How do you work with
language codes? How do you know when two different codes represent the same
thing? How should your code represent relationships between codes, like the
following?"
"One way to know is to read IETF standards and Unicode technical reports.
Another way is to use a library that implements those standards and guidelines
for you, which langcodes does."
"When you're working with these short language codes, you may want to see the
name that the language is called "
 a language: 
" is called ""French"" in
English. That language doesn't have to be English: "
" is called ""français"" in
French. A supplement to langcodes, "
", provides
this information."
"langcodes is maintained by Elia Robyn Lake a.k.a. Robyn Speer, and is released
as free software under the MIT license."
"Although this is not the only reason to use it, langcodes will make you more
acronym-compliant."
langcodes implements 
", the IETF Best
Current Practices on Tags for Identifying Languages. BCP 47 is also known as
RFC 5646. It subsumes ISO 639 and is backward compatible with it, and it also
implements recommendations from the "
.
"langcodes can also refer to a database of language properties and names, built
from Unicode CLDR and the IANA subtag registry, if you install "
.
"In summary, langcodes takes language codes and does the Right Thing with them,
and if you want to know exactly what the Right Thing is, there are some
documents you can go read."
"This function standardizes tags, as strings, in several ways."
"It replaces overlong tags with their shortest version, and also formats them
according to the conventions of BCP 47:"
It removes script subtags that are redundant with the language:
"It replaces deprecated values with their correct versions, if possible:"
"Sometimes this involves complex substitutions, such as replacing Serbo-Croatian
("
) with Serbian in Latin script (
"), or the entire tag "
"
with "
 (American Sign Language).
If 
" is True, it uses macrolanguage codes as a replacement for the most
common standardized language within that macrolanguage."
Even when 
" is False, it shortens tags that contain both the
macrolanguage and the language:"
"If the tag can't be parsed according to BCP 47, this will raise a
LanguageTagError (a subclass of ValueError):"
"This package defines one class, named Language, which contains the results
of parsing a language tag. Language objects have the following fields,
any of which may be unspecified:"
The 
" method converts a string to a Language instance, and the
"
" method makes a Language instance from its fields.  These values
are cached so that calling "
 or 
" again with the
same values returns the same object, for efficiency."
"By default, it will replace non-standard and overlong tags as it interprets
them. To disable this feature and get the codes that literally appear in the
language tag, use the "
 option.
Here are some examples of replacing non-standard tags:
Use the 
" function on a Language object to convert it back to its
standard string form:"
A language code is 
" when every part of it is assigned a meaning by IANA.
That meaning could be ""private use""."
"In langcodes, we check the language subtag, script, territory, and variants for
validity. We don't check other parts such as extlangs or Unicode extensions."
"For example, "
" is a valid language code, and "
 is not:
The top-level function 
" is possibly more convenient to use,
because it can return False even for tags that don't parse:"
"If one subtag is invalid, the entire code is invalid:"
" is valid, though it's a deprecated alias for "
:
The empty language tag (
) is valid:
Private use codes are valid:
Language tags that are very unlikely are still valid:
"Tags with non-ASCII characters are invalid, because they don't parse:"
"Before there was BCP 47, there was ISO 639-2. The ISO tried to make room for the
variety of human languages by assigning every language a 3-letter code,
including the ones that already had 2-letter codes."
"Unfortunately, this just led to more confusion. Some languages ended up with two
different 3-letter codes for legacy reasons, such as French, which is "
" as a
""terminology"" code, and "
" as a ""biblographic"" code. And meanwhile, "
" was
still a code that you'd be using if you followed ISO 639-1."
"In BCP 47, you should use 2-letter codes whenever they're available, and that's
what langcodes does. Fortunately, all the languages that have two different
3-letter codes also have a 2-letter code, so if you prefer the 2-letter code,
you don't have to worry about the distinction."
"But some applications want the 3-letter code in particular, so langcodes
provides a method for getting those, "
". It returns the
'terminology' code by default, and passing "
" returns the
bibliographic code."
"When this method returns, it always returns a 3-letter string."
"For many languages, the terminology and bibliographic alpha3 codes are the same."
"When you use any of these ""overlong"" alpha3 codes in langcodes, they normalize
back to the alpha2 code:"
The methods in this section require an optional package called 
".
You can install it with "
", or request the optional
""data"" feature of langcodes with "
.
The dependency that you put in setup.py should be 
.
"It's often helpful to be able to describe a language code in a way that a user
(or you) can understand, instead of in inscrutable short codes. The
"
 method lets you describe a Language object 
.
The 
" method will look up the name of the
language. The names come from the IANA language tag registry, which is only in
English, plus CLDR, which names languages in many commonly-used languages."
The default language for naming things is English:
But you can ask for language names in numerous other languages:
Why does everyone get Slovak and Slovenian confused? Let's ask them.
"If the language has a script or territory code attached to it, these will be
described in parentheses:"
"Sometimes these can be the result of tag normalization, such as in this case
where the legacy tag 'sh' becomes 'sr-Latn':"
"Naming a language in itself is sometimes a useful thing to do, so the
"
" method makes this easy, providing the display name of a language
in the language itself:"
"The names come from the Unicode CLDR data files, and in English they can
also come from the IANA language subtag registry. Together, they can give
you language names in the 196 languages that CLDR supports."
You can get the parts of the name separately with the methods 
",
"
", and "
", or get a dictionary of all the parts
that are present using the "
" method. These methods also accept a
language code for what language they should be described in."
"As the reverse of the above operations, you may want to look up a language by
its name, converting a natural language name such as ""French"" to a code such as
'fr'."
"The name can be in any language that CLDR supports (see ""Ambiguity"" below)."
"However, this method currently ignores the parenthetical expressions that come from
"
:
"There is still room to improve the way that language names are matched, because
some languages are not consistently named the same way. The method currently
works with hundreds of language names that are used on Wiktionary."
"For the sake of usability, "
" doesn't require you to specify what
language you're looking up a language in by name. This could potentially lead to
a conflict: what if name ""X"" is language A's name for language B, and language C's
name for language D?"
"We can collect the language codes from CLDR and see how many times this
happens. In the majority of cases like that, B and D are codes whose names are
also overlapping in the "
" language and can be resolved by some general
principle."
"For example, no matter whether you decide ""Tagalog"" refers to the language code
"
 or the largely overlapping code 
", that distinction doesn't depend on
the language you're saying ""Tagalog"" in. We can just return "
 consistently.
"In the few cases of actual interlingual ambiguity, langcodes won't match a result.
You can pass in a "
 parameter to say what language the name is in.
"For example, there are two distinct languages called ""Tonga"" in various languages.
They are "
", the language of Tonga which is called ""Tongan"" in English; and "
",
a language of Malawi that can be called ""Nyasa Tonga"" in English."
"Other ambiguous names written in Latin letters are ""Kiga"", ""Mbundu"", ""Roman"", and ""Ruanda""."
The 
 and 
"
methods get Unicode's estimates of how many people in the world use a
language."
"As with the language name data, this requires the optional "
"
package to be installed."
" estimates how many people speak a language. It can
be limited to a particular territory with a territory code (such as a country
code)."
"Script codes will be ignored, because the script is not involved in speaking:"
 estimates how many people write a language.
"The estimates for ""writing population"" are often overestimates, as described
in the "
". In most cases,
they are derived from published data about literacy rates in the places where
those languages are spoken. This doesn't take into account that many literate
people around the world speak a language that isn't typically written, and
write in a "
 language.
Like 
", this can be limited to a particular territory:"
The 
" function returns a number from 0 to 134 indicating the
distance between the language the user desires and a supported language."
"The distance data comes from CLDR v38.1 and involves a lot of judgment calls
made by the Unicode consortium."
This table summarizes the language distance values:
See the docstring of 
 for more explanation and examples.
Suppose you have software that supports any of the 
". The
user wants to use "
.
The function 
"
lets you choose the right language, even if there isn't an exact match.
It returns the language tag of the best-supported language, even if there
isn't an exact match."
The 
" parameter lets you set a cutoff on what counts as language
support. It has a default of 25, a value that is probably okay for simple
cases of i18n, but you might want to set it lower to require more precision."
A similar function is 
",
which returns both the best matching language tag and the distance. If there is
no match, it returns ('und', 1000)."
"There are many more methods for manipulating and comparing language codes,
and you will find them documented thoroughly in "
.
"The interesting functions all live in this one file, with extensive docstrings
and annotations. Making a separate Sphinx page out of the docstrings would be
the traditional thing to do, but here it just seems redundant. You can go read
the docstrings in context, in their native habitat, and they'll always be up to
date."
"To install the package in editable mode before PEP 660 is better supported, use
"
 instead of 
.
"Version 2.0 involves some significant changes that may break compatibility with 1.4,
in addition to updating to version 36.1 of the Unicode CLDR data and the April 2020
version of the IANA subtag registry."
This version requires Python 3.5 or later.
"Originally, the goodness of a match between two different language codes was defined
in terms of a ""match score"" with a maximum of 100. Around 2016, Unicode started
replacing this with a different measure, the ""match distance"", which was defined
much more clearly, but we had to keep using the ""match score""."
"As of langcodes version 2.0, the ""score"" functions (such as
"
", "
", and "
") are deprecated.
They'll keep using the deprecated language match tables from around CLDR 27."
"For a better measure of the closeness of two language codes, use "
",
"
", and "
.
"We were always out of step with CLDR here. Following the example of the IANA
database, we referred to things like the 'US' in 'en-US' as a ""region code"",
but the Unicode standards consistently call it a ""territory code""."
"In langcodes 2.0, parameters, dictionary keys, and attributes named "
"
have been renamed to "
".  We try to support a few common cases with
deprecation warnings, such as looking up the "
" property of a Language
object."
"A nice benefit of this is that when a dictionary is displayed with 'language',
'script', and 'territory' keys in alphabetical order, they are in the same
order as they are in a language code."
description
" knows what languages are. It knows the standardized codes that
refer to them, such as "
" for English, "
 for Spanish and 
 for Hindi.
These are 
". You may know them by their old name, ISO 639
language codes. IETF has done some important things for backward compatibility
and supporting language variations that you won't find in the ISO standard."
"It may sound to you like langcodes solves a pretty boring problem. At one
level, that's right. Sometimes you have a boring problem, and it's great when a
library solves it for you."
"But there's an interesting problem hiding in here. How do you work with
language codes? How do you know when two different codes represent the same
thing? How should your code represent relationships between codes, like the
following?"
"One way to know is to read IETF standards and Unicode technical reports.
Another way is to use a library that implements those standards and guidelines
for you, which langcodes does."
"When you're working with these short language codes, you may want to see the
name that the language is called "
 a language: 
" is called ""French"" in
English. That language doesn't have to be English: "
" is called ""français"" in
French. A supplement to langcodes, "
", provides
this information."
"langcodes is maintained by Elia Robyn Lake a.k.a. Robyn Speer, and is released
as free software under the MIT license."
"Although this is not the only reason to use it, langcodes will make you more
acronym-compliant."
langcodes implements 
", the IETF Best
Current Practices on Tags for Identifying Languages. BCP 47 is also known as
RFC 5646. It subsumes ISO 639 and is backward compatible with it, and it also
implements recommendations from the "
.
"langcodes can also refer to a database of language properties and names, built
from Unicode CLDR and the IANA subtag registry, if you install "
.
"In summary, langcodes takes language codes and does the Right Thing with them,
and if you want to know exactly what the Right Thing is, there are some
documents you can go read."
"This function standardizes tags, as strings, in several ways."
"It replaces overlong tags with their shortest version, and also formats them
according to the conventions of BCP 47:"
It removes script subtags that are redundant with the language:
"It replaces deprecated values with their correct versions, if possible:"
"Sometimes this involves complex substitutions, such as replacing Serbo-Croatian
("
) with Serbian in Latin script (
"), or the entire tag "
"
with "
 (American Sign Language).
If 
" is True, it uses macrolanguage codes as a replacement for the most
common standardized language within that macrolanguage."
Even when 
" is False, it shortens tags that contain both the
macrolanguage and the language:"
"If the tag can't be parsed according to BCP 47, this will raise a
LanguageTagError (a subclass of ValueError):"
"This package defines one class, named Language, which contains the results
of parsing a language tag. Language objects have the following fields,
any of which may be unspecified:"
The 
" method converts a string to a Language instance, and the
"
" method makes a Language instance from its fields.  These values
are cached so that calling "
 or 
" again with the
same values returns the same object, for efficiency."
"By default, it will replace non-standard and overlong tags as it interprets
them. To disable this feature and get the codes that literally appear in the
language tag, use the "
 option.
Here are some examples of replacing non-standard tags:
Use the 
" function on a Language object to convert it back to its
standard string form:"
A language code is 
" when every part of it is assigned a meaning by IANA.
That meaning could be ""private use""."
"In langcodes, we check the language subtag, script, territory, and variants for
validity. We don't check other parts such as extlangs or Unicode extensions."
"For example, "
" is a valid language code, and "
 is not:
The top-level function 
" is possibly more convenient to use,
because it can return False even for tags that don't parse:"
"If one subtag is invalid, the entire code is invalid:"
" is valid, though it's a deprecated alias for "
:
The empty language tag (
) is valid:
Private use codes are valid:
Language tags that are very unlikely are still valid:
"Tags with non-ASCII characters are invalid, because they don't parse:"
"Before there was BCP 47, there was ISO 639-2. The ISO tried to make room for the
variety of human languages by assigning every language a 3-letter code,
including the ones that already had 2-letter codes."
"Unfortunately, this just led to more confusion. Some languages ended up with two
different 3-letter codes for legacy reasons, such as French, which is "
" as a
""terminology"" code, and "
" as a ""biblographic"" code. And meanwhile, "
" was
still a code that you'd be using if you followed ISO 639-1."
"In BCP 47, you should use 2-letter codes whenever they're available, and that's
what langcodes does. Fortunately, all the languages that have two different
3-letter codes also have a 2-letter code, so if you prefer the 2-letter code,
you don't have to worry about the distinction."
"But some applications want the 3-letter code in particular, so langcodes
provides a method for getting those, "
". It returns the
'terminology' code by default, and passing "
" returns the
bibliographic code."
"When this method returns, it always returns a 3-letter string."
"For many languages, the terminology and bibliographic alpha3 codes are the same."
"When you use any of these ""overlong"" alpha3 codes in langcodes, they normalize
back to the alpha2 code:"
The methods in this section require an optional package called 
".
You can install it with "
", or request the optional
""data"" feature of langcodes with "
.
The dependency that you put in setup.py should be 
.
"It's often helpful to be able to describe a language code in a way that a user
(or you) can understand, instead of in inscrutable short codes. The
"
 method lets you describe a Language object 
.
The 
" method will look up the name of the
language. The names come from the IANA language tag registry, which is only in
English, plus CLDR, which names languages in many commonly-used languages."
The default language for naming things is English:
But you can ask for language names in numerous other languages:
Why does everyone get Slovak and Slovenian confused? Let's ask them.
"If the language has a script or territory code attached to it, these will be
described in parentheses:"
"Sometimes these can be the result of tag normalization, such as in this case
where the legacy tag 'sh' becomes 'sr-Latn':"
"Naming a language in itself is sometimes a useful thing to do, so the
"
" method makes this easy, providing the display name of a language
in the language itself:"
"The names come from the Unicode CLDR data files, and in English they can
also come from the IANA language subtag registry. Together, they can give
you language names in the 196 languages that CLDR supports."
You can get the parts of the name separately with the methods 
",
"
", and "
", or get a dictionary of all the parts
that are present using the "
" method. These methods also accept a
language code for what language they should be described in."
"As the reverse of the above operations, you may want to look up a language by
its name, converting a natural language name such as ""French"" to a code such as
'fr'."
"The name can be in any language that CLDR supports (see ""Ambiguity"" below)."
"However, this method currently ignores the parenthetical expressions that come from
"
:
"There is still room to improve the way that language names are matched, because
some languages are not consistently named the same way. The method currently
works with hundreds of language names that are used on Wiktionary."
"For the sake of usability, "
" doesn't require you to specify what
language you're looking up a language in by name. This could potentially lead to
a conflict: what if name ""X"" is language A's name for language B, and language C's
name for language D?"
"We can collect the language codes from CLDR and see how many times this
happens. In the majority of cases like that, B and D are codes whose names are
also overlapping in the "
" language and can be resolved by some general
principle."
"For example, no matter whether you decide ""Tagalog"" refers to the language code
"
 or the largely overlapping code 
", that distinction doesn't depend on
the language you're saying ""Tagalog"" in. We can just return "
 consistently.
"In the few cases of actual interlingual ambiguity, langcodes won't match a result.
You can pass in a "
 parameter to say what language the name is in.
"For example, there are two distinct languages called ""Tonga"" in various languages.
They are "
", the language of Tonga which is called ""Tongan"" in English; and "
",
a language of Malawi that can be called ""Nyasa Tonga"" in English."
"Other ambiguous names written in Latin letters are ""Kiga"", ""Mbundu"", ""Roman"", and ""Ruanda""."
The 
 and 
"
methods get Unicode's estimates of how many people in the world use a
language."
"As with the language name data, this requires the optional "
"
package to be installed."
" estimates how many people speak a language. It can
be limited to a particular territory with a territory code (such as a country
code)."
"Script codes will be ignored, because the script is not involved in speaking:"
 estimates how many people write a language.
"The estimates for ""writing population"" are often overestimates, as described
in the "
". In most cases,
they are derived from published data about literacy rates in the places where
those languages are spoken. This doesn't take into account that many literate
people around the world speak a language that isn't typically written, and
write in a "
 language.
Like 
", this can be limited to a particular territory:"
The 
" function returns a number from 0 to 134 indicating the
distance between the language the user desires and a supported language."
"The distance data comes from CLDR v38.1 and involves a lot of judgment calls
made by the Unicode consortium."
This table summarizes the language distance values:
See the docstring of 
 for more explanation and examples.
Suppose you have software that supports any of the 
". The
user wants to use "
.
The function 
"
lets you choose the right language, even if there isn't an exact match.
It returns the language tag of the best-supported language, even if there
isn't an exact match."
The 
" parameter lets you set a cutoff on what counts as language
support. It has a default of 25, a value that is probably okay for simple
cases of i18n, but you might want to set it lower to require more precision."
A similar function is 
",
which returns both the best matching language tag and the distance. If there is
no match, it returns ('und', 1000)."
"There are many more methods for manipulating and comparing language codes,
and you will find them documented thoroughly in "
.
"The interesting functions all live in this one file, with extensive docstrings
and annotations. Making a separate Sphinx page out of the docstrings would be
the traditional thing to do, but here it just seems redundant. You can go read
the docstrings in context, in their native habitat, and they'll always be up to
date."
"To install the package in editable mode before PEP 660 is better supported, use
"
 instead of 
.
"Version 2.0 involves some significant changes that may break compatibility with 1.4,
in addition to updating to version 36.1 of the Unicode CLDR data and the April 2020
version of the IANA subtag registry."
This version requires Python 3.5 or later.
"Originally, the goodness of a match between two different language codes was defined
in terms of a ""match score"" with a maximum of 100. Around 2016, Unicode started
replacing this with a different measure, the ""match distance"", which was defined
much more clearly, but we had to keep using the ""match score""."
"As of langcodes version 2.0, the ""score"" functions (such as
"
", "
", and "
") are deprecated.
They'll keep using the deprecated language match tables from around CLDR 27."
"For a better measure of the closeness of two language codes, use "
",
"
", and "
.
"We were always out of step with CLDR here. Following the example of the IANA
database, we referred to things like the 'US' in 'en-US' as a ""region code"",
but the Unicode standards consistently call it a ""territory code""."
"In langcodes 2.0, parameters, dictionary keys, and attributes named "
"
have been renamed to "
".  We try to support a few common cases with
deprecation warnings, such as looking up the "
" property of a Language
object."
"A nice benefit of this is that when a dictionary is displayed with 'language',
'script', and 'territory' keys in alphabetical order, they are in the same
order as they are in a language code."
description
" knows what languages are. It knows the standardized codes that
refer to them, such as "
" for English, "
 for Spanish and 
 for Hindi.
These are 
". You may know them by their old name, ISO 639
language codes. IETF has done some important things for backward compatibility
and supporting language variations that you won't find in the ISO standard."
"It may sound to you like langcodes solves a pretty boring problem. At one
level, that's right. Sometimes you have a boring problem, and it's great when a
library solves it for you."
"But there's an interesting problem hiding in here. How do you work with
language codes? How do you know when two different codes represent the same
thing? How should your code represent relationships between codes, like the
following?"
"One way to know is to read IETF standards and Unicode technical reports.
Another way is to use a library that implements those standards and guidelines
for you, which langcodes does."
"When you're working with these short language codes, you may want to see the
name that the language is called "
 a language: 
" is called ""French"" in
English. That language doesn't have to be English: "
" is called ""français"" in
French. A supplement to langcodes, "
", provides
this information."
"langcodes is maintained by Elia Robyn Lake a.k.a. Robyn Speer, and is released
as free software under the MIT license."
"Although this is not the only reason to use it, langcodes will make you more
acronym-compliant."
langcodes implements 
", the IETF Best
Current Practices on Tags for Identifying Languages. BCP 47 is also known as
RFC 5646. It subsumes ISO 639 and is backward compatible with it, and it also
implements recommendations from the "
.
"langcodes can also refer to a database of language properties and names, built
from Unicode CLDR and the IANA subtag registry, if you install "
.
"In summary, langcodes takes language codes and does the Right Thing with them,
and if you want to know exactly what the Right Thing is, there are some
documents you can go read."
"This function standardizes tags, as strings, in several ways."
"It replaces overlong tags with their shortest version, and also formats them
according to the conventions of BCP 47:"
It removes script subtags that are redundant with the language:
"It replaces deprecated values with their correct versions, if possible:"
"Sometimes this involves complex substitutions, such as replacing Serbo-Croatian
("
) with Serbian in Latin script (
"), or the entire tag "
"
with "
 (American Sign Language).
If 
" is True, it uses macrolanguage codes as a replacement for the most
common standardized language within that macrolanguage."
Even when 
" is False, it shortens tags that contain both the
macrolanguage and the language:"
"If the tag can't be parsed according to BCP 47, this will raise a
LanguageTagError (a subclass of ValueError):"
"This package defines one class, named Language, which contains the results
of parsing a language tag. Language objects have the following fields,
any of which may be unspecified:"
The 
" method converts a string to a Language instance, and the
"
" method makes a Language instance from its fields.  These values
are cached so that calling "
 or 
" again with the
same values returns the same object, for efficiency."
"By default, it will replace non-standard and overlong tags as it interprets
them. To disable this feature and get the codes that literally appear in the
language tag, use the "
 option.
Here are some examples of replacing non-standard tags:
Use the 
" function on a Language object to convert it back to its
standard string form:"
A language code is 
" when every part of it is assigned a meaning by IANA.
That meaning could be ""private use""."
"In langcodes, we check the language subtag, script, territory, and variants for
validity. We don't check other parts such as extlangs or Unicode extensions."
"For example, "
" is a valid language code, and "
 is not:
The top-level function 
" is possibly more convenient to use,
because it can return False even for tags that don't parse:"
"If one subtag is invalid, the entire code is invalid:"
" is valid, though it's a deprecated alias for "
:
The empty language tag (
) is valid:
Private use codes are valid:
Language tags that are very unlikely are still valid:
"Tags with non-ASCII characters are invalid, because they don't parse:"
"Before there was BCP 47, there was ISO 639-2. The ISO tried to make room for the
variety of human languages by assigning every language a 3-letter code,
including the ones that already had 2-letter codes."
"Unfortunately, this just led to more confusion. Some languages ended up with two
different 3-letter codes for legacy reasons, such as French, which is "
" as a
""terminology"" code, and "
" as a ""biblographic"" code. And meanwhile, "
" was
still a code that you'd be using if you followed ISO 639-1."
"In BCP 47, you should use 2-letter codes whenever they're available, and that's
what langcodes does. Fortunately, all the languages that have two different
3-letter codes also have a 2-letter code, so if you prefer the 2-letter code,
you don't have to worry about the distinction."
"But some applications want the 3-letter code in particular, so langcodes
provides a method for getting those, "
". It returns the
'terminology' code by default, and passing "
" returns the
bibliographic code."
"When this method returns, it always returns a 3-letter string."
"For many languages, the terminology and bibliographic alpha3 codes are the same."
"When you use any of these ""overlong"" alpha3 codes in langcodes, they normalize
back to the alpha2 code:"
The methods in this section require an optional package called 
".
You can install it with "
", or request the optional
""data"" feature of langcodes with "
.
The dependency that you put in setup.py should be 
.
"It's often helpful to be able to describe a language code in a way that a user
(or you) can understand, instead of in inscrutable short codes. The
"
 method lets you describe a Language object 
.
The 
" method will look up the name of the
language. The names come from the IANA language tag registry, which is only in
English, plus CLDR, which names languages in many commonly-used languages."
The default language for naming things is English:
But you can ask for language names in numerous other languages:
Why does everyone get Slovak and Slovenian confused? Let's ask them.
"If the language has a script or territory code attached to it, these will be
described in parentheses:"
"Sometimes these can be the result of tag normalization, such as in this case
where the legacy tag 'sh' becomes 'sr-Latn':"
"Naming a language in itself is sometimes a useful thing to do, so the
"
" method makes this easy, providing the display name of a language
in the language itself:"
"The names come from the Unicode CLDR data files, and in English they can
also come from the IANA language subtag registry. Together, they can give
you language names in the 196 languages that CLDR supports."
You can get the parts of the name separately with the methods 
",
"
", and "
", or get a dictionary of all the parts
that are present using the "
" method. These methods also accept a
language code for what language they should be described in."
"As the reverse of the above operations, you may want to look up a language by
its name, converting a natural language name such as ""French"" to a code such as
'fr'."
"The name can be in any language that CLDR supports (see ""Ambiguity"" below)."
"However, this method currently ignores the parenthetical expressions that come from
"
:
"There is still room to improve the way that language names are matched, because
some languages are not consistently named the same way. The method currently
works with hundreds of language names that are used on Wiktionary."
"For the sake of usability, "
" doesn't require you to specify what
language you're looking up a language in by name. This could potentially lead to
a conflict: what if name ""X"" is language A's name for language B, and language C's
name for language D?"
"We can collect the language codes from CLDR and see how many times this
happens. In the majority of cases like that, B and D are codes whose names are
also overlapping in the "
" language and can be resolved by some general
principle."
"For example, no matter whether you decide ""Tagalog"" refers to the language code
"
 or the largely overlapping code 
", that distinction doesn't depend on
the language you're saying ""Tagalog"" in. We can just return "
 consistently.
"In the few cases of actual interlingual ambiguity, langcodes won't match a result.
You can pass in a "
 parameter to say what language the name is in.
"For example, there are two distinct languages called ""Tonga"" in various languages.
They are "
", the language of Tonga which is called ""Tongan"" in English; and "
",
a language of Malawi that can be called ""Nyasa Tonga"" in English."
"Other ambiguous names written in Latin letters are ""Kiga"", ""Mbundu"", ""Roman"", and ""Ruanda""."
The 
 and 
"
methods get Unicode's estimates of how many people in the world use a
language."
"As with the language name data, this requires the optional "
"
package to be installed."
" estimates how many people speak a language. It can
be limited to a particular territory with a territory code (such as a country
code)."
"Script codes will be ignored, because the script is not involved in speaking:"
 estimates how many people write a language.
"The estimates for ""writing population"" are often overestimates, as described
in the "
". In most cases,
they are derived from published data about literacy rates in the places where
those languages are spoken. This doesn't take into account that many literate
people around the world speak a language that isn't typically written, and
write in a "
 language.
Like 
", this can be limited to a particular territory:"
The 
" function returns a number from 0 to 134 indicating the
distance between the language the user desires and a supported language."
"The distance data comes from CLDR v38.1 and involves a lot of judgment calls
made by the Unicode consortium."
This table summarizes the language distance values:
See the docstring of 
 for more explanation and examples.
Suppose you have software that supports any of the 
". The
user wants to use "
.
The function 
"
lets you choose the right language, even if there isn't an exact match.
It returns the language tag of the best-supported language, even if there
isn't an exact match."
The 
" parameter lets you set a cutoff on what counts as language
support. It has a default of 25, a value that is probably okay for simple
cases of i18n, but you might want to set it lower to require more precision."
A similar function is 
",
which returns both the best matching language tag and the distance. If there is
no match, it returns ('und', 1000)."
"There are many more methods for manipulating and comparing language codes,
and you will find them documented thoroughly in "
.
"The interesting functions all live in this one file, with extensive docstrings
and annotations. Making a separate Sphinx page out of the docstrings would be
the traditional thing to do, but here it just seems redundant. You can go read
the docstrings in context, in their native habitat, and they'll always be up to
date."
"To install the package in editable mode before PEP 660 is better supported, use
"
 instead of 
.
"Version 2.0 involves some significant changes that may break compatibility with 1.4,
in addition to updating to version 36.1 of the Unicode CLDR data and the April 2020
version of the IANA subtag registry."
This version requires Python 3.5 or later.
"Originally, the goodness of a match between two different language codes was defined
in terms of a ""match score"" with a maximum of 100. Around 2016, Unicode started
replacing this with a different measure, the ""match distance"", which was defined
much more clearly, but we had to keep using the ""match score""."
"As of langcodes version 2.0, the ""score"" functions (such as
"
", "
", and "
") are deprecated.
They'll keep using the deprecated language match tables from around CLDR 27."
"For a better measure of the closeness of two language codes, use "
",
"
", and "
.
"We were always out of step with CLDR here. Following the example of the IANA
database, we referred to things like the 'US' in 'en-US' as a ""region code"",
but the Unicode standards consistently call it a ""territory code""."
"In langcodes 2.0, parameters, dictionary keys, and attributes named "
"
have been renamed to "
".  We try to support a few common cases with
deprecation warnings, such as looking up the "
" property of a Language
object."
"A nice benefit of this is that when a dictionary is displayed with 'language',
'script', and 'territory' keys in alphabetical order, they are in the same
order as they are in a language code."
